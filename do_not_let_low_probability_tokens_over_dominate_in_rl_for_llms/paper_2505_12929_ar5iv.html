<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2505.12929] Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs</title><meta property="og:description" content="Reinforcement learning (RL) has become a cornerstone for enhancing the reasoning capabilities of large language models (LLMs), with recent innovations such as Group Relative Policy Optimization (GRPO) demonstrating excâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2505.12929">
<link rel="canonical" target="_blank" href="https://ar5iv.labs.arxiv.org/html/2505.12929">

<!--Generated on Thu Jun  5 14:48:30 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.4.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.4.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">
Do Not Let Low-Probability Tokens 
<br class="ltx_break">Over-Dominate in RL for LLMs</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhihe Yang<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">1</span></sup> â€ƒXufang Luo<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">2</span></sup> â€ƒZilong Wang<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">2</span></sup> â€ƒDongqi Han<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">2</span></sup> 
<br class="ltx_break"><span class="ltx_text ltx_font_bold">Zhiyuan He<sup class="ltx_sup"><span class="ltx_text ltx_font_medium ltx_font_italic">2</span></sup> â€ƒDongsheng Li<sup class="ltx_sup"><span class="ltx_text ltx_font_medium ltx_font_italic">2</span></sup> â€ƒYunjian Xu<sup class="ltx_sup"><span class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup><span id="footnotex1" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium">1</span></span></span></span></span> 
<br class="ltx_break"><sup class="ltx_sup"><span class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup></span>The Chinese University of Hong Kong, Hong Kong SAR, China. 
<br class="ltx_break"><sup class="ltx_sup"><span class="ltx_text ltx_font_italic">2</span></sup>Microsoft Research Asia, Shanghai, China. 
<br class="ltx_break">
</span><span class="ltx_author_notes">Corresponding authors.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p">Reinforcement learning (RL) has become a cornerstone for enhancing the reasoning capabilities of large language models (LLMs), with recent innovations such as Group Relative Policy Optimization (GRPO) demonstrating exceptional effectiveness.
In this study, we identify a critical yet underexplored issue in RL training: low-probability tokens disproportionately influence model updates due to their large gradient magnitudes.
This dominance hinders the effective learning of high-probability tokens, whose gradients are essential for LLMsâ€™ performance but are substantially suppressed.
To mitigate this interference, we propose two novel methods: <span class="ltx_text ltx_font_italic">Advantage Reweighting</span> and <span class="ltx_text ltx_font_italic">Low-Probability Token Isolation (Lopti)</span>, both of which effectively attenuate gradients from low-probability tokens while emphasizing parameter updates driven by high-probability tokens.
Our approaches promote balanced updates across tokens with varying probabilities, thereby enhancing the efficiency of RL training.
Experimental results demonstrate that they substantially improve the performance of GRPO-trained LLMs, achieving up to a 46.2% improvement in K&amp;K Logic Puzzle reasoning tasks.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Our implementation is available at <a target="_blank" href="https://github.com/zhyang2226/AR-Lopti" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="color:#FF30FF;">https://github.com/zhyang2226/AR-Lopti</a>.</span></span></span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p">The reasoning capabilities of large language models (LLMs) have recently achieved a milestone breakthrough with the integration of reinforcement learning (RL) during post-training phaseÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib1" title="" class="ltx_ref">jaech2024openaio1 </a>; <a href="#bib.bib2" title="" class="ltx_ref">guo2025deepseekr1 </a>; <a href="#bib.bib3" title="" class="ltx_ref">team2025kimi </a></cite>.
Intuitively, the vast vocabulary size and the auto-regressive generation mechanism of LLMs pose significant challenges for effective exploration due to the exponentially large state space.
DeepSeek-R1Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib2" title="" class="ltx_ref">guo2025deepseekr1 </a></cite> eliminates this bias, demonstrating that â€˜simple RL with rule-based rewardâ€™ can significantly enhance the reasoning abilities of LLMs without relying on scaffolding techniques such as Monte Carlo Tree Search (MCTS)Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib4" title="" class="ltx_ref">xie2MCTS </a>; <a href="#bib.bib5" title="" class="ltx_ref">chenalphamath_mcts </a></cite> or Progress Reward Modeling (PRM)Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib6" title="" class="ltx_ref">lightman2024PRM </a>; <a href="#bib.bib7" title="" class="ltx_ref">wang2024PRM </a></cite>.
Moreover, they introduce a novel algorithm, Group Relative Policy Optimization (GRPO)Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib8" title="" class="ltx_ref">shao2024deepseekmath </a></cite>, which has proven highly effective in the domains of mathematics and code, inspiring numerous follow-up studies.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p">Yu et al.Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib9" title="" class="ltx_ref">yu2025dapo </a></cite> and Liu et al.Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib10" title="" class="ltx_ref">liu2025drgrpo </a></cite> consistently report that GRPO training leads to progressively longer response lengths, while the increase does not correspond to a proportional improvement in the modelâ€™s performance.
They attribute this trend to the bias in update weights related to response length inherent in GRPOâ€™s objective.
Xiong et al.Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib11" title="" class="ltx_ref">xiong2025minimalist </a></cite> conduct comparison between GRPO and Proximal Policy Optimization (PPO). They find that the instability of PPO, compared to GRPO, arises from its unnecessary bias toward entirely incorrect responses on overly difficult prompts. In contrast, GRPO mitigates this issue by discarding such prompts through a within-prompt normalization operation.
These findings highlight the substantial impact of update bias on training outcomes.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2505.12929/assets/fig/fig1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="263" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>
Experimental analysis on the K&amp;K Logic Puzzle dataset during GRPO training of <span class="ltx_text ltx_font_typewriter">Qwen2.5-7B-Instruct-1M</span>. Tokens are divided into four groups based on probability quartiles. (a) Token probability distribution and (b) corresponding advantages. (c) Token probability changes after updates (using SGD with lr=1e-3) and (d) gradient norms for each probability group.
Effects of selective updates: (e) Probability changes when only tokens in the lowest quartile (probability &lt; 0.25) are updated, and (f) when only tokens in the highest quartile (probability &gt; 0.75) are updated.
To ensure clarity, the top 1% of outlier samples in the violin plots for token probability changes are excluded. Results are averaged over 10 randomly sampled batches.
</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p">In this study, we identify another important source of update bias in RL training, which is orthogonal to aforementioned ones and has rarely been noted in prior research.
This bias arises from the gradient perspective and is strongly correlated with the token probabilities.
As shown in FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, during GRPO training, tokens are divided into four groups based on probability quartiles. The policy gradient is conducted with the advantage presented in FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(b).
FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(d) shows that low-probability tokens generate disproportionately larger gradients compared to high-probability ones. Since each RL update involves hundreds of thousands of tokens with interacting gradients, low-probability tokens are expected to have a greater influence.
To verify this, we independently update tokens from the lowest and highest quartiles, as shown in FiguresÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(e) and (f). The pattern in (e) closely matches (c), while (f) looks significantly different. Interestingly, in (e), even though high-probability tokens were not updated, their probabilities changed more significantly than when they were updated (as shown in (f)).
Thus, we conclude that <span class="ltx_text ltx_font_bold">low-probability tokens dominate model updates</span> during RL training and that <span class="ltx_text ltx_font_bold">this dominance may impede the precise adjustment of the probability distribution across all tokens</span>. Notably, we observe that high-probability tokens are much less likely to be updated in the correct direction compared to low-probability tokens (cf. FigureÂ <a href="#S4.F3" title="Figure 3 â€£ 4.2 Mitigating the Over-Dominance of Low-Probability Tokens â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p">By deriving the gradients induced by individual tokens, we reveal a key property of RL training that explains the phenomenon illustrated in FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Specifically, for an LLM comprising a benign neural network, the gradient norm of any intermediate activation corresponding to a single token is bounded between two values proportional to <math id="S1.p4.m1" class="ltx_Math" alttext="(1-\pi)" display="inline"><semantics><mrow><mo stretchy="false">(</mo><mrow><mn>1</mn><mo>âˆ’</mo><mi>Ï€</mi></mrow><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(1-\pi)</annotation></semantics></math>, where <math id="S1.p4.m2" class="ltx_Math" alttext="\pi" display="inline"><semantics><mi>Ï€</mi><annotation encoding="application/x-tex">\pi</annotation></semantics></math> is the tokenâ€™s probability.
This property underscores that tokens with lower probabilities result in larger gradient magnitudes, whereas tokens with probabilities approaching 1 yield gradients that are nearly negligible.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p">To mitigate the over-dominance of low-probability tokens and promote more efficient updates, we propose two simple yet effective methods:
<span class="ltx_text ltx_font_italic">Advantage Reweighting</span>, which reduces the weight assigned to low-probability tokens,
and <span class="ltx_text ltx_font_italic">Low-Probability Token Isolation (Lopti)</span>, which separates low-probability tokens and updates them prior to high-probability tokens.
Both methods attenuate gradients from low-probability tokens while emphasizing parameter updates driven by high-probability tokens.
Notably, the first one incurs almost no additional computational cost.
These methods can be applied independently, each providing benefits, or together, with the potential for further performance improvements.
Experimental results demonstrate the effectiveness of the proposed methods across various datasets. In particular, on K&amp;K Logic Puzzle dataset, they enhance the performance of naive GRPO (trained from <span class="ltx_text ltx_font_typewriter">Qwen2.5-3B-Instruct</span>) by 35.9% and 38.5%, respectively, and by 46.2% when used together.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p class="ltx_p">In summary, our contributions are threefold:
(1) We identify a critical issue in RL training for LLMs that has received limited attention: low-probability tokens disproportionately dominate the updates due to their large gradient contributions.
(2) We provide a concise theoretical explanation for this phenomenon.
(3) Based on the identified issue, we propose two simple yet effective methods, which significantly improve the downstream performance of GRPO-trained LLMs across various datasets.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p">As a fundamental technique driving recent advancements in LLMs, reinforcement learning is attracting increasing attention from researchers.
In this section, we provide a concise overview on the development of RL in the context of LLMs.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p class="ltx_p">RL was pioneered by OpenAI as the final step of post-training to further align fine-tuned large models with human preferencesÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib12" title="" class="ltx_ref">christiano2017deep </a>; <a href="#bib.bib13" title="" class="ltx_ref">ziegler2019fine </a>; <a href="#bib.bib14" title="" class="ltx_ref">stiennon2020learning </a>; <a href="#bib.bib15" title="" class="ltx_ref">ouyang2022training </a></cite>.
By leveraging vast amounts of human preference data and stable RL algorithms such as PPOÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib16" title="" class="ltx_ref">schulman2017ppo </a></cite>, numerous enterprise-level language models have benefited from this approach and have been widely adopted.
Notable examples include ChatGPTÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib17" title="" class="ltx_ref">brown2020gpt </a>; <a href="#bib.bib18" title="" class="ltx_ref">achiam2023gpt </a></cite>, LLaMAÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib19" title="" class="ltx_ref">touvron2023llama </a>; <a href="#bib.bib20" title="" class="ltx_ref">touvron2023llama2 </a>; <a href="#bib.bib21" title="" class="ltx_ref">dubey2024llama </a></cite>, QwenÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib22" title="" class="ltx_ref">bai2023qwen </a>; <a href="#bib.bib23" title="" class="ltx_ref">chu2023qwen </a>; <a href="#bib.bib24" title="" class="ltx_ref">yang2024qwen2 </a></cite>, GeminiÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib25" title="" class="ltx_ref">team2023gemini </a>; <a href="#bib.bib26" title="" class="ltx_ref">team2024gemini </a></cite>, and ClaudeÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib27" title="" class="ltx_ref">TheC3 </a></cite>.
Nevertheless, the challenges of collecting high-quality data that accurately reflect human preferences, the limited performance of open-source LLMs, and the computationally intensive training requirements of PPO-like online RL algorithms pose significant barriers for further exploring RLâ€™s potentiality in the domain of LLMs.
Most studies have focused on simplifying RL algorithms and directly leveraging preference data to optimize models.
Representative works include Direct Preference Optimization (DPO)Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib28" title="" class="ltx_ref">rafailov2024dpo </a>; <a href="#bib.bib29" title="" class="ltx_ref">rafailov2024from </a></cite>, related analysesÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib30" title="" class="ltx_ref">xu2024dpo </a>; <a href="#bib.bib31" title="" class="ltx_ref">zhong2024dpo </a>; <a href="#bib.bib32" title="" class="ltx_ref">ren2025learning </a></cite>, and improved variants such as ORPOÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib33" title="" class="ltx_ref">hong2024orpo </a></cite>, CPOÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib34" title="" class="ltx_ref">xu2024cpo </a></cite> and SimPOÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib35" title="" class="ltx_ref">meng2024simpo </a></cite>.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p class="ltx_p">Recently, the emergence of long-chain-of-thought (CoT)Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib36" title="" class="ltx_ref">wei2022chain </a></cite> reasoning and its integration into both pre-training and post-training processes have significantly advanced the foundational capabilities of LLMs. OpenAI-o1Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib1" title="" class="ltx_ref">jaech2024openaio1 </a></cite> was the first to demonstrate the remarkable potential of combining RL with CoT, enabling LLMs to surpass human cognitive abilities and tackle complex mathematical and coding tasks for the first time.
Shortly thereafter, Deepseek-R1Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib2" title="" class="ltx_ref">guo2025deepseekr1 </a></cite> fully harnessed the potential of RL+CoT through a simple yet highly effective reinforcement learning algorithm GRPOÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib8" title="" class="ltx_ref">shao2024deepseekmath </a></cite>. Their findings revealed that LLMs exhibit human-like â€˜aha momentsâ€™ during RL training.
This achievement quickly garnered significant attention, inspiring extensive replication efforts <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib37" title="" class="ltx_ref">deepscaler2025 </a>; <a href="#bib.bib38" title="" class="ltx_ref">xie2025logic </a>; <a href="#bib.bib39" title="" class="ltx_ref">hu2025open </a>; <a href="#bib.bib40" title="" class="ltx_ref">zeng2025simplerl </a></cite> stimulating further research on enhancing GRPOÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib9" title="" class="ltx_ref">yu2025dapo </a>; <a href="#bib.bib10" title="" class="ltx_ref">liu2025drgrpo </a></cite> and PPOÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib41" title="" class="ltx_ref">yuan2025vapo </a>; <a href="#bib.bib42" title="" class="ltx_ref">shi2025efficient </a></cite>, as well as comparative analyses between the twoÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib11" title="" class="ltx_ref">xiong2025minimalist </a></cite>.
Nevertheless, most existing improvement solutions focus on enhancing sample quality, balancing response length, and preventing entropy collapse.
To the best our knowledge, this work is the first to improve RL training from the gradient-disproportionality perspective.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Preliminary</h2>

<section id="S3.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Large Language Models.</h5>

<div id="S3.SS0.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p">Most existing LLMs are based on a transformer decoder-only architectureÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib43" title="" class="ltx_ref">vaswani2017attention </a></cite>, typically denoted as <math id="S3.SS0.SSS0.Px1.p1.m1" class="ltx_Math" alttext="\pi_{\theta}" display="inline"><semantics><msub><mi>Ï€</mi><mi>Î¸</mi></msub><annotation encoding="application/x-tex">\pi_{\theta}</annotation></semantics></math>, where <math id="S3.SS0.SSS0.Px1.p1.m2" class="ltx_Math" alttext="\theta\in\mathbb{R}^{d}" display="inline"><semantics><mrow><mi>Î¸</mi><mo>âˆˆ</mo><msup><mi>â„</mi><mi>d</mi></msup></mrow><annotation encoding="application/x-tex">\theta\in\mathbb{R}^{d}</annotation></semantics></math> represents the model parameters.
The fundamental unit of LLMs is the token, a discrete textual element that may correspond to a word, subword, or character, and is drawn from a finite vocabulary <math id="S3.SS0.SSS0.Px1.p1.m3" class="ltx_Math" alttext="\mathcal{V}=\{v^{1},\dots,v^{N}\}" display="inline"><semantics><mrow><mi class="ltx_font_mathcaligraphic">ğ’±</mi><mo>=</mo><mrow><mo stretchy="false">{</mo><msup><mi>v</mi><mn>1</mn></msup><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><msup><mi>v</mi><mi>N</mi></msup><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{V}=\{v^{1},\dots,v^{N}\}</annotation></semantics></math>, where <math id="S3.SS0.SSS0.Px1.p1.m4" class="ltx_Math" alttext="N" display="inline"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math> denotes the vocabulary size.
During text generation, the model outputs a probability distribution over the vocabulary, conditioned on the given prompt <math id="S3.SS0.SSS0.Px1.p1.m5" class="ltx_Math" alttext="\bm{q}" display="inline"><semantics><mi>ğ’’</mi><annotation encoding="application/x-tex">\bm{q}</annotation></semantics></math> and the sequence of previously generated tokens <math id="S3.SS0.SSS0.Px1.p1.m6" class="ltx_Math" alttext="\bm{o}_{&lt;t}" display="inline"><semantics><msub><mi>ğ’</mi><mrow><mi></mi><mo>&lt;</mo><mi>t</mi></mrow></msub><annotation encoding="application/x-tex">\bm{o}_{&lt;t}</annotation></semantics></math>.
The next token <math id="S3.SS0.SSS0.Px1.p1.m7" class="ltx_Math" alttext="o_{t}" display="inline"><semantics><msub><mi>o</mi><mi>t</mi></msub><annotation encoding="application/x-tex">o_{t}</annotation></semantics></math> is then sampled from this distribution, expressed mathematically as <math id="S3.SS0.SSS0.Px1.p1.m8" class="ltx_math_unparsed" alttext="o_{t}\sim\pi_{\theta}(\cdot|\bm{q},\bm{o}_{&lt;t})" display="inline"><semantics><mrow><msub><mi>o</mi><mi>t</mi></msub><mo>âˆ¼</mo><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">â‹…</mo><mo fence="false" rspace="0.167em" stretchy="false">|</mo><mi>ğ’’</mi><mo>,</mo><msub><mi>ğ’</mi><mrow><mi></mi><mo>&lt;</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">o_{t}\sim\pi_{\theta}(\cdot|\bm{q},\bm{o}_{&lt;t})</annotation></semantics></math>.
The generation process is autoregressive, proceeding iteratively until either an end-of-sentence (EOS) token is produced or a predefined maximum sequence length <math id="S3.SS0.SSS0.Px1.p1.m9" class="ltx_Math" alttext="t_{max}" display="inline"><semantics><msub><mi>t</mi><mrow><mi>m</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>a</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>x</mi></mrow></msub><annotation encoding="application/x-tex">t_{max}</annotation></semantics></math> is reached. The resulting sequence of tokens is denoted as <math id="S3.SS0.SSS0.Px1.p1.m10" class="ltx_Math" alttext="\bm{o}" display="inline"><semantics><mi>ğ’</mi><annotation encoding="application/x-tex">\bm{o}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS0.SSS0.Px1.p2" class="ltx_para">
<p class="ltx_p">Practical LLMs are often required to align with human preferences or exhibit strong reasoning capabilities, which cannot be easily achieved through naive pre-training and supervised fine-tuning. If a reward function <math id="S3.SS0.SSS0.Px1.p2.m1" class="ltx_Math" alttext="r(\bm{q},\bm{o})" display="inline"><semantics><mrow><mi>r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>ğ’’</mi><mo>,</mo><mi>ğ’</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">r(\bm{q},\bm{o})</annotation></semantics></math> is available to quantitatively capture these objectives, the optimization of an LLM can be formulated as a reinforcement learning task.
In this framework, the generation of each token is treated as an action, while the prompt and the previously generated tokens are treated as the state. Accordingly, the optimization objective of the LLM is expressed as <math id="S3.SS0.SSS0.Px1.p2.m2" class="ltx_Math" alttext="\max_{\theta}\mathbb{E}_{\bm{q}\sim\mathcal{D},\bm{o}\sim\pi_{\theta}}[r(\bm{q},\bm{o})]" display="inline"><semantics><mrow><mrow><msub><mi>max</mi><mi>Î¸</mi></msub><mo lspace="0.167em">â¡</mo><msub><mi>ğ”¼</mi><mrow><mrow><mi>ğ’’</mi><mo>âˆ¼</mo><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi></mrow><mo>,</mo><mrow><mi>ğ’</mi><mo>âˆ¼</mo><msub><mi>Ï€</mi><mi>Î¸</mi></msub></mrow></mrow></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">[</mo><mrow><mi>r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>ğ’’</mi><mo>,</mo><mi>ğ’</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">]</mo></mrow></mrow><annotation encoding="application/x-tex">\max_{\theta}\mathbb{E}_{\bm{q}\sim\mathcal{D},\bm{o}\sim\pi_{\theta}}[r(\bm{q},\bm{o})]</annotation></semantics></math>, where <math id="S3.SS0.SSS0.Px1.p2.m3" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math> is pre-collected dataset.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Group Relative Policy Optimization.</h5>

<div id="S3.SS0.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p">As a widely used algorithm in early-stage research, PPOÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib16" title="" class="ltx_ref">schulman2017ppo </a></cite> requires a value model with as manyâ€”or even moreâ€”parameters as the model being trained.
The value model must be trained in conjunction with LLMs, and its initialization adds complexity and uncertainties to the RL training process.
To address these challenges, DeepSeek introduces GRPOÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib10" title="" class="ltx_ref">liu2025drgrpo </a></cite>, which eliminates the need for a value model entirely by estimating value through group-relative comparison.
Specifically, for each question <math id="S3.SS0.SSS0.Px2.p1.m1" class="ltx_Math" alttext="\bm{q}" display="inline"><semantics><mi>ğ’’</mi><annotation encoding="application/x-tex">\bm{q}</annotation></semantics></math>, GRPO samples a group of outputs <math id="S3.SS0.SSS0.Px2.p1.m2" class="ltx_Math" alttext="\{\bm{o}_{1},\bm{o}_{2},\dots,\bm{o}_{G}\}" display="inline"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>ğ’</mi><mn>1</mn></msub><mo>,</mo><msub><mi>ğ’</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><msub><mi>ğ’</mi><mi>G</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\bm{o}_{1},\bm{o}_{2},\dots,\bm{o}_{G}\}</annotation></semantics></math> and estimate the expected return under the question through <math id="S3.SS0.SSS0.Px2.p1.m3" class="ltx_Math" alttext="V(q)=\mathrm{mean}(r(\bm{q},\bm{o}_{1}),r(\bm{q},\bm{o}_{2}),\dots)" display="inline"><semantics><mrow><mrow><mi>V</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mi>mean</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mrow><mi>r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>ğ’’</mi><mo>,</mo><msub><mi>ğ’</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><mi>r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>ğ’’</mi><mo>,</mo><msub><mi>ğ’</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">V(q)=\mathrm{mean}(r(\bm{q},\bm{o}_{1}),r(\bm{q},\bm{o}_{2}),\dots)</annotation></semantics></math>.
During the training process, the estimated advantage is set to be consistence within each responses (<math id="S3.SS0.SSS0.Px2.p1.m4" class="ltx_Math" alttext="\hat{A}_{i,t}=\hat{A}_{i}" display="inline"><semantics><mrow><msub><mover accent="true"><mi>A</mi><mo>^</mo></mover><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo>=</mo><msub><mover accent="true"><mi>A</mi><mo>^</mo></mover><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\hat{A}_{i,t}=\hat{A}_{i}</annotation></semantics></math>), and is calculated through <math id="S3.SS0.SSS0.Px2.p1.m5" class="ltx_Math" alttext="\hat{A}_{i}=\frac{r(\bm{q},\bm{o}_{i})-V(q)}{\mathrm{std}(r(\bm{q},\bm{o}_{1}),r(\bm{q},\bm{o}_{2}),\dots)}" display="inline"><semantics><mrow><msub><mover accent="true"><mi>A</mi><mo>^</mo></mover><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mrow><mi>r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>ğ’’</mi><mo>,</mo><msub><mi>ğ’</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mrow><mo>âˆ’</mo><mrow><mi>V</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><mrow><mi>std</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mrow><mi>r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>ğ’’</mi><mo>,</mo><msub><mi>ğ’</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><mi>r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>ğ’’</mi><mo>,</mo><msub><mi>ğ’</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo stretchy="false">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">\hat{A}_{i}=\frac{r(\bm{q},\bm{o}_{i})-V(q)}{\mathrm{std}(r(\bm{q},\bm{o}_{1}),r(\bm{q},\bm{o}_{2}),\dots)}</annotation></semantics></math>.
Compared to PPO, GRPO reduces GPU memory overhead by 50% and decreases single-step RL training time by over 60%Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib38" title="" class="ltx_ref">xie2025logic </a></cite>.
In this work, we adopt a variant of GRPO to optimize the policy model <math id="S3.SS0.SSS0.Px2.p1.m6" class="ltx_Math" alttext="\pi_{\theta}" display="inline"><semantics><msub><mi>Ï€</mi><mi>Î¸</mi></msub><annotation encoding="application/x-tex">\pi_{\theta}</annotation></semantics></math>. The optimization objective is expressed as follows:</p>
</div>
<div id="S3.SS0.SSS0.Px2.p2" class="ltx_para">
<table id="S3.E1" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S3.E1X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E1X.m2" class="ltx_Math" alttext="\displaystyle J_{GRPO}(\theta)" display="inline"><semantics><mrow><msub><mi mathsize="0.800em">J</mi><mrow><mi mathsize="0.800em">G</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">R</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">P</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">O</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mi mathsize="0.800em">Î¸</mi><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><annotation encoding="application/x-tex">\displaystyle J_{GRPO}(\theta)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E1X.m3" class="ltx_Math" alttext="\displaystyle=\mathbb{E}_{\bm{q}\sim\mathcal{D},\{\bm{o}_{i}\}_{i=1}^{G}\sim\pi_{old}}" display="inline"><semantics><mrow><mi></mi><mo mathsize="0.800em">=</mo><msub><mi mathsize="0.800em">ğ”¼</mi><mrow><mrow><mi mathsize="0.800em">ğ’’</mi><mo mathsize="0.800em">âˆ¼</mo><mi class="ltx_font_mathcaligraphic" mathsize="0.800em">ğ’Ÿ</mi></mrow><mo mathsize="0.800em">,</mo><mrow><msubsup><mrow><mo maxsize="0.800em" minsize="0.800em">{</mo><msub><mi mathsize="0.800em">ğ’</mi><mi mathsize="0.800em">i</mi></msub><mo maxsize="0.800em" minsize="0.800em">}</mo></mrow><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">=</mo><mn mathsize="0.800em">1</mn></mrow><mi mathsize="0.800em">G</mi></msubsup><mo mathsize="0.800em">âˆ¼</mo><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">d</mi></mrow></msub></mrow></mrow></msub></mrow><annotation encoding="application/x-tex">\displaystyle=\mathbb{E}_{\bm{q}\sim\mathcal{D},\{\bm{o}_{i}\}_{i=1}^{G}\sim\pi_{old}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="3" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(1)</span></td>
</tr>
<tr id="S3.E1Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E1Xa.m2" class="ltx_Math" alttext="\displaystyle\frac{1}{\sum_{i=1}^{G}|\bm{o}_{i}|}\sum_{i=1}^{G}\sum_{t=1}^{|\bm{o}_{i}|}\left\{\min\left[r_{i,t}(\theta)\hat{A}_{i,t},\mathrm{clip}(r_{i,t}(\theta);1-\epsilon_{l},1+\epsilon_{h})\hat{A}_{i,t}\right]-\beta\,\mathbb{D}_{\mathrm{KL}}\left[\pi_{\theta}\|\pi_{ref}\right]\right\}" display="inline"><semantics><mrow><mstyle displaystyle="true"><mfrac><mn mathsize="0.800em">1</mn><mrow><msubsup><mo maxsize="0.800em" minsize="0.800em" stretchy="true">âˆ‘</mo><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">=</mo><mn mathsize="0.800em">1</mn></mrow><mi mathsize="0.800em">G</mi></msubsup><mrow><mo lspace="0em" maxsize="0.800em" minsize="0.800em" stretchy="true">|</mo><msub><mi mathsize="0.800em">ğ’</mi><mi mathsize="0.800em">i</mi></msub><mo maxsize="0.800em" minsize="0.800em" stretchy="true">|</mo></mrow></mrow></mfrac></mstyle><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mstyle displaystyle="true"><munderover><mo maxsize="0.800em" minsize="0.800em" movablelimits="false" stretchy="true">âˆ‘</mo><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">=</mo><mn mathsize="0.800em">1</mn></mrow><mi mathsize="0.800em">G</mi></munderover></mstyle><mrow><mstyle displaystyle="true"><munderover><mo maxsize="0.800em" minsize="0.800em" movablelimits="false" stretchy="true">âˆ‘</mo><mrow><mi mathsize="0.800em">t</mi><mo mathsize="0.800em">=</mo><mn mathsize="0.800em">1</mn></mrow><mrow><mo maxsize="0.800em" minsize="0.800em" stretchy="true">|</mo><msub><mi mathsize="0.800em">ğ’</mi><mi mathsize="0.800em">i</mi></msub><mo maxsize="0.800em" minsize="0.800em" stretchy="true">|</mo></mrow></munderover></mstyle><mrow><mo>{</mo><mrow><mrow><mi mathsize="0.800em">min</mi><mo>â¡</mo><mrow><mo>[</mo><mrow><msub><mi mathsize="0.800em">r</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mi mathsize="0.800em">Î¸</mi><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow><mo lspace="0em" rspace="0em">â€‹</mo><msub><mover accent="true"><mi mathsize="0.800em">A</mi><mo mathsize="0.800em">^</mo></mover><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub></mrow><mo mathsize="0.800em">,</mo><mrow><mi mathsize="0.800em">clip</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mrow><msub><mi mathsize="0.800em">r</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mi mathsize="0.800em">Î¸</mi><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mo mathsize="0.800em">;</mo><mrow><mn mathsize="0.800em">1</mn><mo mathsize="0.800em">âˆ’</mo><msub><mi mathsize="0.800em">Ïµ</mi><mi mathsize="0.800em">l</mi></msub></mrow><mo mathsize="0.800em">,</mo><mrow><mn mathsize="0.800em">1</mn><mo mathsize="0.800em">+</mo><msub><mi mathsize="0.800em">Ïµ</mi><mi mathsize="0.800em">h</mi></msub></mrow><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow><mo lspace="0em" rspace="0em">â€‹</mo><msub><mover accent="true"><mi mathsize="0.800em">A</mi><mo mathsize="0.800em">^</mo></mover><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub></mrow><mo>]</mo></mrow></mrow><mo mathsize="0.800em">âˆ’</mo><mrow><mi mathsize="0.800em">Î²</mi><mo lspace="0.170em" rspace="0em">â€‹</mo><msub><mi mathsize="0.800em">ğ”»</mi><mi mathsize="0.800em">KL</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo>[</mo><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo mathsize="0.800em">âˆ¥</mo><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">f</mi></mrow></msub></mrow><mo>]</mo></mrow></mrow></mrow><mo>}</mo></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\frac{1}{\sum_{i=1}^{G}|\bm{o}_{i}|}\sum_{i=1}^{G}\sum_{t=1}^{|\bm{o}_{i}|}\left\{\min\left[r_{i,t}(\theta)\hat{A}_{i,t},\mathrm{clip}(r_{i,t}(\theta);1-\epsilon_{l},1+\epsilon_{h})\hat{A}_{i,t}\right]-\beta\,\mathbb{D}_{\mathrm{KL}}\left[\pi_{\theta}\|\pi_{ref}\right]\right\}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="S3.E1Xb" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E1Xb.m2" class="ltx_Math" alttext="\displaystyle\mathrm{with}\,\,r_{i,t}(\theta)" display="inline"><semantics><mrow><mi mathsize="0.800em">with</mi><mo lspace="0.330em" rspace="0em">â€‹</mo><msub><mi mathsize="0.800em">r</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mi mathsize="0.800em">Î¸</mi><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\mathrm{with}\,\,r_{i,t}(\theta)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E1Xb.m3" class="ltx_Math" alttext="\displaystyle\!=\!\frac{\pi_{\theta}(o_{i,t}|\bm{q},\bm{o}_{i,&lt;t})}{\pi_{old}(o_{i,t}|\bm{q},\bm{o}_{i,&lt;t})},\mathrm{and}\,\,\mathbb{D}_{\mathrm{KL}}\left[\pi_{\theta}\|\pi_{ref}\right]\!=\!\frac{\pi_{ref}(o_{i,t}|\bm{q},\bm{o}_{i,&lt;t})}{\pi_{\theta}(o_{i,t}|\bm{q},\bm{o}_{i,&lt;t})}\!-\!\log\frac{\pi_{ref}(o_{i,t}|\bm{q},\bm{o}_{i,&lt;t})}{\pi_{\theta}(o_{i,t}|\bm{q},\bm{o}_{i,&lt;t})}\!-\!1," display="inline"><semantics><mrow><mrow><mrow><mi></mi><mo lspace="0.108em" mathsize="0.800em" rspace="0.108em">=</mo><mstyle displaystyle="true"><mfrac><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mrow><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo fence="false" mathsize="0.800em">|</mo><mrow><mi mathsize="0.800em">ğ’’</mi><mo mathsize="0.800em">,</mo><msub><mi mathsize="0.800em">ğ’</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mrow><mi></mi><mo mathsize="0.800em">&lt;</mo><mi mathsize="0.800em">t</mi></mrow></mrow></msub></mrow></mrow><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mrow><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mrow><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo fence="false" mathsize="0.800em">|</mo><mrow><mi mathsize="0.800em">ğ’’</mi><mo mathsize="0.800em">,</mo><msub><mi mathsize="0.800em">ğ’</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mrow><mi></mi><mo mathsize="0.800em">&lt;</mo><mi mathsize="0.800em">t</mi></mrow></mrow></msub></mrow></mrow><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow></mfrac></mstyle></mrow><mo mathsize="0.800em">,</mo><mrow><mrow><mi mathsize="0.800em">and</mi><mo lspace="0.330em" rspace="0em">â€‹</mo><msub><mi mathsize="0.800em">ğ”»</mi><mi mathsize="0.800em">KL</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo>[</mo><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo mathsize="0.800em">âˆ¥</mo><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">f</mi></mrow></msub></mrow><mo>]</mo></mrow></mrow><mo lspace="0.108em" mathsize="0.800em" rspace="0.108em">=</mo><mrow><mstyle displaystyle="true"><mfrac><mrow><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">f</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mrow><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo fence="false" mathsize="0.800em">|</mo><mrow><mi mathsize="0.800em">ğ’’</mi><mo mathsize="0.800em">,</mo><msub><mi mathsize="0.800em">ğ’</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mrow><mi></mi><mo mathsize="0.800em">&lt;</mo><mi mathsize="0.800em">t</mi></mrow></mrow></msub></mrow></mrow><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mrow><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo fence="false" mathsize="0.800em">|</mo><mrow><mi mathsize="0.800em">ğ’’</mi><mo mathsize="0.800em">,</mo><msub><mi mathsize="0.800em">ğ’</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mrow><mi></mi><mo mathsize="0.800em">&lt;</mo><mi mathsize="0.800em">t</mi></mrow></mrow></msub></mrow></mrow><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow></mfrac></mstyle><mo lspace="0.052em" mathsize="0.800em" rspace="0.052em">âˆ’</mo><mrow><mi mathsize="0.800em">log</mi><mo lspace="0.167em">â¡</mo><mstyle displaystyle="true"><mfrac><mrow><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">f</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mrow><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo fence="false" mathsize="0.800em">|</mo><mrow><mi mathsize="0.800em">ğ’’</mi><mo mathsize="0.800em">,</mo><msub><mi mathsize="0.800em">ğ’</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mrow><mi></mi><mo mathsize="0.800em">&lt;</mo><mi mathsize="0.800em">t</mi></mrow></mrow></msub></mrow></mrow><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mrow><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo fence="false" mathsize="0.800em">|</mo><mrow><mi mathsize="0.800em">ğ’’</mi><mo mathsize="0.800em">,</mo><msub><mi mathsize="0.800em">ğ’</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mrow><mi></mi><mo mathsize="0.800em">&lt;</mo><mi mathsize="0.800em">t</mi></mrow></mrow></msub></mrow></mrow><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow></mfrac></mstyle></mrow><mo lspace="0.052em" mathsize="0.800em" rspace="0.052em">âˆ’</mo><mn mathsize="0.800em">1</mn></mrow></mrow></mrow><mo mathsize="0.800em">,</mo></mrow><annotation encoding="application/x-tex">\displaystyle\!=\!\frac{\pi_{\theta}(o_{i,t}|\bm{q},\bm{o}_{i,&lt;t})}{\pi_{old}(o_{i,t}|\bm{q},\bm{o}_{i,&lt;t})},\mathrm{and}\,\,\mathbb{D}_{\mathrm{KL}}\left[\pi_{\theta}\|\pi_{ref}\right]\!=\!\frac{\pi_{ref}(o_{i,t}|\bm{q},\bm{o}_{i,&lt;t})}{\pi_{\theta}(o_{i,t}|\bm{q},\bm{o}_{i,&lt;t})}\!-\!\log\frac{\pi_{ref}(o_{i,t}|\bm{q},\bm{o}_{i,&lt;t})}{\pi_{\theta}(o_{i,t}|\bm{q},\bm{o}_{i,&lt;t})}\!-\!1,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
</div>
<div id="S3.SS0.SSS0.Px2.p3" class="ltx_para">
<p class="ltx_p">where <math id="S3.SS0.SSS0.Px2.p3.m1" class="ltx_Math" alttext="\pi_{old}" display="inline"><semantics><msub><mi>Ï€</mi><mrow><mi>o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>d</mi></mrow></msub><annotation encoding="application/x-tex">\pi_{old}</annotation></semantics></math> denotes the policy used to sample the responses, <math id="S3.SS0.SSS0.Px2.p3.m2" class="ltx_Math" alttext="\pi_{ref}" display="inline"><semantics><msub><mi>Ï€</mi><mrow><mi>r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>f</mi></mrow></msub><annotation encoding="application/x-tex">\pi_{ref}</annotation></semantics></math> represents the initial policy prior to RL training, and <math id="S3.SS0.SSS0.Px2.p3.m3" class="ltx_Math" alttext="\epsilon_{l},\epsilon_{h},\beta" display="inline"><semantics><mrow><msub><mi>Ïµ</mi><mi>l</mi></msub><mo>,</mo><msub><mi>Ïµ</mi><mi>h</mi></msub><mo>,</mo><mi>Î²</mi></mrow><annotation encoding="application/x-tex">\epsilon_{l},\epsilon_{h},\beta</annotation></semantics></math> are manually defined hyperparameters.
Note that the original implementation of GRPO normalizes the token update weights based on the response length, which introduces a significant bias toward shorter responses during updates.
In line with verlÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib44" title="" class="ltx_ref">sheng2024verl </a></cite> and most follow-up workÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib40" title="" class="ltx_ref">zeng2025simplerl </a>; <a href="#bib.bib10" title="" class="ltx_ref">liu2025drgrpo </a></cite>, we remove this operation and conduct normalization among all tokens within the same query-batch.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Methodology</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Explanation on Low-Probability Tokensâ€™ Dominance</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p class="ltx_p">In this section, we provide a theoretical explanation for why tokens with lower probabilities tend to dominate updates during RL training.
The learning objective in Eq.Â (<a href="#S3.E1" title="In Group Relative Policy Optimization. â€£ 3 Preliminary â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) can be interpreted as a weighted cross-entropy loss.
For simplicity, we use the notation <math id="S4.SS1.p1.m1" class="ltx_Math" alttext="\pi(o_{i,t})" display="inline"><semantics><mrow><mi>Ï€</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\pi(o_{i,t})</annotation></semantics></math> to denote <math id="S4.SS1.p1.m2" class="ltx_Math" alttext="\pi(o_{i,t}|\bm{q},\bm{o}_{i,&lt;t})" display="inline"><semantics><mrow><mi>Ï€</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mrow><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo fence="false">|</mo><mrow><mi>ğ’’</mi><mo>,</mo><msub><mi>ğ’</mi><mrow><mi>i</mi><mo>,</mo><mrow><mi></mi><mo>&lt;</mo><mi>t</mi></mrow></mrow></msub></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\pi(o_{i,t}|\bm{q},\bm{o}_{i,&lt;t})</annotation></semantics></math>.
By evaluating the gradient, we obtain the following expression (cf. AppendixÂ <a href="#A1.SS1" title="A.1 Gradient Derivation for the GRPO Objective â€£ Appendix A Theoretical Interpretations â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.1</span></a> for derivation):</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<table id="S4.E2" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S4.E2X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E2X.m2" class="ltx_Math" alttext="\displaystyle\nabla_{\theta}J_{GRPO}(\theta)" display="inline"><semantics><mrow><mrow><msub><mo mathsize="0.800em">âˆ‡</mo><mi mathsize="0.800em">Î¸</mi></msub><msub><mi mathsize="0.800em">J</mi><mrow><mi mathsize="0.800em">G</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">R</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">P</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">O</mi></mrow></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mi mathsize="0.800em">Î¸</mi><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\nabla_{\theta}J_{GRPO}(\theta)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.E2X.m3" class="ltx_Math" alttext="\displaystyle=\mathbb{E}_{\bm{q}\sim\mathcal{D},\{\bm{o}_{i}\}_{i=1}^{G}\sim\pi_{old}}\frac{1}{\sum_{i=1}^{G}|\bm{o}_{i}|}\sum_{i=1}^{G}\sum_{t=1}^{|\bm{o}_{i}|}" display="inline"><semantics><mrow><mi></mi><mo mathsize="0.800em">=</mo><mrow><msub><mi mathsize="0.800em">ğ”¼</mi><mrow><mrow><mi mathsize="0.800em">ğ’’</mi><mo mathsize="0.800em">âˆ¼</mo><mi class="ltx_font_mathcaligraphic" mathsize="0.800em">ğ’Ÿ</mi></mrow><mo mathsize="0.800em">,</mo><mrow><msubsup><mrow><mo maxsize="0.800em" minsize="0.800em">{</mo><msub><mi mathsize="0.800em">ğ’</mi><mi mathsize="0.800em">i</mi></msub><mo maxsize="0.800em" minsize="0.800em">}</mo></mrow><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">=</mo><mn mathsize="0.800em">1</mn></mrow><mi mathsize="0.800em">G</mi></msubsup><mo mathsize="0.800em">âˆ¼</mo><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">d</mi></mrow></msub></mrow></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mstyle displaystyle="true"><mfrac><mn mathsize="0.800em">1</mn><mrow><msubsup><mo maxsize="0.800em" minsize="0.800em" stretchy="true">âˆ‘</mo><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">=</mo><mn mathsize="0.800em">1</mn></mrow><mi mathsize="0.800em">G</mi></msubsup><mrow><mo lspace="0em" maxsize="0.800em" minsize="0.800em" stretchy="true">|</mo><msub><mi mathsize="0.800em">ğ’</mi><mi mathsize="0.800em">i</mi></msub><mo maxsize="0.800em" minsize="0.800em" stretchy="true">|</mo></mrow></mrow></mfrac></mstyle><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mstyle displaystyle="true"><munderover><mo maxsize="0.800em" minsize="0.800em" movablelimits="false" stretchy="true">âˆ‘</mo><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">=</mo><mn mathsize="0.800em">1</mn></mrow><mi mathsize="0.800em">G</mi></munderover></mstyle><mstyle displaystyle="true"><munderover><mo maxsize="0.800em" minsize="0.800em" movablelimits="false" stretchy="true">âˆ‘</mo><mrow><mi mathsize="0.800em">t</mi><mo mathsize="0.800em">=</mo><mn mathsize="0.800em">1</mn></mrow><mrow><mo maxsize="0.800em" minsize="0.800em" stretchy="true">|</mo><msub><mi mathsize="0.800em">ğ’</mi><mi mathsize="0.800em">i</mi></msub><mo maxsize="0.800em" minsize="0.800em" stretchy="true">|</mo></mrow></munderover></mstyle></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=\mathbb{E}_{\bm{q}\sim\mathcal{D},\{\bm{o}_{i}\}_{i=1}^{G}\sim\pi_{old}}\frac{1}{\sum_{i=1}^{G}|\bm{o}_{i}|}\sum_{i=1}^{G}\sum_{t=1}^{|\bm{o}_{i}|}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="3" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(2)</span></td>
</tr>
<tr id="S4.E2Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.E2Xa.m2" class="ltx_Math" alttext="\displaystyle\underbrace{\left[\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})}\hat{A}_{i,t}\cdot\mathbb{I}_{\mathrm{trust}}(\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})},\hat{A}_{i,t})+\beta\frac{\pi_{ref}(o_{i,t})}{\pi_{\theta}(o_{i,t})}-\beta\right]}_{w_{i,t}}\cdot\nabla_{\theta}\log\pi_{\theta}(o_{i,t})," display="inline"><semantics><mrow><mrow><mrow><munder><munder accentunder="true"><mrow><mo>[</mo><mrow><mrow><mrow><mrow><mrow><mstyle displaystyle="true"><mfrac><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mrow><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow></mfrac></mstyle><mo lspace="0em" rspace="0em">â€‹</mo><msub><mover accent="true"><mi mathsize="0.800em">A</mi><mo mathsize="0.800em">^</mo></mover><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub></mrow><mo lspace="0.222em" mathsize="0.800em" rspace="0.222em">â‹…</mo><msub><mi mathsize="0.800em">ğ•€</mi><mi mathsize="0.800em">trust</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mstyle displaystyle="true"><mfrac><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mrow><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow></mfrac></mstyle><mo mathsize="0.800em">,</mo><msub><mover accent="true"><mi mathsize="0.800em">A</mi><mo mathsize="0.800em">^</mo></mover><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mo mathsize="0.800em">+</mo><mrow><mi mathsize="0.800em">Î²</mi><mo lspace="0em" rspace="0em">â€‹</mo><mstyle displaystyle="true"><mfrac><mrow><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">f</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow></mfrac></mstyle></mrow></mrow><mo mathsize="0.800em">âˆ’</mo><mi mathsize="0.800em">Î²</mi></mrow><mo>]</mo></mrow><mo stretchy="true">âŸ</mo></munder><msub><mi mathsize="0.800em">w</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub></munder><mo lspace="0.222em" mathsize="0.800em" rspace="0.222em">â‹…</mo><mrow><mrow><msub><mo mathsize="0.800em" rspace="0.167em">âˆ‡</mo><mi mathsize="0.800em">Î¸</mi></msub><mi mathsize="0.800em">log</mi></mrow><mo lspace="0.167em">â¡</mo><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub></mrow></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mo mathsize="0.800em">,</mo></mrow><annotation encoding="application/x-tex">\displaystyle\underbrace{\left[\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})}\hat{A}_{i,t}\cdot\mathbb{I}_{\mathrm{trust}}(\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})},\hat{A}_{i,t})+\beta\frac{\pi_{ref}(o_{i,t})}{\pi_{\theta}(o_{i,t})}-\beta\right]}_{w_{i,t}}\cdot\nabla_{\theta}\log\pi_{\theta}(o_{i,t}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="S4.E2Xb" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E2Xb.m2" class="ltx_Math" alttext="\displaystyle\mathrm{where}\,\,\mathbb{I}_{\mathrm{trust}}" display="inline"><semantics><mrow><mi mathsize="0.800em">where</mi><mo lspace="0.330em" rspace="0em">â€‹</mo><msub><mi mathsize="0.800em">ğ•€</mi><mi mathsize="0.800em">trust</mi></msub></mrow><annotation encoding="application/x-tex">\displaystyle\mathrm{where}\,\,\mathbb{I}_{\mathrm{trust}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.E2Xb.m3" class="ltx_Math" alttext="\displaystyle(\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})},\hat{A}_{i,t})=\left\{\begin{array}[]{ll}0&amp;\left\{\begin{array}[]{l}\mathrm{if}\,\,\hat{A}_{i,t}&gt;0\,\,\mathrm{and}\,\,\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})}&gt;1+\epsilon_{h}\\
\mathrm{if}\,\,\hat{A}_{i,t}&lt;0\,\,\mathrm{and}\,\,\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})}&lt;1-\epsilon_{l}\end{array}\right.\\
1&amp;\mathrm{otherwise}\end{array}\right.." display="inline"><semantics><mrow><mrow><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mstyle displaystyle="true"><mfrac><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mrow><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow></mfrac></mstyle><mo mathsize="0.800em">,</mo><msub><mover accent="true"><mi mathsize="0.800em">A</mi><mo mathsize="0.800em">^</mo></mover><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow><mo mathsize="0.800em">=</mo><mrow><mo>{</mo><mtable columnspacing="5pt" rowspacing="0pt"><mtr><mtd class="ltx_align_left" columnalign="left"><mn mathsize="0.800em">0</mn></mtd><mtd class="ltx_align_left" columnalign="left"><mrow><mo>{</mo><mtable rowspacing="0pt"><mtr><mtd class="ltx_align_left" columnalign="left"><mrow><mrow><mi mathsize="0.800em">if</mi><mo lspace="0.330em" rspace="0em">â€‹</mo><msub><mover accent="true"><mi mathsize="0.800em">A</mi><mo mathsize="0.800em">^</mo></mover><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub></mrow><mo mathsize="0.800em">&gt;</mo><mrow><mn mathsize="0.800em">0</mn><mo lspace="0.330em" rspace="0em">â€‹</mo><mi mathsize="0.800em">and</mi><mo lspace="0.330em" rspace="0em">â€‹</mo><mfrac><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mrow><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow></mfrac></mrow><mo mathsize="0.800em">&gt;</mo><mrow><mn mathsize="0.800em">1</mn><mo mathsize="0.800em">+</mo><msub><mi mathsize="0.800em">Ïµ</mi><mi mathsize="0.800em">h</mi></msub></mrow></mrow></mtd></mtr><mtr><mtd class="ltx_align_left" columnalign="left"><mrow><mrow><mi mathsize="0.800em">if</mi><mo lspace="0.330em" rspace="0em">â€‹</mo><msub><mover accent="true"><mi mathsize="0.800em">A</mi><mo mathsize="0.800em">^</mo></mover><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub></mrow><mo mathsize="0.800em">&lt;</mo><mrow><mn mathsize="0.800em">0</mn><mo lspace="0.330em" rspace="0em">â€‹</mo><mi mathsize="0.800em">and</mi><mo lspace="0.330em" rspace="0em">â€‹</mo><mfrac><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mrow><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow></mfrac></mrow><mo mathsize="0.800em">&lt;</mo><mrow><mn mathsize="0.800em">1</mn><mo mathsize="0.800em">âˆ’</mo><msub><mi mathsize="0.800em">Ïµ</mi><mi mathsize="0.800em">l</mi></msub></mrow></mrow></mtd></mtr></mtable><mi></mi></mrow></mtd></mtr><mtr><mtd class="ltx_align_left" columnalign="left"><mn mathsize="0.800em">1</mn></mtd><mtd class="ltx_align_left" columnalign="left"><mi mathsize="0.800em">otherwise</mi></mtd></mtr></mtable><mi></mi></mrow></mrow><mo lspace="0em" mathsize="0.800em">.</mo></mrow><annotation encoding="application/x-tex">\displaystyle(\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})},\hat{A}_{i,t})=\left\{\begin{array}[]{ll}0&amp;\left\{\begin{array}[]{l}\mathrm{if}\,\,\hat{A}_{i,t}&gt;0\,\,\mathrm{and}\,\,\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})}&gt;1+\epsilon_{h}\\
\mathrm{if}\,\,\hat{A}_{i,t}&lt;0\,\,\mathrm{and}\,\,\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})}&lt;1-\epsilon_{l}\end{array}\right.\\
1&amp;\mathrm{otherwise}\end{array}\right..</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p class="ltx_p">We represent LLM as a composite function <math id="S4.SS1.p3.m1" class="ltx_Math" alttext="f=f_{L}\circ f_{L-1}\circ\cdots\circ f_{1}" display="inline"><semantics><mrow><mi>f</mi><mo>=</mo><mrow><msub><mi>f</mi><mi>L</mi></msub><mo lspace="0.222em" rspace="0.222em">âˆ˜</mo><msub><mi>f</mi><mrow><mi>L</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo lspace="0.222em" rspace="0.222em">âˆ˜</mo><mi mathvariant="normal">â‹¯</mi><mo lspace="0.222em" rspace="0.222em">âˆ˜</mo><msub><mi>f</mi><mn>1</mn></msub></mrow></mrow><annotation encoding="application/x-tex">f=f_{L}\circ f_{L-1}\circ\cdots\circ f_{1}</annotation></semantics></math>, where each <math id="S4.SS1.p3.m2" class="ltx_Math" alttext="f_{\ell}" display="inline"><semantics><msub><mi>f</mi><mi mathvariant="normal">â„“</mi></msub><annotation encoding="application/x-tex">f_{\ell}</annotation></semantics></math> (with <math id="S4.SS1.p3.m3" class="ltx_Math" alttext="\ell\in\{1,\dots,L\}" display="inline"><semantics><mrow><mi mathvariant="normal">â„“</mi><mo>âˆˆ</mo><mrow><mo stretchy="false">{</mo><mn>1</mn><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><mi>L</mi><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">\ell\in\{1,\dots,L\}</annotation></semantics></math>) corresponds to a distinct layer of the network.
Let <math id="S4.SS1.p3.m4" class="ltx_Math" alttext="a_{\ell-1}" display="inline"><semantics><msub><mi>a</mi><mrow><mi mathvariant="normal">â„“</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">a_{\ell-1}</annotation></semantics></math> denote the input and <math id="S4.SS1.p3.m5" class="ltx_Math" alttext="a_{\ell}" display="inline"><semantics><msub><mi>a</mi><mi mathvariant="normal">â„“</mi></msub><annotation encoding="application/x-tex">a_{\ell}</annotation></semantics></math> denotes the output of <math id="S4.SS1.p3.m6" class="ltx_Math" alttext="\ell" display="inline"><semantics><mi mathvariant="normal">â„“</mi><annotation encoding="application/x-tex">\ell</annotation></semantics></math>th layer.
We further define the Jacobian matrix of the <math id="S4.SS1.p3.m7" class="ltx_Math" alttext="\ell" display="inline"><semantics><mi mathvariant="normal">â„“</mi><annotation encoding="application/x-tex">\ell</annotation></semantics></math>th layer with respect to its input as <math id="S4.SS1.p3.m8" class="ltx_Math" alttext="J_{\ell}:=\frac{\partial f_{\ell}(a_{\ell-1})}{\partial a_{\ell-1}}" display="inline"><semantics><mrow><msub><mi>J</mi><mi mathvariant="normal">â„“</mi></msub><mo>:=</mo><mfrac><mrow><mo rspace="0em">âˆ‚</mo><mrow><msub><mi>f</mi><mi mathvariant="normal">â„“</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>a</mi><mrow><mi mathvariant="normal">â„“</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mrow><mo rspace="0em">âˆ‚</mo><msub><mi>a</mi><mrow><mi mathvariant="normal">â„“</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">J_{\ell}:=\frac{\partial f_{\ell}(a_{\ell-1})}{\partial a_{\ell-1}}</annotation></semantics></math>.</p>
</div>
<div id="S4.Thmtheorem1" class="ltx_theorem ltx_theorem_assumption">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span class="ltx_text ltx_font_bold">Assumption 4.1</span></span><span class="ltx_text ltx_font_bold">.</span>
</h6>
<div id="S4.Thmtheorem1.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">For every layer, the Jacobian <math id="S4.Thmtheorem1.p1.m1" class="ltx_Math" alttext="J_{\ell}" display="inline"><semantics><msub><mi>J</mi><mi mathvariant="normal">â„“</mi></msub><annotation encoding="application/x-tex">J_{\ell}</annotation></semantics></math> is well-defined and the <math id="S4.Thmtheorem1.p1.m2" class="ltx_Math" alttext="f_{\ell}" display="inline"><semantics><msub><mi>f</mi><mi mathvariant="normal">â„“</mi></msub><annotation encoding="application/x-tex">f_{\ell}</annotation></semantics></math> is locally differentiable. Furthermore, assume that for each layer, there exist two constants <math id="S4.Thmtheorem1.p1.m3" class="ltx_Math" alttext="c_{\ell}&gt;0" display="inline"><semantics><mrow><msub><mi>c</mi><mi mathvariant="normal">â„“</mi></msub><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">c_{\ell}&gt;0</annotation></semantics></math> and <math id="S4.Thmtheorem1.p1.m4" class="ltx_Math" alttext="d_{\ell}&gt;0" display="inline"><semantics><mrow><msub><mi>d</mi><mi mathvariant="normal">â„“</mi></msub><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">d_{\ell}&gt;0</annotation></semantics></math> such that <math id="S4.Thmtheorem1.p1.m5" class="ltx_Math" alttext="\sigma_{\min}(J_{\ell})\geq c_{\ell}" display="inline"><semantics><mrow><mrow><msub><mi>Ïƒ</mi><mi>min</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>J</mi><mi mathvariant="normal">â„“</mi></msub><mo stretchy="false">)</mo></mrow></mrow><mo>â‰¥</mo><msub><mi>c</mi><mi mathvariant="normal">â„“</mi></msub></mrow><annotation encoding="application/x-tex">\sigma_{\min}(J_{\ell})\geq c_{\ell}</annotation></semantics></math> and <math id="S4.Thmtheorem1.p1.m6" class="ltx_Math" alttext="\sigma_{\max}(J_{\ell})\leq d_{\ell}" display="inline"><semantics><mrow><mrow><msub><mi>Ïƒ</mi><mi>max</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>J</mi><mi mathvariant="normal">â„“</mi></msub><mo stretchy="false">)</mo></mrow></mrow><mo>â‰¤</mo><msub><mi>d</mi><mi mathvariant="normal">â„“</mi></msub></mrow><annotation encoding="application/x-tex">\sigma_{\max}(J_{\ell})\leq d_{\ell}</annotation></semantics></math>, where <math id="S4.Thmtheorem1.p1.m7" class="ltx_Math" alttext="\sigma_{\min}(\cdot)" display="inline"><semantics><mrow><msub><mi>Ïƒ</mi><mi>min</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">â‹…</mo><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\sigma_{\min}(\cdot)</annotation></semantics></math> and <math id="S4.Thmtheorem1.p1.m8" class="ltx_Math" alttext="\sigma_{\max}(\cdot)" display="inline"><semantics><mrow><msub><mi>Ïƒ</mi><mi>max</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">â‹…</mo><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\sigma_{\max}(\cdot)</annotation></semantics></math> denote the minimum and maximum singular values of the given matrix, respectively.
</span></p>
</div>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p class="ltx_p">AssumptionÂ <a href="#S4.Thmtheorem1" title="Assumption 4.1. â€£ 4.1 Explanation on Low-Probability Tokensâ€™ Dominance â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a> is not restrictive, as it aligns with the standard design and training principles of neural-networks, ensuring stable gradients flow through well-defined and non-degenerate Jacobians.</p>
</div>
<div id="S4.Thmtheorem2" class="ltx_theorem ltx_theorem_proposition">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span class="ltx_text ltx_font_bold">Proposition 4.2</span></span><span class="ltx_text ltx_font_bold">.</span>
</h6>
<div id="S4.Thmtheorem2.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">Under AssumptionÂ <a href="#S4.Thmtheorem1" title="Assumption 4.1. â€£ 4.1 Explanation on Low-Probability Tokensâ€™ Dominance â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>, let <math id="S4.Thmtheorem2.p1.m1" class="ltx_Math" alttext="\delta_{\ell}(o_{i,t}):=\nabla_{a_{\ell}}J_{GRPO}(o_{i,t})" display="inline"><semantics><mrow><mrow><msub><mi>Î´</mi><mi mathvariant="normal">â„“</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo>:=</mo><mrow><mrow><msub><mo rspace="0.167em">âˆ‡</mo><msub><mi>a</mi><mi mathvariant="normal">â„“</mi></msub></msub><msub><mi>J</mi><mrow><mi>G</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>R</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>P</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>O</mi></mrow></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\delta_{\ell}(o_{i,t}):=\nabla_{a_{\ell}}J_{GRPO}(o_{i,t})</annotation></semantics></math> denote the gradient of the GRPO objective with respect to activation <math id="S4.Thmtheorem2.p1.m2" class="ltx_Math" alttext="a_{\ell}" display="inline"><semantics><msub><mi>a</mi><mi mathvariant="normal">â„“</mi></msub><annotation encoding="application/x-tex">a_{\ell}</annotation></semantics></math> at any layer for a single token <math id="S4.Thmtheorem2.p1.m3" class="ltx_Math" alttext="o_{i,t}" display="inline"><semantics><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><annotation encoding="application/x-tex">o_{i,t}</annotation></semantics></math>. Let <math id="S4.Thmtheorem2.p1.m4" class="ltx_math_unparsed" alttext="\|\cdot\|" display="inline"><semantics><mrow><mo rspace="0em">âˆ¥</mo><mo lspace="0em" rspace="0em">â‹…</mo><mo lspace="0em">âˆ¥</mo></mrow><annotation encoding="application/x-tex">\|\cdot\|</annotation></semantics></math> denote the spectral norm, and define the vocabulary size as <math id="S4.Thmtheorem2.p1.m5" class="ltx_Math" alttext="N" display="inline"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>. Then, for each layer <math id="S4.Thmtheorem2.p1.m6" class="ltx_Math" alttext="\ell" display="inline"><semantics><mi mathvariant="normal">â„“</mi><annotation encoding="application/x-tex">\ell</annotation></semantics></math>, the following inequalities always hold:</span></p>
<table id="S4.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E3.m1" class="ltx_Math" alttext="\prod_{j=\ell+1}^{L}c_{j}\cdot|w_{i,t}|\cdot\sqrt{\frac{N}{N-1}}\cdot{\color[rgb]{0,0,1}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,1}\big{(}1-\pi_{\theta}(o_{i,t})\big{)}}\leq{\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}\|\delta_{\ell}(o_{i,t})\|}\leq\prod_{j=\ell+1}^{L}d_{j}\cdot|w_{i,t}|\cdot\sqrt{2}\cdot{\color[rgb]{0,0,1}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,1}\big{(}1-\pi_{\theta}(o_{i,t})\big{)}}." display="block"><semantics><mrow><mrow><mrow><munderover><mo movablelimits="false">âˆ</mo><mrow><mi>j</mi><mo>=</mo><mrow><mi mathvariant="normal">â„“</mi><mo>+</mo><mn>1</mn></mrow></mrow><mi>L</mi></munderover><mrow><msub><mi>c</mi><mi>j</mi></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mrow><mo stretchy="false">|</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo rspace="0.055em" stretchy="false">|</mo></mrow><mo rspace="0.222em">â‹…</mo><msqrt><mfrac><mi>N</mi><mrow><mi>N</mi><mo>âˆ’</mo><mn>1</mn></mrow></mfrac></msqrt><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mrow><mo mathcolor="#0000FF" maxsize="1.200em" minsize="1.200em">(</mo><mrow><mn mathcolor="#0000FF">1</mn><mo mathcolor="#0000FF">âˆ’</mo><mrow><msub><mi mathcolor="#0000FF">Ï€</mi><mi mathcolor="#0000FF">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo mathcolor="#0000FF" stretchy="false">(</mo><msub><mi mathcolor="#0000FF">o</mi><mrow><mi mathcolor="#0000FF">i</mi><mo mathcolor="#0000FF">,</mo><mi mathcolor="#0000FF">t</mi></mrow></msub><mo mathcolor="#0000FF" stretchy="false">)</mo></mrow></mrow></mrow><mo mathcolor="#0000FF" maxsize="1.200em" minsize="1.200em">)</mo></mrow></mrow></mrow><mo>â‰¤</mo><mrow><mo mathcolor="#FF0000" stretchy="false">â€–</mo><mrow><msub><mi mathcolor="#FF0000">Î´</mi><mi mathcolor="#FF0000" mathvariant="normal">â„“</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo mathcolor="#FF0000" stretchy="false">(</mo><msub><mi mathcolor="#FF0000">o</mi><mrow><mi mathcolor="#FF0000">i</mi><mo mathcolor="#FF0000">,</mo><mi mathcolor="#FF0000">t</mi></mrow></msub><mo mathcolor="#FF0000" stretchy="false">)</mo></mrow></mrow><mo mathcolor="#FF0000" stretchy="false">â€–</mo></mrow><mo rspace="0.111em">â‰¤</mo><mrow><munderover><mo movablelimits="false">âˆ</mo><mrow><mi>j</mi><mo>=</mo><mrow><mi mathvariant="normal">â„“</mi><mo>+</mo><mn>1</mn></mrow></mrow><mi>L</mi></munderover><mrow><msub><mi>d</mi><mi>j</mi></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mrow><mo stretchy="false">|</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo rspace="0.055em" stretchy="false">|</mo></mrow><mo rspace="0.222em">â‹…</mo><msqrt><mn>2</mn></msqrt><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mrow><mo mathcolor="#0000FF" maxsize="1.200em" minsize="1.200em">(</mo><mrow><mn mathcolor="#0000FF">1</mn><mo mathcolor="#0000FF">âˆ’</mo><mrow><msub><mi mathcolor="#0000FF">Ï€</mi><mi mathcolor="#0000FF">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo mathcolor="#0000FF" stretchy="false">(</mo><msub><mi mathcolor="#0000FF">o</mi><mrow><mi mathcolor="#0000FF">i</mi><mo mathcolor="#0000FF">,</mo><mi mathcolor="#0000FF">t</mi></mrow></msub><mo mathcolor="#0000FF" stretchy="false">)</mo></mrow></mrow></mrow><mo mathcolor="#0000FF" maxsize="1.200em" minsize="1.200em">)</mo></mrow></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\prod_{j=\ell+1}^{L}c_{j}\cdot|w_{i,t}|\cdot\sqrt{\frac{N}{N-1}}\cdot{\color[rgb]{0,0,1}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,1}\big{(}1-\pi_{\theta}(o_{i,t})\big{)}}\leq{\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}\|\delta_{\ell}(o_{i,t})\|}\leq\prod_{j=\ell+1}^{L}d_{j}\cdot|w_{i,t}|\cdot\sqrt{2}\cdot{\color[rgb]{0,0,1}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,1}\big{(}1-\pi_{\theta}(o_{i,t})\big{)}}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
</div>
<figure id="S4.F2" class="ltx_figure ltx_align_floatright">
<p class="ltx_p"><span class="ltx_text" style="position:relative; bottom:-28.5pt;">
<img src="/html/2505.12929/assets/fig/vis_of_proposition.png" id="S4.F2.g1" class="ltx_graphics ltx_img_landscape" width="240" height="129" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Diagram of PropositionÂ <a href="#S4.Thmtheorem2" title="Proposition 4.2. â€£ 4.1 Explanation on Low-Probability Tokensâ€™ Dominance â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>.</figcaption>
</figure>
<div id="S4.SS1.p5" class="ltx_para">
<p class="ltx_p">Refer to AppendixÂ <a href="#A1.SS2" title="A.2 Proof for Proposition 4.2 â€£ Appendix A Theoretical Interpretations â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.2</span></a> for the detailed proof.
PropositionÂ <a href="#S4.Thmtheorem2" title="Proposition 4.2. â€£ 4.1 Explanation on Low-Probability Tokensâ€™ Dominance â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a> demonstrate that, for a single token, the gradient norm with respect to activation <math id="S4.SS1.p5.m1" class="ltx_Math" alttext="a_{\ell}" display="inline"><semantics><msub><mi>a</mi><mi mathvariant="normal">â„“</mi></msub><annotation encoding="application/x-tex">a_{\ell}</annotation></semantics></math> at any layer is bounded. Specifically, it is confined within the truncated conical region illustrated in FigureÂ <a href="#S4.F2" title="Figure 2 â€£ 4.1 Explanation on Low-Probability Tokensâ€™ Dominance â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
In Eq.Â (<a href="#S4.E3" title="In Proposition 4.2. â€£ 4.1 Explanation on Low-Probability Tokensâ€™ Dominance â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>), apart from the term <math id="S4.SS1.p5.m2" class="ltx_Math" alttext="(1-\pi_{\theta}(o_{i,t}))" display="inline"><semantics><mrow><mo stretchy="false">(</mo><mrow><mn>1</mn><mo>âˆ’</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(1-\pi_{\theta}(o_{i,t}))</annotation></semantics></math>, all other components in these bounds can be regarded as constant.
(Although <math id="S4.SS1.p5.m3" class="ltx_Math" alttext="w_{i,t}" display="inline"><semantics><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><annotation encoding="application/x-tex">w_{i,t}</annotation></semantics></math> depends on <math id="S4.SS1.p5.m4" class="ltx_Math" alttext="\pi_{\theta}(o_{i,t})" display="inline"><semantics><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\pi_{\theta}(o_{i,t})</annotation></semantics></math>, it is approximately equal to <math id="S4.SS1.p5.m5" class="ltx_Math" alttext="\hat{A}_{i,t}" display="inline"><semantics><msub><mover accent="true"><mi>A</mi><mo>^</mo></mover><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><annotation encoding="application/x-tex">\hat{A}_{i,t}</annotation></semantics></math> in most cases.)
This result highlights that <span class="ltx_text ltx_font_italic">tokens with lower probabilities lead to larger gradient magnitudes, whereas tokens with probabilities approaching 1 produce gradients that are nearly zero.</span>
The experimental evidence presented in FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> corroborates this relationship, demonstrating a roughly proportional correspondence between the gradient norm of all LLM parameters and <math id="S4.SS1.p5.m6" class="ltx_Math" alttext="(1-\pi_{\theta}(o_{i,t}))" display="inline"><semantics><mrow><mo stretchy="false">(</mo><mrow><mn>1</mn><mo>âˆ’</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(1-\pi_{\theta}(o_{i,t}))</annotation></semantics></math>.</p>
</div>
<div id="S4.SS1.p6" class="ltx_para">
<p class="ltx_p">Notably, during the RL training process, the gradients are averaged over hundreds of thousands of tokens for each update. Typically, the gradients are not sparsely distributed, leading to mutual influence among them. In such cases, low-probability tokens tend to dominate the gradient updates.
Nevertheless, the gradients of high-probability tokens are equally important and should not be neglected (see SectionÂ <a href="#S5.SS3" title="5.3 Ablation Studies â€£ 5 Experimental Results â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a> for details).
To the best of our knowledge, no prior study has explicitly investigated the gradient interference between low-probability and high-probability tokens.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Mitigating the Over-Dominance of Low-Probability Tokens</h3>

<figure id="S4.F3" class="ltx_figure ltx_align_floatright"><img src="/html/2505.12929/assets/fig/fig2.png" id="S4.F3.g1" class="ltx_graphics ltx_img_square" width="210" height="229" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The proportion of positive tokens updated in the correct direction
for different updating methods, under the same experimental settings as in FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</figcaption>
</figure>
<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Adverse Effect of the Dominance.</h5>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p">A natural question arises: what are the consequences if the gradient of low-probability tokens over-dominates the update process? Experimental results inÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib11" title="" class="ltx_ref">xiong2025minimalist </a></cite> suggest that positive samples (i.e., responses/tokens with an advantage greater than 0) play a more significant role than those negative ones. Theoretically, the probability of tokens with positive advantage should increase after each update.
Thus, we record the proportion of positive tokens with increased probabilities during a single RL training step, as shown in FigureÂ <a href="#S4.F3" title="Figure 3 â€£ 4.2 Mitigating the Over-Dominance of Low-Probability Tokens â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
In line with expectations, as the probability of a token grows, the proportion of updates in the correct direction decreases. In particular, the proportion of correct update directions for tokens with probability greater than 0.75 is even slightly less than 50%.
To mitigate the over-dominance of low-probability tokens and promote more efficient updates for high-probability tokens, we introduce the following two methods.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Advantage Reweighting.</h5>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p">A straightforward approach to address this issue is to reweight the advantage of tokens based on their probabilities. Specifically, we re-calculate the advantage of each token as follows:</p>
<table id="S4.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E4.m1" class="ltx_Math" alttext="\hat{A}_{i,t}=[\alpha\cdot\pi_{\theta}(o_{i,t})+(1-\alpha)]\cdot\hat{A}^{old}_{i,t}," display="block"><semantics><mrow><mrow><msub><mover accent="true"><mi>A</mi><mo>^</mo></mover><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo>=</mo><mrow><mrow><mo stretchy="false">[</mo><mrow><mrow><mrow><mi>Î±</mi><mo lspace="0.222em" rspace="0.222em">â‹…</mo><msub><mi>Ï€</mi><mi>Î¸</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo>+</mo><mrow><mo stretchy="false">(</mo><mrow><mn>1</mn><mo>âˆ’</mo><mi>Î±</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><mo rspace="0.055em" stretchy="false">]</mo></mrow><mo rspace="0.222em">â‹…</mo><msubsup><mover accent="true"><mi>A</mi><mo>^</mo></mover><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow><mrow><mi>o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>d</mi></mrow></msubsup></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\hat{A}_{i,t}=[\alpha\cdot\pi_{\theta}(o_{i,t})+(1-\alpha)]\cdot\hat{A}^{old}_{i,t},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math id="S4.SS2.SSS0.Px2.p1.m1" class="ltx_Math" alttext="\alpha\in[0,1]" display="inline"><semantics><mrow><mi>Î±</mi><mo>âˆˆ</mo><mrow><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></mrow><annotation encoding="application/x-tex">\alpha\in[0,1]</annotation></semantics></math> is a manually-defined hyperparameter.
This formulation assigns linearly smaller update weights to tokens with lower probabilities.
As shown in the upper panel of FigureÂ <a href="#S4.F3" title="Figure 3 â€£ 4.2 Mitigating the Over-Dominance of Low-Probability Tokens â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, it can significantly reduce the errors in update directions for positive high-probability tokens.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Low-Probability Tokens Isolation (Lopti).</h5>

<div id="S4.SS2.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p">In addition to <span class="ltx_text ltx_font_italic">Advantage Reweighting</span>, we also explored an alternative method, referred to as <span class="ltx_text ltx_font_italic">Lopti</span>.
Specifically, for a sampled mini-batch in RL, we predefine a probability threshold <math id="S4.SS2.SSS0.Px3.p1.m1" class="ltx_Math" alttext="\eta\in(0,1)" display="inline"><semantics><mrow><mi>Î·</mi><mo>âˆˆ</mo><mrow><mo stretchy="false">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\eta\in(0,1)</annotation></semantics></math> to divide tokens into two groups: low-probability tokens and high-probability tokens. We first update the low-probability tokens, followed by the high-probability tokens. For detailed implementation, please refer to lines 11â€“19 of AlgorithmÂ <a href="#alg1" title="Algorithm 1 â€£ Low-Probability Tokens Isolation (Lopti). â€£ 4.2 Mitigating the Over-Dominance of Low-Probability Tokens â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
With a universal hyperparameter setting of <math id="S4.SS2.SSS0.Px3.p1.m2" class="ltx_Math" alttext="\eta=0.5" display="inline"><semantics><mrow><mi>Î·</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\eta=0.5</annotation></semantics></math>, this method achieves a comparable effect to <span class="ltx_text ltx_font_italic">Advantage Reweighting</span>, as shown in the lower panel of FigureÂ <a href="#S4.F3" title="Figure 3 â€£ 4.2 Mitigating the Over-Dominance of Low-Probability Tokens â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div id="S4.SS2.SSS0.Px3.p2" class="ltx_para">
<p class="ltx_p">The intuition behind <span class="ltx_text ltx_font_italic">Lopti</span> is as follows: during the first stage, updates on low-probability tokens indirectly influence the distribution of the remaining high-probability tokens that have not yet been updated (as in FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(e)).
If a positive high-probability token is affected in the correct direction (i.e., its probability increases), its gradient becomes smaller in the subsequent stage when high-probability tokens are updated. Conversely, if its probability decreases, its gradient will dominate within the high-probability token group, thereby receiving greater attention during the update process.
Note that the order of updates cannot be reversed. The corresponding ablation is presented in SectionÂ <a href="#S5.SS3" title="5.3 Ablation Studies â€£ 5 Experimental Results â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a>.</p>
</div>
<div id="S4.SS2.SSS0.Px3.p3" class="ltx_para">
<p class="ltx_p">It is worth noting that <span class="ltx_text ltx_font_italic">Advantage Reweighting</span> and <span class="ltx_text ltx_font_italic">Lopti</span> can operate concurrently and may even lead to further improved downstream performance.
In AlgorithmÂ <a href="#alg1" title="Algorithm 1 â€£ Low-Probability Tokens Isolation (Lopti). â€£ 4.2 Mitigating the Over-Dominance of Low-Probability Tokens â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we detail how to integrate these two techniques with GRPO.
Note that the original GRPO update step (the gray section with strikethrough in lines 8â€“10) should be skipped if <span class="ltx_text ltx_font_italic">Lopti</span> is activated.
The computational cost requirements are detailed in AppendixÂ <a href="#A3.SS2" title="C.2 Computational Costs â€£ Appendix C Experimental Details â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.2</span></a>. Since <span class="ltx_text ltx_font_italic">Lopti</span> splits the tokens and performs updates twice, it results in higher computational costs, which is a limitation of our method (cf. AppendixÂ <a href="#A5" title="Appendix E Limitations â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">E</span></a>).</p>
</div>
<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold">Algorithm 1</span> </span> GRPO with <span class="ltx_text" style="color:#FF8000;">Advantage Reweighting</span> and <span class="ltx_text" style="color:#00FFFF;">Low-Probability Token Isolation</span></figcaption>
<div class="ltx_listing ltx_listing">
<div id="alg1.l1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">1:</span></span><span class="ltx_text" style="font-size:90%;">Initial LLM </span><math id="alg1.l1.m1" class="ltx_Math" alttext="\pi_{\theta}=\pi_{ref}" display="inline"><semantics><mrow><msub><mi mathsize="0.900em">Ï€</mi><mi mathsize="0.900em">Î¸</mi></msub><mo mathsize="0.900em">=</mo><msub><mi mathsize="0.900em">Ï€</mi><mrow><mi mathsize="0.900em">r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.900em">e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.900em">f</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\pi_{\theta}=\pi_{ref}</annotation></semantics></math><span class="ltx_text" style="font-size:90%;">, datasets </span><math id="alg1.l1.m2" class="ltx_Math" alttext="\mathcal{D}=\{\bm{q}\}" display="inline"><semantics><mrow><mi class="ltx_font_mathcaligraphic" mathsize="0.900em">ğ’Ÿ</mi><mo mathsize="0.900em">=</mo><mrow><mo maxsize="0.900em" minsize="0.900em">{</mo><mi mathsize="0.900em">ğ’’</mi><mo maxsize="0.900em" minsize="0.900em">}</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{D}=\{\bm{q}\}</annotation></semantics></math><span class="ltx_text" style="font-size:90%;">, reward function </span><math id="alg1.l1.m3" class="ltx_Math" alttext="r(\bm{q},\bm{o})" display="inline"><semantics><mrow><mi mathsize="0.900em">r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.900em" minsize="0.900em">(</mo><mi mathsize="0.900em">ğ’’</mi><mo mathsize="0.900em">,</mo><mi mathsize="0.900em">ğ’</mi><mo maxsize="0.900em" minsize="0.900em">)</mo></mrow></mrow><annotation encoding="application/x-tex">r(\bm{q},\bm{o})</annotation></semantics></math><span class="ltx_text" style="font-size:90%;">, </span><span class="ltx_text" style="font-size:90%;color:#FF8000;">reweighting hyperparamter <math id="alg1.l1.m4" class="ltx_Math" alttext="\alpha" display="inline"><semantics><mi mathcolor="#FF8000">Î±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="ltx_text" style="font-size:90%;">, </span><span class="ltx_text" style="font-size:90%;color:#00FFFF;">isolation threshold <math id="alg1.l1.m5" class="ltx_Math" alttext="\eta" display="inline"><semantics><mi mathcolor="#00FFFF">Î·</mi><annotation encoding="application/x-tex">\eta</annotation></semantics></math></span><span class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">2:</span></span><span class="ltx_text" style="font-size:90%;"></span><span class="ltx_text ltx_font_bold" style="font-size:90%;">for</span><span class="ltx_text" style="font-size:90%;">Â each dataset epochÂ </span><span class="ltx_text ltx_font_bold" style="font-size:90%;">do</span><span class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">3:</span></span><span class="ltx_text" style="font-size:90%;">â€ƒâ€„</span><span class="ltx_text ltx_font_bold" style="font-size:90%;">for</span><span class="ltx_text" style="font-size:90%;">Â each RL step, sample </span><math id="alg1.l3.m1" class="ltx_Math" alttext="\{\bm{q}\}^{M}\sim\mathcal{D}" display="inline"><semantics><mrow><msup><mrow><mo maxsize="0.900em" minsize="0.900em">{</mo><mi mathsize="0.900em">ğ’’</mi><mo maxsize="0.900em" minsize="0.900em">}</mo></mrow><mi mathsize="0.900em">M</mi></msup><mo mathsize="0.900em">âˆ¼</mo><mi class="ltx_font_mathcaligraphic" mathsize="0.900em">ğ’Ÿ</mi></mrow><annotation encoding="application/x-tex">\{\bm{q}\}^{M}\sim\mathcal{D}</annotation></semantics></math><span class="ltx_text" style="font-size:90%;"> Â </span><span class="ltx_text ltx_font_bold" style="font-size:90%;">do</span><span class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">4:</span></span><span class="ltx_text" style="font-size:90%;">â€ƒâ€ƒâ€‚â€…Auto-regress sampling </span><math id="alg1.l4.m1" class="ltx_Math" alttext="G" display="inline"><semantics><mi mathsize="0.900em">G</mi><annotation encoding="application/x-tex">G</annotation></semantics></math><span class="ltx_text" style="font-size:90%;"> responses </span><math id="alg1.l4.m2" class="ltx_Math" alttext="\{\bm{o}_{i}\}_{i=1}^{G}" display="inline"><semantics><msubsup><mrow><mo maxsize="0.900em" minsize="0.900em">{</mo><msub><mi mathsize="0.900em">ğ’</mi><mi mathsize="0.900em">i</mi></msub><mo maxsize="0.900em" minsize="0.900em">}</mo></mrow><mrow><mi mathsize="0.900em">i</mi><mo mathsize="0.900em">=</mo><mn mathsize="0.900em">1</mn></mrow><mi mathsize="0.900em">G</mi></msubsup><annotation encoding="application/x-tex">\{\bm{o}_{i}\}_{i=1}^{G}</annotation></semantics></math><span class="ltx_text" style="font-size:90%;"> for each question within </span><math id="alg1.l4.m3" class="ltx_Math" alttext="\{\bm{q}\}^{M}" display="inline"><semantics><msup><mrow><mo maxsize="0.900em" minsize="0.900em">{</mo><mi mathsize="0.900em">ğ’’</mi><mo maxsize="0.900em" minsize="0.900em">}</mo></mrow><mi mathsize="0.900em">M</mi></msup><annotation encoding="application/x-tex">\{\bm{q}\}^{M}</annotation></semantics></math><span class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">5:</span></span><span class="ltx_text" style="font-size:90%;">â€ƒâ€ƒâ€‚â€…Record the old probability for each token </span><math id="alg1.l5.m1" class="ltx_Math" alttext="\pi_{old}(o_{i,t})=\pi_{\theta}(o_{i,t})" display="inline"><semantics><mrow><mrow><msub><mi mathsize="0.900em">Ï€</mi><mrow><mi mathsize="0.900em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.900em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.900em">d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.900em" minsize="0.900em">(</mo><msub><mi mathsize="0.900em">o</mi><mrow><mi mathsize="0.900em">i</mi><mo mathsize="0.900em">,</mo><mi mathsize="0.900em">t</mi></mrow></msub><mo maxsize="0.900em" minsize="0.900em">)</mo></mrow></mrow><mo mathsize="0.900em">=</mo><mrow><msub><mi mathsize="0.900em">Ï€</mi><mi mathsize="0.900em">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.900em" minsize="0.900em">(</mo><msub><mi mathsize="0.900em">o</mi><mrow><mi mathsize="0.900em">i</mi><mo mathsize="0.900em">,</mo><mi mathsize="0.900em">t</mi></mrow></msub><mo maxsize="0.900em" minsize="0.900em">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\pi_{old}(o_{i,t})=\pi_{\theta}(o_{i,t})</annotation></semantics></math><span class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">6:</span></span><span class="ltx_text" style="font-size:90%;">â€ƒâ€ƒâ€‚â€…Calculate the reward for each response with reward function </span><math id="alg1.l6.m1" class="ltx_Math" alttext="\bm{r}(\bm{q},\bm{o}_{i})" display="inline"><semantics><mrow><mi mathsize="0.900em">ğ’“</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.900em" minsize="0.900em">(</mo><mi mathsize="0.900em">ğ’’</mi><mo mathsize="0.900em">,</mo><msub><mi mathsize="0.900em">ğ’</mi><mi mathsize="0.900em">i</mi></msub><mo maxsize="0.900em" minsize="0.900em">)</mo></mrow></mrow><annotation encoding="application/x-tex">\bm{r}(\bm{q},\bm{o}_{i})</annotation></semantics></math><span class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">7:</span></span><span class="ltx_text" style="font-size:90%;">â€ƒâ€ƒâ€‚â€…Calculate the advantage for each token (response) through </span><math id="alg1.l7.m1" class="ltx_Math" alttext="\hat{A}_{i,t}=\hat{A}_{i}=\frac{r(\bm{q},\bm{o}_{i})-\mathrm{mean}\{\bm{r}(\bm{q},\bm{o}_{i})\}_{i=1}^{G}}{\mathrm{std}\{\bm{r}(\bm{q},\bm{o}_{i})\}_{i=1}^{G}}" display="inline"><semantics><mrow><msub><mover accent="true"><mi mathsize="0.900em">A</mi><mo mathsize="0.900em">^</mo></mover><mrow><mi mathsize="0.900em">i</mi><mo mathsize="0.900em">,</mo><mi mathsize="0.900em">t</mi></mrow></msub><mo mathsize="0.900em">=</mo><msub><mover accent="true"><mi mathsize="0.900em">A</mi><mo mathsize="0.900em">^</mo></mover><mi mathsize="0.900em">i</mi></msub><mo mathsize="0.900em">=</mo><mfrac><mrow><mrow><mi mathsize="0.900em">r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.900em" minsize="0.900em">(</mo><mi mathsize="0.900em">ğ’’</mi><mo mathsize="0.900em">,</mo><msub><mi mathsize="0.900em">ğ’</mi><mi mathsize="0.900em">i</mi></msub><mo maxsize="0.900em" minsize="0.900em">)</mo></mrow></mrow><mo mathsize="0.900em">âˆ’</mo><mrow><mi mathsize="0.900em">mean</mi><mo lspace="0em" rspace="0em">â€‹</mo><msubsup><mrow><mo maxsize="0.900em" minsize="0.900em">{</mo><mrow><mi mathsize="0.900em">ğ’“</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.900em" minsize="0.900em">(</mo><mi mathsize="0.900em">ğ’’</mi><mo mathsize="0.900em">,</mo><msub><mi mathsize="0.900em">ğ’</mi><mi mathsize="0.900em">i</mi></msub><mo maxsize="0.900em" minsize="0.900em">)</mo></mrow></mrow><mo maxsize="0.900em" minsize="0.900em">}</mo></mrow><mrow><mi mathsize="0.900em">i</mi><mo mathsize="0.900em">=</mo><mn mathsize="0.900em">1</mn></mrow><mi mathsize="0.900em">G</mi></msubsup></mrow></mrow><mrow><mi mathsize="0.900em">std</mi><mo lspace="0em" rspace="0em">â€‹</mo><msubsup><mrow><mo maxsize="0.900em" minsize="0.900em">{</mo><mrow><mi mathsize="0.900em">ğ’“</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.900em" minsize="0.900em">(</mo><mi mathsize="0.900em">ğ’’</mi><mo mathsize="0.900em">,</mo><msub><mi mathsize="0.900em">ğ’</mi><mi mathsize="0.900em">i</mi></msub><mo maxsize="0.900em" minsize="0.900em">)</mo></mrow></mrow><mo maxsize="0.900em" minsize="0.900em">}</mo></mrow><mrow><mi mathsize="0.900em">i</mi><mo mathsize="0.900em">=</mo><mn mathsize="0.900em">1</mn></mrow><mi mathsize="0.900em">G</mi></msubsup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\hat{A}_{i,t}=\hat{A}_{i}=\frac{r(\bm{q},\bm{o}_{i})-\mathrm{mean}\{\bm{r}(\bm{q},\bm{o}_{i})\}_{i=1}^{G}}{\mathrm{std}\{\bm{r}(\bm{q},\bm{o}_{i})\}_{i=1}^{G}}</annotation></semantics></math><span class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">8:</span></span><span class="ltx_text" style="font-size:90%;color:#FF8000;">â€ƒâ€ƒâ€‚â€…Reweight Advantage through Eq.Â (</span><a href="#S4.E4" title="In Advantage Reweighting. â€£ 4.2 Mitigating the Over-Dominance of Low-Probability Tokens â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref" style="font-size:90%;color:#FF8000;"><span class="ltx_text ltx_ref_tag">4</span></a><span class="ltx_text" style="font-size:90%;color:#FF8000;">)</span><span class="ltx_text" style="font-size:90%;">
<span class="ltx_text" style="color:#808080;">
</span></span>
</div>
<div id="alg1.l9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">9:</span></span><span class="ltx_text" style="font-size:90%;color:#808080;">â€ƒâ€ƒâ€‚â€…</span><span class="ltx_text ltx_ulem_sout" style="font-size:90%;color:#808080;"><span class="ltx_text ltx_font_bold">for</span> each RL epoch, sample <math id="alg1.l9.m1" class="ltx_Math" alttext="\mathrm{mini\_batch}\sim\{\bm{q},\{\{\hat{A}_{i,t},\pi_{old}(o_{i,t})\}_{t=1}^{|\bm{o}_{i}|}\}_{i=1}^{G}\}^{M}" display="inline"><semantics><mrow><mrow><mi mathcolor="#808080">mini</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#808080" mathvariant="normal">_</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#808080">batch</mi></mrow><mo mathcolor="#808080">âˆ¼</mo><msup><mrow><mo mathcolor="#808080" stretchy="false">{</mo><mi mathcolor="#808080">ğ’’</mi><mo mathcolor="#808080">,</mo><msubsup><mrow><mo mathcolor="#808080" stretchy="false">{</mo><msubsup><mrow><mo mathcolor="#808080" stretchy="false">{</mo><msub><mover accent="true"><mi mathcolor="#808080">A</mi><mo mathcolor="#808080">^</mo></mover><mrow><mi mathcolor="#808080">i</mi><mo mathcolor="#808080">,</mo><mi mathcolor="#808080">t</mi></mrow></msub><mo mathcolor="#808080">,</mo><mrow><msub><mi mathcolor="#808080">Ï€</mi><mrow><mi mathcolor="#808080">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#808080">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#808080">d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo mathcolor="#808080" stretchy="false">(</mo><msub><mi mathcolor="#808080">o</mi><mrow><mi mathcolor="#808080">i</mi><mo mathcolor="#808080">,</mo><mi mathcolor="#808080">t</mi></mrow></msub><mo mathcolor="#808080" stretchy="false">)</mo></mrow></mrow><mo mathcolor="#808080" stretchy="false">}</mo></mrow><mrow><mi mathcolor="#808080">t</mi><mo mathcolor="#808080">=</mo><mn mathcolor="#808080">1</mn></mrow><mrow><mo mathcolor="#808080" stretchy="false">|</mo><msub><mi mathcolor="#808080">ğ’</mi><mi mathcolor="#808080">i</mi></msub><mo mathcolor="#808080" stretchy="false">|</mo></mrow></msubsup><mo mathcolor="#808080" stretchy="false">}</mo></mrow><mrow><mi mathcolor="#808080">i</mi><mo mathcolor="#808080">=</mo><mn mathcolor="#808080">1</mn></mrow><mi mathcolor="#808080">G</mi></msubsup><mo mathcolor="#808080" stretchy="false">}</mo></mrow><mi mathcolor="#808080">M</mi></msup></mrow><annotation encoding="application/x-tex">\mathrm{mini\_batch}\sim\{\bm{q},\{\{\hat{A}_{i,t},\pi_{old}(o_{i,t})\}_{t=1}^{|\bm{o}_{i}|}\}_{i=1}^{G}\}^{M}</annotation></semantics></math> <span class="ltx_text ltx_font_bold">do</span></span><span class="ltx_text" style="font-size:90%;color:#808080;">
</span>
</div>
<div id="alg1.l10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">10:</span></span><span class="ltx_text" style="font-size:90%;color:#808080;">â€ƒâ€ƒâ€‚â€…â€ƒâ€„</span><span class="ltx_text ltx_ulem_sout" style="font-size:90%;color:#808080;">Update the policy <math id="alg1.l10.m1" class="ltx_Math" alttext="\pi_{\theta}" display="inline"><semantics><msub><mi mathcolor="#808080">Ï€</mi><mi mathcolor="#808080">Î¸</mi></msub><annotation encoding="application/x-tex">\pi_{\theta}</annotation></semantics></math> with <math id="alg1.l10.m2" class="ltx_Math" alttext="\mathrm{mini\_batch}" display="inline"><semantics><mrow><mi mathcolor="#808080">mini</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#808080" mathvariant="normal">_</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#808080">batch</mi></mrow><annotation encoding="application/x-tex">\mathrm{mini\_batch}</annotation></semantics></math> through Eq.Â (<a href="#S3.E1" title="In Group Relative Policy Optimization. â€£ 3 Preliminary â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>)</span><span class="ltx_text" style="font-size:90%;color:#808080;">
</span>
</div>
<div id="alg1.l11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">11:</span></span><span class="ltx_text" style="font-size:90%;color:#808080;">â€ƒâ€ƒâ€‚â€…</span><span class="ltx_text ltx_ulem_sout ltx_font_bold" style="font-size:90%;color:#808080;">end for</span><span class="ltx_text" style="font-size:90%;color:#808080;">
</span><span class="ltx_text" style="font-size:90%;color:#00FFFF;">
</span>
</div>
<div id="alg1.l12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">12:</span></span><span class="ltx_text" style="font-size:90%;color:#00FFFF;">â€ƒâ€ƒâ€‚â€…Record the old Advantage </span><math id="alg1.l12.m1" class="ltx_Math" alttext="\hat{A}_{i,t}^{old}=\hat{A}_{i,t}" display="inline"><semantics><mrow><msubsup><mover accent="true"><mi mathcolor="#00FFFF" mathsize="0.900em">A</mi><mo mathcolor="#00FFFF" mathsize="0.900em">^</mo></mover><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">i</mi><mo mathcolor="#00FFFF" mathsize="0.900em">,</mo><mi mathcolor="#00FFFF" mathsize="0.900em">t</mi></mrow><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#00FFFF" mathsize="0.900em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#00FFFF" mathsize="0.900em">d</mi></mrow></msubsup><mo mathcolor="#00FFFF" mathsize="0.900em">=</mo><msub><mover accent="true"><mi mathcolor="#00FFFF" mathsize="0.900em">A</mi><mo mathcolor="#00FFFF" mathsize="0.900em">^</mo></mover><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">i</mi><mo mathcolor="#00FFFF" mathsize="0.900em">,</mo><mi mathcolor="#00FFFF" mathsize="0.900em">t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\hat{A}_{i,t}^{old}=\hat{A}_{i,t}</annotation></semantics></math><span class="ltx_text" style="font-size:90%;color:#00FFFF;">
</span>
</div>
<div id="alg1.l13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">13:</span></span><span class="ltx_text" style="font-size:90%;color:#00FFFF;">â€ƒâ€ƒâ€‚â€…Mask high-probability tokens through </span><math id="alg1.l13.m1" class="ltx_Math" alttext="\hat{A}_{i,t}=\hat{A}_{i,t}^{old}\odot\mathbb{I}(\pi_{old}(o_{i,t})\leq\eta)" display="inline"><semantics><mrow><msub><mover accent="true"><mi mathcolor="#00FFFF" mathsize="0.900em">A</mi><mo mathcolor="#00FFFF" mathsize="0.900em">^</mo></mover><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">i</mi><mo mathcolor="#00FFFF" mathsize="0.900em">,</mo><mi mathcolor="#00FFFF" mathsize="0.900em">t</mi></mrow></msub><mo mathcolor="#00FFFF" mathsize="0.900em">=</mo><mrow><mrow><msubsup><mover accent="true"><mi mathcolor="#00FFFF" mathsize="0.900em">A</mi><mo mathcolor="#00FFFF" mathsize="0.900em">^</mo></mover><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">i</mi><mo mathcolor="#00FFFF" mathsize="0.900em">,</mo><mi mathcolor="#00FFFF" mathsize="0.900em">t</mi></mrow><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#00FFFF" mathsize="0.900em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#00FFFF" mathsize="0.900em">d</mi></mrow></msubsup><mo lspace="0.222em" mathcolor="#00FFFF" mathsize="0.900em" rspace="0.222em">âŠ™</mo><mi mathcolor="#00FFFF" mathsize="0.900em">ğ•€</mi></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">(</mo><mrow><mrow><msub><mi mathcolor="#00FFFF" mathsize="0.900em">Ï€</mi><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#00FFFF" mathsize="0.900em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#00FFFF" mathsize="0.900em">d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">(</mo><msub><mi mathcolor="#00FFFF" mathsize="0.900em">o</mi><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">i</mi><mo mathcolor="#00FFFF" mathsize="0.900em">,</mo><mi mathcolor="#00FFFF" mathsize="0.900em">t</mi></mrow></msub><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">)</mo></mrow></mrow><mo mathcolor="#00FFFF" mathsize="0.900em">â‰¤</mo><mi mathcolor="#00FFFF" mathsize="0.900em">Î·</mi></mrow><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\hat{A}_{i,t}=\hat{A}_{i,t}^{old}\odot\mathbb{I}(\pi_{old}(o_{i,t})\leq\eta)</annotation></semantics></math><span class="ltx_text" style="font-size:90%;color:#00FFFF;">
</span>
</div>
<div id="alg1.l14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">14:</span></span><span class="ltx_text" style="font-size:90%;color:#00FFFF;">â€ƒâ€ƒâ€‚â€…</span><span class="ltx_text ltx_font_bold" style="font-size:90%;color:#00FFFF;">for</span><span class="ltx_text" style="font-size:90%;color:#00FFFF;"> each RL epoch, sample </span><math id="alg1.l14.m1" class="ltx_Math" alttext="\mathrm{mini\_batch}\sim\{\bm{q},\{\{\hat{A}_{i,t},\pi_{old}(o_{i,t})\}_{t=1}^{|\bm{o}_{i}|}\}_{i=1}^{G}\}^{M}" display="inline"><semantics><mrow><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">mini</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#00FFFF" mathsize="0.900em" mathvariant="normal">_</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#00FFFF" mathsize="0.900em">batch</mi></mrow><mo mathcolor="#00FFFF" mathsize="0.900em">âˆ¼</mo><msup><mrow><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">{</mo><mi mathcolor="#00FFFF" mathsize="0.900em">ğ’’</mi><mo mathcolor="#00FFFF" mathsize="0.900em">,</mo><msubsup><mrow><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">{</mo><msubsup><mrow><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">{</mo><msub><mover accent="true"><mi mathcolor="#00FFFF" mathsize="0.900em">A</mi><mo mathcolor="#00FFFF" mathsize="0.900em">^</mo></mover><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">i</mi><mo mathcolor="#00FFFF" mathsize="0.900em">,</mo><mi mathcolor="#00FFFF" mathsize="0.900em">t</mi></mrow></msub><mo mathcolor="#00FFFF" mathsize="0.900em">,</mo><mrow><msub><mi mathcolor="#00FFFF" mathsize="0.900em">Ï€</mi><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#00FFFF" mathsize="0.900em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#00FFFF" mathsize="0.900em">d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">(</mo><msub><mi mathcolor="#00FFFF" mathsize="0.900em">o</mi><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">i</mi><mo mathcolor="#00FFFF" mathsize="0.900em">,</mo><mi mathcolor="#00FFFF" mathsize="0.900em">t</mi></mrow></msub><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">)</mo></mrow></mrow><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">}</mo></mrow><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">t</mi><mo mathcolor="#00FFFF" mathsize="0.900em">=</mo><mn mathcolor="#00FFFF" mathsize="0.900em">1</mn></mrow><mrow><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em" stretchy="true">|</mo><msub><mi mathcolor="#00FFFF" mathsize="0.900em">ğ’</mi><mi mathcolor="#00FFFF" mathsize="0.900em">i</mi></msub><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em" stretchy="true">|</mo></mrow></msubsup><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">}</mo></mrow><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">i</mi><mo mathcolor="#00FFFF" mathsize="0.900em">=</mo><mn mathcolor="#00FFFF" mathsize="0.900em">1</mn></mrow><mi mathcolor="#00FFFF" mathsize="0.900em">G</mi></msubsup><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">}</mo></mrow><mi mathcolor="#00FFFF" mathsize="0.900em">M</mi></msup></mrow><annotation encoding="application/x-tex">\mathrm{mini\_batch}\sim\{\bm{q},\{\{\hat{A}_{i,t},\pi_{old}(o_{i,t})\}_{t=1}^{|\bm{o}_{i}|}\}_{i=1}^{G}\}^{M}</annotation></semantics></math><span class="ltx_text" style="font-size:90%;color:#00FFFF;"> </span><span class="ltx_text ltx_font_bold" style="font-size:90%;color:#00FFFF;">do</span><span class="ltx_text" style="font-size:90%;color:#00FFFF;">
</span>
</div>
<div id="alg1.l15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">15:</span></span><span class="ltx_text" style="font-size:90%;color:#00FFFF;">â€ƒâ€ƒâ€‚â€…â€ƒâ€„Update the policy </span><math id="alg1.l15.m1" class="ltx_Math" alttext="\pi_{\theta}" display="inline"><semantics><msub><mi mathcolor="#00FFFF" mathsize="0.900em">Ï€</mi><mi mathcolor="#00FFFF" mathsize="0.900em">Î¸</mi></msub><annotation encoding="application/x-tex">\pi_{\theta}</annotation></semantics></math><span class="ltx_text" style="font-size:90%;color:#00FFFF;"> with </span><math id="alg1.l15.m2" class="ltx_Math" alttext="\mathrm{mini\,batch}" display="inline"><semantics><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">mini</mi><mo lspace="0.170em" rspace="0em">â€‹</mo><mi mathcolor="#00FFFF" mathsize="0.900em">batch</mi></mrow><annotation encoding="application/x-tex">\mathrm{mini\,batch}</annotation></semantics></math><span class="ltx_text" style="font-size:90%;color:#00FFFF;"> through Eq.Â (</span><a href="#S3.E1" title="In Group Relative Policy Optimization. â€£ 3 Preliminary â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref" style="font-size:90%;color:#00FFFF;"><span class="ltx_text ltx_ref_tag">1</span></a><span class="ltx_text" style="font-size:90%;color:#00FFFF;">)
</span>
</div>
<div id="alg1.l16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">16:</span></span><span class="ltx_text" style="font-size:90%;color:#00FFFF;">â€ƒâ€ƒâ€‚â€…</span><span class="ltx_text ltx_font_bold" style="font-size:90%;color:#00FFFF;">end for</span><span class="ltx_text" style="font-size:90%;color:#00FFFF;">
</span>
</div>
<div id="alg1.l17" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">17:</span></span><span class="ltx_text" style="font-size:90%;color:#00FFFF;">â€ƒâ€ƒâ€‚â€…Mask low-probability tokens </span><math id="alg1.l17.m1" class="ltx_math_unparsed" alttext="\hat{A}_{i,t}=\hat{A}_{i,t}^{old}\odot(1-\mathbb{I}(\pi_{old}(o_{i,t})\leq\eta)" display="inline"><semantics><mrow><msub><mover accent="true"><mi mathcolor="#00FFFF" mathsize="0.900em">A</mi><mo mathcolor="#00FFFF" mathsize="0.900em">^</mo></mover><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">i</mi><mo mathcolor="#00FFFF" mathsize="0.900em">,</mo><mi mathcolor="#00FFFF" mathsize="0.900em">t</mi></mrow></msub><mo mathcolor="#00FFFF" mathsize="0.900em">=</mo><msubsup><mover accent="true"><mi mathcolor="#00FFFF" mathsize="0.900em">A</mi><mo mathcolor="#00FFFF" mathsize="0.900em">^</mo></mover><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">i</mi><mo mathcolor="#00FFFF" mathsize="0.900em">,</mo><mi mathcolor="#00FFFF" mathsize="0.900em">t</mi></mrow><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#00FFFF" mathsize="0.900em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#00FFFF" mathsize="0.900em">d</mi></mrow></msubsup><mo lspace="0.222em" mathcolor="#00FFFF" mathsize="0.900em" rspace="0.222em">âŠ™</mo><mrow><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">(</mo><mn mathcolor="#00FFFF" mathsize="0.900em">1</mn><mo mathcolor="#00FFFF" mathsize="0.900em">âˆ’</mo><mi mathcolor="#00FFFF" mathsize="0.900em">ğ•€</mi><mrow><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">(</mo><msub><mi mathcolor="#00FFFF" mathsize="0.900em">Ï€</mi><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#00FFFF" mathsize="0.900em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#00FFFF" mathsize="0.900em">d</mi></mrow></msub><mrow><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">(</mo><msub><mi mathcolor="#00FFFF" mathsize="0.900em">o</mi><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">i</mi><mo mathcolor="#00FFFF" mathsize="0.900em">,</mo><mi mathcolor="#00FFFF" mathsize="0.900em">t</mi></mrow></msub><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">)</mo></mrow><mo mathcolor="#00FFFF" mathsize="0.900em">â‰¤</mo><mi mathcolor="#00FFFF" mathsize="0.900em">Î·</mi><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\hat{A}_{i,t}=\hat{A}_{i,t}^{old}\odot(1-\mathbb{I}(\pi_{old}(o_{i,t})\leq\eta)</annotation></semantics></math><span class="ltx_text" style="font-size:90%;color:#00FFFF;"> )
</span>
</div>
<div id="alg1.l18" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">18:</span></span><span class="ltx_text" style="font-size:90%;color:#00FFFF;">â€ƒâ€ƒâ€‚â€…</span><span class="ltx_text ltx_font_bold" style="font-size:90%;color:#00FFFF;">for</span><span class="ltx_text" style="font-size:90%;color:#00FFFF;"> each RL epoch, sample </span><math id="alg1.l18.m1" class="ltx_Math" alttext="\mathrm{mini\_batch}\sim\{\bm{q},\{\{\hat{A}_{i,t},\pi_{old}(o_{i,t})\}_{t=1}^{|\bm{o}_{i}|}\}_{i=1}^{G}\}^{M}" display="inline"><semantics><mrow><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">mini</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#00FFFF" mathsize="0.900em" mathvariant="normal">_</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#00FFFF" mathsize="0.900em">batch</mi></mrow><mo mathcolor="#00FFFF" mathsize="0.900em">âˆ¼</mo><msup><mrow><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">{</mo><mi mathcolor="#00FFFF" mathsize="0.900em">ğ’’</mi><mo mathcolor="#00FFFF" mathsize="0.900em">,</mo><msubsup><mrow><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">{</mo><msubsup><mrow><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">{</mo><msub><mover accent="true"><mi mathcolor="#00FFFF" mathsize="0.900em">A</mi><mo mathcolor="#00FFFF" mathsize="0.900em">^</mo></mover><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">i</mi><mo mathcolor="#00FFFF" mathsize="0.900em">,</mo><mi mathcolor="#00FFFF" mathsize="0.900em">t</mi></mrow></msub><mo mathcolor="#00FFFF" mathsize="0.900em">,</mo><mrow><msub><mi mathcolor="#00FFFF" mathsize="0.900em">Ï€</mi><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#00FFFF" mathsize="0.900em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathcolor="#00FFFF" mathsize="0.900em">d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">(</mo><msub><mi mathcolor="#00FFFF" mathsize="0.900em">o</mi><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">i</mi><mo mathcolor="#00FFFF" mathsize="0.900em">,</mo><mi mathcolor="#00FFFF" mathsize="0.900em">t</mi></mrow></msub><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">)</mo></mrow></mrow><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">}</mo></mrow><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">t</mi><mo mathcolor="#00FFFF" mathsize="0.900em">=</mo><mn mathcolor="#00FFFF" mathsize="0.900em">1</mn></mrow><mrow><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em" stretchy="true">|</mo><msub><mi mathcolor="#00FFFF" mathsize="0.900em">ğ’</mi><mi mathcolor="#00FFFF" mathsize="0.900em">i</mi></msub><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em" stretchy="true">|</mo></mrow></msubsup><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">}</mo></mrow><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">i</mi><mo mathcolor="#00FFFF" mathsize="0.900em">=</mo><mn mathcolor="#00FFFF" mathsize="0.900em">1</mn></mrow><mi mathcolor="#00FFFF" mathsize="0.900em">G</mi></msubsup><mo mathcolor="#00FFFF" maxsize="0.900em" minsize="0.900em">}</mo></mrow><mi mathcolor="#00FFFF" mathsize="0.900em">M</mi></msup></mrow><annotation encoding="application/x-tex">\mathrm{mini\_batch}\sim\{\bm{q},\{\{\hat{A}_{i,t},\pi_{old}(o_{i,t})\}_{t=1}^{|\bm{o}_{i}|}\}_{i=1}^{G}\}^{M}</annotation></semantics></math><span class="ltx_text" style="font-size:90%;color:#00FFFF;"> </span><span class="ltx_text ltx_font_bold" style="font-size:90%;color:#00FFFF;">do</span><span class="ltx_text" style="font-size:90%;color:#00FFFF;">
</span>
</div>
<div id="alg1.l19" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">19:</span></span><span class="ltx_text" style="font-size:90%;color:#00FFFF;">â€ƒâ€ƒâ€‚â€…â€ƒâ€„Update the policy </span><math id="alg1.l19.m1" class="ltx_Math" alttext="\pi_{\theta}" display="inline"><semantics><msub><mi mathcolor="#00FFFF" mathsize="0.900em">Ï€</mi><mi mathcolor="#00FFFF" mathsize="0.900em">Î¸</mi></msub><annotation encoding="application/x-tex">\pi_{\theta}</annotation></semantics></math><span class="ltx_text" style="font-size:90%;color:#00FFFF;"> with </span><math id="alg1.l19.m2" class="ltx_Math" alttext="\mathrm{mini\,batch}" display="inline"><semantics><mrow><mi mathcolor="#00FFFF" mathsize="0.900em">mini</mi><mo lspace="0.170em" rspace="0em">â€‹</mo><mi mathcolor="#00FFFF" mathsize="0.900em">batch</mi></mrow><annotation encoding="application/x-tex">\mathrm{mini\,batch}</annotation></semantics></math><span class="ltx_text" style="font-size:90%;color:#00FFFF;"> through Eq.Â (</span><a href="#S3.E1" title="In Group Relative Policy Optimization. â€£ 3 Preliminary â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref" style="font-size:90%;color:#00FFFF;"><span class="ltx_text ltx_ref_tag">1</span></a><span class="ltx_text" style="font-size:90%;color:#00FFFF;">)
</span>
</div>
<div id="alg1.l20" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">20:</span></span><span class="ltx_text" style="font-size:90%;color:#00FFFF;">â€ƒâ€ƒâ€‚â€…</span><span class="ltx_text ltx_font_bold" style="font-size:90%;color:#00FFFF;">end for</span><span class="ltx_text" style="font-size:90%;color:#00FFFF;">
</span>
</div>
<div id="alg1.l21" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">21:</span></span><span class="ltx_text" style="font-size:90%;">â€ƒâ€„</span><span class="ltx_text ltx_font_bold" style="font-size:90%;">end</span><span class="ltx_text" style="font-size:90%;">Â </span><span class="ltx_text ltx_font_bold" style="font-size:90%;">for</span>
</div>
<div id="alg1.l22" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">22:</span></span><span class="ltx_text" style="font-size:90%;"></span><span class="ltx_text ltx_font_bold" style="font-size:90%;">end</span><span class="ltx_text" style="font-size:90%;">Â </span><span class="ltx_text ltx_font_bold" style="font-size:90%;">for</span>
</div>
<div id="alg1.l23" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" style="font-size:80%;">23:</span></span><span class="ltx_text ltx_font_bold" style="font-size:90%;">return</span><span class="ltx_text" style="font-size:90%;"> Final policy </span><math id="alg1.l23.m1" class="ltx_Math" alttext="\pi_{\theta}" display="inline"><semantics><msub><mi mathsize="0.900em">Ï€</mi><mi mathsize="0.900em">Î¸</mi></msub><annotation encoding="application/x-tex">\pi_{\theta}</annotation></semantics></math><span class="ltx_text" style="font-size:90%;">
</span>
</div>
</div>
</figure>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experimental Results</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p">To validate the effectiveness of our proposed method, we first conduct experiments on the Knights and Knaves (K&amp;K) Logic Puzzles datasetÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib38" title="" class="ltx_ref">xie2025logic </a>; <a href="#bib.bib45" title="" class="ltx_ref">xie2024memorization </a></cite> using GRPO, as described in SectionÂ <a href="#S5.SS1" title="5.1 Experiments on K&amp;K Logic Puzzles â€£ 5 Experimental Results â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>.
We then extend the experiments to the math-related datasetÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib37" title="" class="ltx_ref">deepscaler2025 </a>; <a href="#bib.bib42" title="" class="ltx_ref">shi2025efficient </a></cite>, as detailed in SectionÂ <a href="#S5.SS2" title="5.2 Experiments on Math-related Datasets â€£ 5 Experimental Results â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>.
Finally, we present a series of critical ablation studies, as outlined in SectionÂ <a href="#S5.SS3" title="5.3 Ablation Studies â€£ 5 Experimental Results â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a>. Note that our methods are not restricted to GRPO and hold great potential across all Policy-Gradient based RL algorithms. For experiments utilizing REINFORCE++Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib46" title="" class="ltx_ref">hu2025reinforce++ </a></cite>, please refer to AppendixÂ <a href="#A4" title="Appendix D Additional Experimental Results on REINFORCE++ â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a>.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Experiments on K&amp;K Logic Puzzles</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p class="ltx_p">The K&amp;K logic puzzles, first aggregated into a benchmark for LLMs by Xie et al.Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib45" title="" class="ltx_ref">xie2024memorization </a></cite>, are a class of reasoning problems rooted in classical logic gameÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib47" title="" class="ltx_ref">smullyan1986name </a>; <a href="#bib.bib48" title="" class="ltx_ref">johnson1990meta </a></cite>.
These puzzles involve a fictional scenario where inhabitants of an island are either Knights, who always tell the truth, or Knaves, who always lie.
The objective is to determine the identity of each inhabitant (Knight or Knave) based on a set of statements they make about themselves and others.
Please refer to AppendixÂ <a href="#A3.SS1.SSS1" title="C.1.1 K&amp;K Logic Puzzle â€£ C.1 Task Description â€£ Appendix C Experimental Details â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.1.1</span></a> for detailed introduction.
The K&amp;K logic puzzles are highly challenging, with only the most advanced LLMs demonstrating strong performanceÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib45" title="" class="ltx_ref">xie2024memorization </a></cite>.
Additionally, it is not exposed in the modelâ€™s pre-training phase, allowing the model to demonstrate continual learning behavior during training. As training progresses, both the training reward and test accuracy gradually improve, rather than converging rapidly.
These characteristics make this benchmark an ideal choice for verifying RL performance.</p>
</div>
<figure id="S5.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" style="width:112.7pt;"><img src="/html/2505.12929/assets/fig/kk_logics_training_record_reward.png" id="S5.F4.g1" class="ltx_graphics ltx_img_portrait" width="598" height="957" alt="Refer to caption"></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle ltx_transformed_outer" style="width:294.9pt;height:216pt;vertical-align:-106.3pt;"><span class="ltx_transformed_inner" style="transform:translate(-40.9pt,13.7pt) scale(0.8,0.8) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_border_t"></td>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="background-color:#EFEFEF;" colspan="5"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Difficulty by Number of People</span></th>
<td class="ltx_td ltx_border_t"></td>
</tr>
<tr class="ltx_tr" style="background-color:#EFEFEF;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">3</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">4</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">5</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">6</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">7</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Avg.</span></th>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t"><span class="ltx_text ltx_font_bold">GPT-4o</span></td>
<td class="ltx_td ltx_align_center ltx_border_t">0.57</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.49</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.32</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.23</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.21</td>
<td class="ltx_td ltx_align_left ltx_border_t">0.36</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text ltx_font_bold">o1-2024-12-17</span></td>
<td class="ltx_td ltx_align_center">0.51</td>
<td class="ltx_td ltx_align_center">0.38</td>
<td class="ltx_td ltx_align_center">0.38</td>
<td class="ltx_td ltx_align_center">0.35</td>
<td class="ltx_td ltx_align_center">0.30</td>
<td class="ltx_td ltx_align_left">0.38</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text ltx_font_bold">Deepseek-R1</span></td>
<td class="ltx_td ltx_align_center">0.73</td>
<td class="ltx_td ltx_align_center">0.77</td>
<td class="ltx_td ltx_align_center">0.78</td>
<td class="ltx_td ltx_align_center">0.75</td>
<td class="ltx_td ltx_align_center">0.88</td>
<td class="ltx_td ltx_align_left">0.78</td>
</tr>
<tr class="ltx_tr" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#ECF4FF;">Qwen2.5-3B-Instruct</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="background-color:#ECF4FF;">0.09</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="background-color:#ECF4FF;">0.10</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="background-color:#ECF4FF;">0.03</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="background-color:#ECF4FF;">0.05</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="background-color:#ECF4FF;">0.02</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" style="background-color:#ECF4FF;"><span class="ltx_text" style="background-color:#ECF4FF;">0.06</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#9B9B9B;"><span class="ltx_text ltx_font_bold" style="color:#9B9B9B;">+ GRPO</span></span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#9B9B9B;">0.60</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#9B9B9B;">0.45</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#9B9B9B;">0.33</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#9B9B9B;">0.34</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#9B9B9B;">0.23</span></td>
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#9B9B9B;">0.39</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#F56B00;"><span class="ltx_text ltx_font_bold" style="color:#F56B00;">+ GRPO + Reweight</span></span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#F56B00;">0.67</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#F56B00;">0.62</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#F56B00;">0.53</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#F56B00;">0.44</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#F56B00;">0.37</span></td>
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#F56B00;">0.53 <sup class="ltx_sup"><span class="ltx_text ltx_font_italic">(â†‘35.9%)</span></sup></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#32BEE6;"><span class="ltx_text ltx_font_bold" style="color:#32BEE6;">+ GRPO + Lopti</span></span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#32BEE6;">0.74</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#32BEE6;">0.67</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#32BEE6;">0.56</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#32BEE6;">0.42</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#32BEE6;">0.30</span></td>
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#32BEE6;">0.54 <sup class="ltx_sup"><span class="ltx_text ltx_font_italic">(â†‘38.5%)</span></sup></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#009901;"><span class="ltx_text ltx_font_bold" style="color:#009901;">+ GRPO + Reweight + Lopti</span></span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#009901;">0.72</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#009901;">0.66</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#009901;">0.55</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#009901;">0.52</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#009901;">0.40</span></td>
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#009901;">0.57 <sup class="ltx_sup"><span class="ltx_text ltx_font_italic">(â†‘46.2%)</span></sup></span></td>
</tr>
<tr class="ltx_tr" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#ECF4FF;">Qwen2.5-7B-Instruct-1M</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="background-color:#ECF4FF;">0.22</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="background-color:#ECF4FF;">0.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="background-color:#ECF4FF;">0.08</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="background-color:#ECF4FF;">0.10</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="background-color:#ECF4FF;">0.02</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" style="background-color:#ECF4FF;"><span class="ltx_text" style="background-color:#ECF4FF;">0.11</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#9B9B9B;"><span class="ltx_text ltx_font_bold" style="color:#9B9B9B;">+ GRPO</span></span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#9B9B9B;">0.91</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#9B9B9B;">0.91</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#9B9B9B;">0.77</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#9B9B9B;">0.65</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#9B9B9B;">0.61</span></td>
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#9B9B9B;">0.77</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#F56B00;"><span class="ltx_text ltx_font_bold" style="color:#F56B00;">+ GRPO + Reweight</span></span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#F56B00;">0.97</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#F56B00;">0.98</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#F56B00;">0.89</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#F56B00;">0.83</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#F56B00;">0.80</span></td>
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#F56B00;">0.89 <sup class="ltx_sup"><span class="ltx_text ltx_font_italic">(â†‘15.6%)</span></sup></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#32BEE6;"><span class="ltx_text ltx_font_bold" style="color:#32BEE6;">+ GRPO + Lopti</span></span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#32BEE6;">0.95</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#32BEE6;">0.94</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#32BEE6;">0.84</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#32BEE6;">0.80</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#32BEE6;">0.76</span></td>
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#32BEE6;">0.86 <sup class="ltx_sup"><span class="ltx_text ltx_font_italic">(â†‘9.1%)</span></sup></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b"><span class="ltx_text" style="color:#009901;"><span class="ltx_text ltx_font_bold" style="color:#009901;">+ GRPO + Reweight + Lopti</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_b"><span class="ltx_text" style="color:#009901;">0.95</span></td>
<td class="ltx_td ltx_align_center ltx_border_b"><span class="ltx_text" style="color:#009901;">0.94</span></td>
<td class="ltx_td ltx_align_center ltx_border_b"><span class="ltx_text" style="color:#009901;">0.91</span></td>
<td class="ltx_td ltx_align_center ltx_border_b"><span class="ltx_text" style="color:#009901;">0.87</span></td>
<td class="ltx_td ltx_align_center ltx_border_b"><span class="ltx_text" style="color:#009901;">0.87</span></td>
<td class="ltx_td ltx_align_left ltx_border_b"><span class="ltx_text" style="color:#009901;">0.91 <sup class="ltx_sup"><span class="ltx_text ltx_font_italic">(â†‘18.2%)</span></sup></span></td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Experimental results on the K&amp;K Logic Puzzles benchmark.
For <span class="ltx_text ltx_font_italic">Advantage Reweight</span>, <math id="S5.F4.m9" class="ltx_Math" alttext="\alpha=0.3" display="inline"><semantics><mrow><mi>Î±</mi><mo>=</mo><mn>0.3</mn></mrow><annotation encoding="application/x-tex">\alpha=0.3</annotation></semantics></math>, and for <span class="ltx_text ltx_font_italic">Lopti</span>, <math id="S5.F4.m10" class="ltx_Math" alttext="\eta=0.5" display="inline"><semantics><mrow><mi>Î·</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\eta=0.5</annotation></semantics></math>.
The reward curve during training (left) is truncated to exclude the first epoch and smoothed with an exponential moving average (coefficient: 0.95). The evaluation accuracy on the test set (right) are averaged over the last three checkpoints to mitigate randomness.</figcaption>
</figure>
<figure id="S5.F5" class="ltx_figure"><img src="/html/2505.12929/assets/fig/fig4.png" id="S5.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="261" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>
(a) The relationship between the frequency of six categories of inference-related words and the corresponding sample rewards for Qwen-2.5-7B-Instruct-1M trained with naive GRPO. The Pearson correlation coefficient (<math id="S5.F5.m3" class="ltx_Math" alttext="r" display="inline"><semantics><mi>r</mi><annotation encoding="application/x-tex">r</annotation></semantics></math>) and Spearman rank correlation coefficient (<math id="S5.F5.m4" class="ltx_Math" alttext="\rho" display="inline"><semantics><mi>Ï</mi><annotation encoding="application/x-tex">\rho</annotation></semantics></math>) are annotated.
(b) A comparison of the frequency of the six categories of words across the starting point (Qwen-2.5-7B-Instruct-1M), naive GRPO, and GRPO enhanced with Advantage Reweighting and/or Lopti.
</figcaption>
</figure>
<div id="S5.SS1.p2" class="ltx_para">
<p class="ltx_p">Following Logic-RLÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib38" title="" class="ltx_ref">xie2025logic </a></cite>, we construct the training set by combining logic puzzles with 3 to 7 players and adopt its rule-based reward function, which consists of two components:
(1) Format score, assigned 1 if the model provides CoT reasoning within <span class="ltx_text ltx_font_typewriter">&lt;think&gt;&lt;/think&gt;</span> tags and the final answer within <span class="ltx_text ltx_font_typewriter">&lt;answer&gt;&lt;/answer&gt;</span> tags, and -1 otherwise; (2) Answer reward, assigned 2 for a perfect match with the ground truth, -1.5 for partial correctness, and -2 for an completely incorrect answer.
We use <span class="ltx_text ltx_font_typewriter">Qwen2.5-3B-Instruct</span> and <span class="ltx_text ltx_font_typewriter">Qwen2.5-7B-Instruct-1M</span> as starting points.
Without employing curriculum learning, we directly expose the model to the mixed training set and train it for a total of 5 epochs.
The experimental results are reported in FigureÂ <a href="#S5.F4" title="Figure 4 â€£ 5.1 Experiments on K&amp;K Logic Puzzles â€£ 5 Experimental Results â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
Detailed hyperparameter settings are provided in AppendixÂ <a href="#A2" title="Appendix B Hyperparameter Settings â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>, and comprehensive experimental records can be found in AppendixÂ <a href="#A3.SS1.SSS1" title="C.1.1 K&amp;K Logic Puzzle â€£ C.1 Task Description â€£ Appendix C Experimental Details â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.1.1</span></a>.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p class="ltx_p">During the early stages of GRPO training (across all settings), the reward increases rapidly, but the growth slows significantly after the first epoch. Subsequently, the improvements introduced by <span class="ltx_text ltx_font_italic">Advantage Reweighting</span> and <span class="ltx_text ltx_font_italic">Lopti</span> become progressively more evident, particularly after 4 epochs.
Interestingly, for simpler tasks (involving fewer players), the performance gap between the baseline GRPO and the GRPO enhanced with <span class="ltx_text ltx_font_italic">Advantage Reweighting</span> and/or <span class="ltx_text ltx_font_italic">Lopti</span> is minimal. However, for more complex tasks with more players, the performance gap becomes significant.
In challenging tasks, positive samples are typically fewer and thus more valuable. As analyzed in SectionÂ <a href="#S4.SS2" title="4.2 Mitigating the Over-Dominance of Low-Probability Tokens â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>, high-probability tokens in these rare positive samples are not effectively amplified under standard GRPO training. Our method addresses this limitation, thereby resulting in substantial performance improvements.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p class="ltx_p">In addition, we perform a linguistic analysis to investigate the correlation between the modelâ€™s reasoning behavior and its final performance. Specifically, we use the model trained with naive GRPO to generate responses for the 500 prompts in the test set, sampling 8 responses per prompt, resulting in a total of 4,000 samples. For these samples, we analyze the frequency of six categories of inference-related words (see AppendixÂ <a href="#A3.SS1.SSS1" title="C.1.1 K&amp;K Logic Puzzle â€£ C.1 Task Description â€£ Appendix C Experimental Details â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.1.1</span></a> for details) and their corresponding rule-based rewards, as illustrated in FigureÂ <a href="#S5.F5" title="Figure 5 â€£ 5.1 Experiments on K&amp;K Logic Puzzles â€£ 5 Experimental Results â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>(a).
The analysis reveals a positive correlation between the frequency of words in the categories <span class="ltx_text ltx_font_italic">Analysis</span>, <span class="ltx_text ltx_font_italic">Statement</span>, and <span class="ltx_text ltx_font_italic">Causal Indicators</span> and the samplesâ€™ rewards. Conversely, the frequency of words in the categories <span class="ltx_text ltx_font_italic">Conclusion Indicator</span>, <span class="ltx_text ltx_font_italic">Assumption</span>, and <span class="ltx_text ltx_font_italic">Assertion</span> exhibits a negative correlation with the rewards.</p>
</div>
<div id="S5.SS1.p5" class="ltx_para">
<p class="ltx_p">It is worth noting that the statistical patterns observed in these six categories of words indirectly highlight the enhancement effects of our proposed <span class="ltx_text ltx_font_italic">Advantage Reweighting</span> and/or <span class="ltx_text ltx_font_italic">Lopti</span> mechanisms on GRPO training, as shown in FigureÂ <a href="#S5.F5" title="Figure 5 â€£ 5.1 Experiments on K&amp;K Logic Puzzles â€£ 5 Experimental Results â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>(b).
Notably, the frequency of words positively correlated with reward in the samples generated by our method is significantly higher than that of the baseline, while the frequency of words negatively correlated with reward is substantially lower.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Experiments on Math-related Datasets</h3>

<figure id="S5.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Experimental results on math-related datasets (DSR for DeepScaleR and ORZ for Open-Reasoner-Zero).
For <span class="ltx_text ltx_font_italic">Advantage Reweight</span>, <math id="S5.T1.m3" class="ltx_Math" alttext="\alpha" display="inline"><semantics><mi>Î±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math> is set to 0.1, and for <span class="ltx_text ltx_font_italic">Lopti</span>, <math id="S5.T1.m4" class="ltx_Math" alttext="\eta" display="inline"><semantics><mi>Î·</mi><annotation encoding="application/x-tex">\eta</annotation></semantics></math> is set to 0.5.
The evaluation accuracy(%) are averaged over the last three checkpoints to mitigate randomness.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:726292655pt;vertical-align:-726292655.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-27.9pt,0.0pt) scale(0.885964728230027,3542891) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr" style="background-color:#EFEFEF;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" style="background-color:#EFEFEF;padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Dataset</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Algorithms</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;">
<table class="ltx_tabular ltx_align_middle" style="background-color:#EFEFEF;">
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold">Olympiad</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold">Bench</span></td>
</tr>
</table>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Minerva</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;">
<table class="ltx_tabular ltx_align_middle" style="background-color:#EFEFEF;">
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold">MATH</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold">500</span></td>
</tr>
</table>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;">
<table class="ltx_tabular ltx_align_middle" style="background-color:#EFEFEF;">
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold">AMC</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold">avg@16</span></td>
</tr>
</table>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;">
<table class="ltx_tabular ltx_align_middle" style="background-color:#EFEFEF;">
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold">AIME24</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold">pass@16</span></td>
</tr>
</table>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;">
<table class="ltx_tabular ltx_align_middle" style="background-color:#EFEFEF;">
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold">AIME24</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold">avg@16</span></td>
</tr>
</table>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;">
<table class="ltx_tabular ltx_align_middle" style="background-color:#EFEFEF;">
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold">Avg.</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold">all</span></td>
</tr>
</table>
</th>
</tr>
<tr class="ltx_tr" style="background-color:#ECF4FF;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" style="background-color:#ECF4FF;padding-left:2.3pt;padding-right:2.3pt;" colspan="2"><span class="ltx_text ltx_font_bold" style="background-color:#ECF4FF;">Qwen2.5-7B</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="background-color:#ECF4FF;">27.64</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="background-color:#ECF4FF;">18.38</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="background-color:#ECF4FF;">63.00</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="background-color:#ECF4FF;">22.21</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="background-color:#ECF4FF;">30.00</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="background-color:#ECF4FF;">5.00</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="background-color:#ECF4FF;">27.71</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#9B9B9B;"><span class="ltx_text ltx_font_bold" style="color:#9B9B9B;">+ GRPO</span></span></th>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#9B9B9B;">36.50</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#9B9B9B;">29.66</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#9B9B9B;">74.67</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#9B9B9B;">47.72</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#9B9B9B;">28.89</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#9B9B9B;">16.46</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#9B9B9B;">38.98</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row" style="padding-left:2.3pt;padding-right:2.3pt;"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#F56B00;"><span class="ltx_text ltx_font_bold" style="color:#F56B00;">+ GRPO + Reweight</span></span></th>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#F56B00;">37.00</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#F56B00;">29.66</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#F56B00;">75.47</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#F56B00;">48.32</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#F56B00;">35.56</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#F56B00;">14.03</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#F56B00;">40.01</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-left:2.3pt;padding-right:2.3pt;">
<table class="ltx_tabular ltx_align_middle">
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold">DSR</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold">Uniform</span></td>
</tr>
</table>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#32BEE6;"><span class="ltx_text ltx_font_bold" style="color:#32BEE6;">+ GRPO + Lopti</span></span></th>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#32BEE6;">36.60</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#32BEE6;">30.27</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#32BEE6;">76.53</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#32BEE6;">47.69</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#32BEE6;">32.22</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#32BEE6;">14.24</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#32BEE6;">39.59</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#9B9B9B;"><span class="ltx_text ltx_font_bold" style="color:#9B9B9B;">+ GRPO</span></span></th>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#9B9B9B;">38.23</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#9B9B9B;">27.69</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#9B9B9B;">78.33</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#9B9B9B;">49.57</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#9B9B9B;">32.22</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#9B9B9B;">12.92</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#9B9B9B;">39.83</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row" style="padding-left:2.3pt;padding-right:2.3pt;"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#F56B00;"><span class="ltx_text ltx_font_bold" style="color:#F56B00;">+ GRPO + Reweight</span></span></th>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#F56B00;">40.81</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#F56B00;">29.04</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#F56B00;">77.80</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#F56B00;">49.07</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#F56B00;">33.33</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#F56B00;">16.46</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#F56B00;">41.09</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text ltx_font_bold">ORZ</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#32BEE6;"><span class="ltx_text ltx_font_bold" style="color:#32BEE6;">+ GRPO + Lopti</span></span></th>
<td class="ltx_td ltx_align_center ltx_border_b" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#32BEE6;">38.63</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#32BEE6;">29.78</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#32BEE6;">78.53</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#32BEE6;">47.29</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#32BEE6;">34.44</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#32BEE6;">15.28</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" style="padding-left:2.3pt;padding-right:2.3pt;"><span class="ltx_text" style="color:#32BEE6;">40.66</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S5.SS2.p1" class="ltx_para">
<p class="ltx_p">To assess the generalization capability of our proposed methods, we conduct additional experiments on math-related datasets. Consistent with the majority of prior studies, we utilize <span class="ltx_text ltx_font_typewriter">Qwen2.5-7B</span> as the base model and employ a straightforward rule-based reward. Specifically, a score of 1 is assigned for completely correct answers, while a score of 0 is given for all other cases.
We experiment with two different datasets. The first one is a subset containing 10k problems introduced by AdaRFTÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib42" title="" class="ltx_ref">shi2025efficient </a></cite>, which is sampled from DeepScaleRÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib37" title="" class="ltx_ref">deepscaler2025 </a></cite>. This dataset, referred to as DSR-Uniform, evenly covers problems across all difficulty levels and is specifically designed for <span class="ltx_text ltx_font_typewriter">Qwen2.5-7B</span>. We train this dataset for 5 epochs.
The second one is a dataset containing 57k problems introduced by Open-Reasoner-Zero (ORZ)Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib10" title="" class="ltx_ref">liu2025drgrpo </a></cite>.
For this dataset (ORZ), we train for 1 epoch.
Apart from the number of training epochs, all other hyperparameters (cf. AppendixÂ <a href="#A2" title="Appendix B Hyperparameter Settings â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>) are kept consistent across both datasets.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p class="ltx_p">We evaluate the LLMs after training on five benchmarks: Olympiad BenchÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib49" title="" class="ltx_ref">he2024olympiadbench </a></cite>, MinervaÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib50" title="" class="ltx_ref">lewkowycz2022solving </a></cite>, MATH-500Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib51" title="" class="ltx_ref">hendrycks2021math </a></cite>, AMCÂ 2022-2023, and AIMEÂ 2024. For the first three benchmarks, we use greedy sampling for evaluation. For the last two benchmarks, following most prior works, we sample 16 responses for each question and report the average accuracy (avg@16). Notably, AIMEÂ 2024 is an extremely challenging dataset; therefore, we also report pass@16, which considers a question correctly answered if at least one of the 16 responses is correct.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p class="ltx_p">The experimental results are summarized in TableÂ <a href="#S5.T1" title="Table 1 â€£ 5.2 Experiments on Math-related Datasets â€£ 5 Experimental Results â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
In contrast to the continual learning behavior observed in the K&amp;K Logic Puzzle dataset,
the test accuracy curve on the math-related dataset converges to a specific value within 100 steps and subsequently exhibits only minor fluctuations.
Despite this, the improvements introduced by our <span class="ltx_text ltx_font_italic">Advantage Reweighting</span> and <span class="ltx_text ltx_font_italic">Lopti</span> remain observable.
It is worth noting that the combined application of these two techniques does not result in further performance gains; therefore, we recommend using them individually for optimal results.
For detailed experimental records, please refer to AppendixÂ <a href="#A3.SS1.SSS2" title="C.1.2 Math Dataset â€£ C.1 Task Description â€£ Appendix C Experimental Details â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.1.2</span></a>.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Ablation Studies</h3>

<figure id="S5.F6" class="ltx_figure"><img src="/html/2505.12929/assets/fig/fig6.png" id="S5.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="297" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>
Ablation studies on the K&amp;K Logic Puzzles dataset.
(a) Effect of restricting updates to high-probability tokens.
(b) Effect of the token update order in <span class="ltx_text ltx_font_italic">Lopti</span>.
(c) Effect of the hyperparameter <math id="S5.F6.m3" class="ltx_Math" alttext="\alpha" display="inline"><semantics><mi>Î±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math> in <span class="ltx_text ltx_font_italic">Advantage Reweighting</span>.
(d) Effect of the hyperparameter <math id="S5.F6.m4" class="ltx_Math" alttext="\eta" display="inline"><semantics><mi>Î·</mi><annotation encoding="application/x-tex">\eta</annotation></semantics></math> in <span class="ltx_text ltx_font_italic">Lopti</span>.
</figcaption>
</figure>
<div id="S5.SS3.p1" class="ltx_para">
<p class="ltx_p">To better convey our motivation and demonstrate the effectiveness of the proposed methods, we perform ablation studies on the K&amp;K Logic Puzzles dataset.
The key conclusions derived from these studies are summarized in the following three points.</p>
</div>
<section id="S5.SS3.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">â€¢â€‰High-probability tokens matter in RL training.</h5>

<div id="S5.SS3.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p">Although the results in FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and FigureÂ <a href="#S4.F3" title="Figure 3 â€£ 4.2 Mitigating the Over-Dominance of Low-Probability Tokens â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> suggest that the gradients of high-probability tokens are almost suppressed by low-probability tokens during updates, the high-probability tokens remain crucial and cannot be disregarded. As shown in FigureÂ <a href="#S5.F6" title="Figure 6 â€£ 5.3 Ablation Studies â€£ 5 Experimental Results â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>(a), masking high-probability tokens leads to a significant degradation in the performance of the baseline GRPO.
Therefore, reducing the influence of low-probability tokens on high-probability ones holds great potential for advancing RL training, as anticipated.</p>
</div>
</section>
<section id="S5.SS3.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">â€¢â€‰The update order is the key for <span class="ltx_text ltx_font_italic">Lopti</span>.</h5>

<div id="S5.SS3.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p">The intuition behind <span class="ltx_text ltx_font_italic">Lopti</span>, as introduced in SectionÂ <a href="#S4.SS2" title="4.2 Mitigating the Over-Dominance of Low-Probability Tokens â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>, stems from the <span class="ltx_text ltx_font_italic">low-probability dominant effect</span> of incorrectly reduced positive high-probability tokens.
To confirm this intuition and rule out the possibility of random gains, we reverse the update order by processing high-probability tokens first, followed by low-probability tokens, as shown in FigureÂ <a href="#S5.F6" title="Figure 6 â€£ 5.3 Ablation Studies â€£ 5 Experimental Results â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>(b).
This modification leads to significantly worse performance compared to the GRPO baseline, with training even collapsing after the 4th epoch.</p>
</div>
</section>
<section id="S5.SS3.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">â€¢â€‰Proper hyperparameter tuning is essential for <span class="ltx_text ltx_font_italic">Advantage Reweighting</span> and <span class="ltx_text ltx_font_italic">Lopti</span>.</h5>

<div id="S5.SS3.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p">As introduced in SectionÂ <a href="#S4.SS2" title="4.2 Mitigating the Over-Dominance of Low-Probability Tokens â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>, <span class="ltx_text ltx_font_italic">Advantage Reweighting</span> involves the hyperparameter <math id="S5.SS3.SSS0.Px3.p1.m1" class="ltx_Math" alttext="\alpha" display="inline"><semantics><mi>Î±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>, while <span class="ltx_text ltx_font_italic">Lopti</span> depends on the hyperparameter <math id="S5.SS3.SSS0.Px3.p1.m2" class="ltx_Math" alttext="\eta" display="inline"><semantics><mi>Î·</mi><annotation encoding="application/x-tex">\eta</annotation></semantics></math>. For the K&amp;K Logic Puzzles dataset, the recommended ranges are <math id="S5.SS3.SSS0.Px3.p1.m3" class="ltx_Math" alttext="\alpha\in[0.2,0.3]" display="inline"><semantics><mrow><mi>Î±</mi><mo>âˆˆ</mo><mrow><mo stretchy="false">[</mo><mn>0.2</mn><mo>,</mo><mn>0.3</mn><mo stretchy="false">]</mo></mrow></mrow><annotation encoding="application/x-tex">\alpha\in[0.2,0.3]</annotation></semantics></math> and <math id="S5.SS3.SSS0.Px3.p1.m4" class="ltx_Math" alttext="\eta\in[0.3,0.5]" display="inline"><semantics><mrow><mi>Î·</mi><mo>âˆˆ</mo><mrow><mo stretchy="false">[</mo><mn>0.3</mn><mo>,</mo><mn>0.5</mn><mo stretchy="false">]</mo></mrow></mrow><annotation encoding="application/x-tex">\eta\in[0.3,0.5]</annotation></semantics></math>, as values outside these ranges may result in inferior performance compared to the GRPO baseline.
It is worth noting that the hyperparameter setting for <span class="ltx_text ltx_font_italic">Advantage Reweighting</span> is task-sensitive, whereas <span class="ltx_text ltx_font_italic">Lopti</span> demonstrates greater robustness in this regard. For math-related datasets, the optimal hyperparameter for <span class="ltx_text ltx_font_italic">Advantage Reweighting</span> is <math id="S5.SS3.SSS0.Px3.p1.m5" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics><mrow><mi>Î±</mi><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">\alpha=0.1</annotation></semantics></math>, while <span class="ltx_text ltx_font_italic">Lopti</span> maintains its robustness with <math id="S5.SS3.SSS0.Px3.p1.m6" class="ltx_Math" alttext="\eta=0.5" display="inline"><semantics><mrow><mi>Î·</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\eta=0.5</annotation></semantics></math>.</p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p class="ltx_p">In this paper, we identify a crucial issue in RL training for LLMs: the over-dominance of low-probability tokens in model updates due to their disproportionately large gradient magnitudes.
We substantiate this issue through both empirical observations and rigorous theoretical analysis.
To address this imbalance, we propose two novel approaches: <span class="ltx_text ltx_font_italic">Advantage Reweighting</span> and <span class="ltx_text ltx_font_italic">Lopti</span>.
These methods effectively mitigate gradient disparities by diminishing the undue influence of low-probability tokens, thereby facilitating more balanced and efficient updates for high-probability tokens.
Extensive experiments demonstrate the effectiveness of these approaches, showing consistent improvements in GRPO-trained LLMs across diverse base models and datasets.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El-Kishky, Aiden Low, Alec Helyar, Aleksander Madry, Alex Beutel, Alex Carney, etÂ al.

</span>
<span class="ltx_bibblock">OpenAI o1 system card.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2412.16720</span>, 2024.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, etÂ al.

</span>
<span class="ltx_bibblock">Deepseek-R1: Incentivizing reasoning capability in LLMs via reinforcement learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2501.12948</span>, 2025.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Kimi Team, Angang Du, Bofei Gao, Bowei Xing, Changjiu Jiang, Cheng Chen, Cheng Li, Chenjun Xiao, Chenzhuang Du, Chonghua Liao, etÂ al.

</span>
<span class="ltx_bibblock">Kimi k1.5: Scaling reinforcement learning with LLMs.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2501.12599</span>, 2025.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Yuxi Xie, Anirudh Goyal, Wenyue Zheng, Min-Yen Kan, TimothyÂ P Lillicrap, Kenji Kawaguchi, and Michael Shieh.

</span>
<span class="ltx_bibblock">Monte carlo tree search boosts reasoning via iterative preference learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">The First Workshop on System-2 Reasoning at Scale, NeurIPSâ€™24</span>, 2024.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Guoxin Chen, Minpeng Liao, Chengxi Li, and Kai Fan.

</span>
<span class="ltx_bibblock">Alphamath almost zero: Process supervision without process.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, volumeÂ 38, 2024.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Hunter Lightman, Vineet Kosaraju, Yuri Burda, Harrison Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe.

</span>
<span class="ltx_bibblock">Letâ€™s verify step by step.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">The Twelfth International Conference on Learning Representations</span>, 2024.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Peiyi Wang, Lei Li, Zhihong Shao, Runxin Xu, Damai Dai, Yifei Li, Deli Chen, YuÂ Wu, and Zhifang Sui.

</span>
<span class="ltx_bibblock">Math-shepherd: Verify and reinforce llms step-by-step without human annotations.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics</span>, 2024.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YKÂ Li, YÂ Wu, etÂ al.

</span>
<span class="ltx_bibblock">Deepseekmath: Pushing the limits of mathematical reasoning in open language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2402.03300</span>, 2024.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Qiying Yu, Zheng Zhang, Ruofei Zhu, Yufeng Yuan, Xiaochen Zuo, YuÂ Yue, Tiantian Fan, Gaohong Liu, Lingjun Liu, Xin Liu, etÂ al.

</span>
<span class="ltx_bibblock">DAPO: An open-source llm reinforcement learning system at scale.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.14476</span>, 2025.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Zichen Liu, Changyu Chen, Wenjun Li, Penghui Qi, Tianyu Pang, Chao Du, WeeÂ Sun Lee, and Min Lin.

</span>
<span class="ltx_bibblock">Understanding r1-zero-like training: A critical perspective.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.20783</span>, 2025.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Wei Xiong, Jiarui Yao, Yuhui Xu, BoÂ Pang, Lei Wang, Doyen Sahoo, Junnan Li, Nan Jiang, Tong Zhang, Caiming Xiong, etÂ al.

</span>
<span class="ltx_bibblock">A minimalist approach to llm reasoning: from rejection sampling to reinforce.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.11343</span>, 2025.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
PaulÂ F Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario Amodei.

</span>
<span class="ltx_bibblock">Deep reinforcement learning from human preferences.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, volumeÂ 31, 2017.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
DanielÂ M Ziegler, Nisan Stiennon, Jeffrey Wu, TomÂ B Brown, Alec Radford, Dario Amodei, Paul Christiano, and Geoffrey Irving.

</span>
<span class="ltx_bibblock">Fine-tuning language models from human preferences.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:1909.08593</span>, 2019.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, and PaulÂ F Christiano.

</span>
<span class="ltx_bibblock">Learning to summarize with human feedback.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, volumeÂ 34, 2020.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, XuÂ Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, etÂ al.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, volumeÂ 36, 2022.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.

</span>
<span class="ltx_bibblock">Proximal policy optimization algorithms.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:1707.06347</span>, 2017.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, JaredÂ D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, etÂ al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, volumeÂ 34, 2020.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, FlorenciaÂ Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, etÂ al.

</span>
<span class="ltx_bibblock">GPT-4 technical report.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2303.08774</span>, 2023.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, TimothÃ©e Lacroix, Baptiste RoziÃ¨re, Naman Goyal, Eric Hambro, Faisal Azhar, etÂ al.

</span>
<span class="ltx_bibblock">LLaMA: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2302.13971</span>, 2023.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, etÂ al.

</span>
<span class="ltx_bibblock">LLaMA 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.09288</span>, 2023.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, etÂ al.

</span>
<span class="ltx_bibblock">The LLaMA 3 herd of models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2407.21783</span>, 2024.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, YuÂ Han, Fei Huang, etÂ al.

</span>
<span class="ltx_bibblock">Qwen technical report.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2309.16609</span>, 2023.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Yunfei Chu, Jin Xu, Xiaohuan Zhou, Qian Yang, Shiliang Zhang, Zhijie Yan, Chang Zhou, and Jingren Zhou.

</span>
<span class="ltx_bibblock">Qwen-audio: Advancing universal audio understanding via unified large-scale audio-language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2311.07919</span>, 2023.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
AnÂ Yang, Baosong Yang, Binyuan Hui, BoÂ Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, etÂ al.

</span>
<span class="ltx_bibblock">Qwen2 technical report.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2407.10671</span>, 2024.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, AndrewÂ M Dai, Anja Hauth, Katie Millican, etÂ al.

</span>
<span class="ltx_bibblock">Gemini: a family of highly capable multimodal models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2312.11805</span>, 2023.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Gemini Team, Petko Georgiev, VingÂ Ian Lei, Ryan Burnell, Libin Bai, Anmol Gulati, Garrett Tanzer, Damien Vincent, Zhufeng Pan, Shibo Wang, etÂ al.

</span>
<span class="ltx_bibblock">Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2403.05530</span>, 2024.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Anthropic.

</span>
<span class="ltx_bibblock">The Claude 3 model family: Opus, sonnet, haiku.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Technical Report</span>, 2024.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Rafael Rafailov, Archit Sharma, Eric Mitchell, ChristopherÂ D Manning, Stefano Ermon, and Chelsea Finn.

</span>
<span class="ltx_bibblock">Direct preference optimization: Your language model is secretly a reward model.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, volumeÂ 37, 2023.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Rafael Rafailov, Joey Hejna, Ryan Park, and Chelsea Finn.

</span>
<span class="ltx_bibblock">From r to Q*: Your language model is secretly a Q-function.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">First Conference on Language Modeling</span>, 2024.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Shusheng Xu, Wei Fu, Jiaxuan Gao, Wenjie Ye, Weilin Liu, Zhiyu Mei, Guangju Wang, Chao Yu, and YiÂ Wu.

</span>
<span class="ltx_bibblock">Is DPO superior to PPO for LLM alignment? a comprehensive study.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, volumeÂ 41, 2024.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Han Zhong, Guhao Feng, Wei Xiong, Xinle Cheng, LiÂ Zhao, DiÂ He, Jiang Bian, and Liwei Wang.

</span>
<span class="ltx_bibblock">DPO meets PPO: Reinforced token optimization for RLHF.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">ICML 2024 Workshop on Models of Human Feedback for AI Alignment</span>, 2024.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
YiÂ Ren and DanicaÂ J. Sutherland.

</span>
<span class="ltx_bibblock">Learning dynamics of LLM finetuning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">The Thirteenth International Conference on Learning Representations</span>, 2025.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Jiwoo Hong, Noah Lee, and James Thorne.

</span>
<span class="ltx_bibblock">ORPO: Monolithic preference optimization without reference model.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing</span>, 2024.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Haoran Xu, Amr Sharaf, Yunmo Chen, Weiting Tan, Lingfeng Shen, Benjamin VanÂ Durme, Kenton Murray, and YoungÂ Jin Kim.

</span>
<span class="ltx_bibblock">Contrastive preference optimization: Pushing the boundaries of llm performance in machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, volumeÂ 41, 2024.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
YuÂ Meng, Mengzhou Xia, and Danqi Chen.

</span>
<span class="ltx_bibblock">SimPO: Simple preference optimization with a reference-free reward.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, volumeÂ 38, 2024.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, EdÂ Chi, QuocÂ V Le, Denny Zhou, etÂ al.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, volumeÂ 36, 2022.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Michael Luo, Sijun Tan, Justin Wong, Xiaoxiang Shi, WilliamÂ Y. Tang, Manan Roongta, Colin Cai, Jeffrey Luo, LiÂ Erran Li, RalucaÂ Ada Popa, and Ion Stoica.

</span>
<span class="ltx_bibblock">Deepscaler: Surpassing o1-preview with a 1.5b model by scaling rl.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Notion Blog</span>, 2025.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Tian Xie, Zitian Gao, Qingnan Ren, Haoming Luo, Yuqian Hong, Bryan Dai, Joey Zhou, Kai Qiu, Zhirong Wu, and Chong Luo.

</span>
<span class="ltx_bibblock">Logic-rl: Unleashing llm reasoning with rule-based reinforcement learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.14768</span>, 2025.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Jingcheng Hu, Yinmin Zhang, QiÂ Han, Daxin Jiang, Xiangyu Zhang, and Heung-Yeung Shum.

</span>
<span class="ltx_bibblock">Open-reasoner-zero: An open source approach to scaling up reinforcement learning on the base model.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.24290</span>, 2025.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Weihao Zeng, Yuzhen Huang, Qian Liu, Wei Liu, Keqing He, Zejun Ma, and Junxian He.

</span>
<span class="ltx_bibblock">Simplerl-zoo: Investigating and taming zero reinforcement learning for open base models in the wild.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.18892</span>, 2025.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Yufeng Yuan, Qiying Yu, Xiaochen Zuo, Ruofei Zhu, Wenyuan Xu, Jiaze Chen, Chengyi Wang, TianTian Fan, Zhengyin Du, Xiangpeng Wei, etÂ al.

</span>
<span class="ltx_bibblock">VAPO: Efficient and reliable reinforcement learning for advanced reasoning tasks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.05118</span>, 2025.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Taiwei Shi, Yiyang Wu, Linxin Song, Tianyi Zhou, and Jieyu Zhao.

</span>
<span class="ltx_bibblock">Efficient reinforcement finetuning via adaptive curriculum learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.05520</span>, 2025.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, AidanÂ N Gomez, Åukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, volumeÂ 30, 2017.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Guangming Sheng, Chi Zhang, Zilingfeng Ye, Xibin Wu, Wang Zhang, RuÂ Zhang, Yanghua Peng, Haibin Lin, and Chuan Wu.

</span>
<span class="ltx_bibblock">Hybridflow: A flexible and efficient RLHF framework.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Proceedings of the Twentieth European Conference on Computer Systems</span>, 2025.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Chulin Xie, Yangsibo Huang, Chiyuan Zhang, DaÂ Yu, Xinyun Chen, BillÂ Yuchen Lin, BoÂ Li, Badih Ghazi, and Ravi Kumar.

</span>
<span class="ltx_bibblock">On memorization of large language models in logical reasoning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2410.23123</span>, 2024.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Jian Hu.

</span>
<span class="ltx_bibblock">Reinforce++: A simple and efficient approach for aligning large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2501.03262</span>, 2025.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Raymond Smullyan.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">What is the name of this book?</span>

</span>
<span class="ltx_bibblock">Touchstone Books Guildford, UK, 1986.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
PhilipÂ N Johnson-Laird and RuthÂ MJ Byrne.

</span>
<span class="ltx_bibblock">Meta-logical problems: Knights, knaves, and rips.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Cognition</span>, 36(1):69â€“84, 1990.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Chaoqun He, Renjie Luo, Yuzhuo Bai, Shengding Hu, Zhen Thai, Junhao Shen, Jinyi Hu, XuÂ Han, Yujie Huang, Yuxiang Zhang, etÂ al.

</span>
<span class="ltx_bibblock">Olympiadbench: A challenging benchmark for promoting agi with olympiad-level bilingual multimodal scientific problems.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics</span>, 2024.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, etÂ al.

</span>
<span class="ltx_bibblock">Solving quantitative reasoning problems with language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, volumeÂ 36, 2022.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt.

</span>
<span class="ltx_bibblock">Measuring mathematical problem solving with the math dataset.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2103.03874</span>, 2021.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
John Schulman.

</span>
<span class="ltx_bibblock">Approximating KL divergence.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Technical Blog</span>, 2020.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
RonaldÂ J Williams.

</span>
<span class="ltx_bibblock">Simple statistical gradient-following algorithms for connectionist reinforcement learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Machine learning</span>, 8:229â€“256, 1992.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Theoretical Interpretations</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Gradient Derivation for the GRPO Objective</h3>

<div id="A1.SS1.p1" class="ltx_para">
<p class="ltx_p">For clarity, we re-state the objective function of GRPO below:</p>
</div>
<div id="A1.SS1.p2" class="ltx_para">
<table id="A1.E5" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="A1.E5X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A1.E5X.m2" class="ltx_Math" alttext="\displaystyle J_{GRPO}(\theta)" display="inline"><semantics><mrow><msub><mi mathsize="0.800em">J</mi><mrow><mi mathsize="0.800em">G</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">R</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">P</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">O</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mi mathsize="0.800em">Î¸</mi><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><annotation encoding="application/x-tex">\displaystyle J_{GRPO}(\theta)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E5X.m3" class="ltx_Math" alttext="\displaystyle=\mathbb{E}_{\bm{q}\sim\mathcal{D},\{\bm{o}_{i}\}_{i=1}^{G}\sim\pi_{old}}" display="inline"><semantics><mrow><mi></mi><mo mathsize="0.800em">=</mo><msub><mi mathsize="0.800em">ğ”¼</mi><mrow><mrow><mi mathsize="0.800em">ğ’’</mi><mo mathsize="0.800em">âˆ¼</mo><mi class="ltx_font_mathcaligraphic" mathsize="0.800em">ğ’Ÿ</mi></mrow><mo mathsize="0.800em">,</mo><mrow><msubsup><mrow><mo maxsize="0.800em" minsize="0.800em">{</mo><msub><mi mathsize="0.800em">ğ’</mi><mi mathsize="0.800em">i</mi></msub><mo maxsize="0.800em" minsize="0.800em">}</mo></mrow><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">=</mo><mn mathsize="0.800em">1</mn></mrow><mi mathsize="0.800em">G</mi></msubsup><mo mathsize="0.800em">âˆ¼</mo><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">d</mi></mrow></msub></mrow></mrow></msub></mrow><annotation encoding="application/x-tex">\displaystyle=\mathbb{E}_{\bm{q}\sim\mathcal{D},\{\bm{o}_{i}\}_{i=1}^{G}\sim\pi_{old}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="3" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(5)</span></td>
</tr>
<tr id="A1.E5Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E5Xa.m2" class="ltx_Math" alttext="\displaystyle\frac{1}{\sum_{i=1}^{G}|\bm{o}_{i}|}\sum_{i=1}^{G}\sum_{t=1}^{|\bm{o}_{i}|}\left\{\underbrace{\min\left[r_{i,t}(\theta)\hat{A}_{i},\mathrm{clip}(r_{i,t}(\theta);1-\epsilon_{l},1+\epsilon_{h})\hat{A}_{i}\right]}_{J_{policy}(\theta)}-\underbrace{\beta\,\mathbb{D}_{\mathrm{KL}}\left[\pi_{\theta}\|\pi_{ref}\right]}_{J_{KL}(\theta)}\right\}" display="inline"><semantics><mrow><mstyle displaystyle="true"><mfrac><mn mathsize="0.800em">1</mn><mrow><msubsup><mo maxsize="0.800em" minsize="0.800em" stretchy="true">âˆ‘</mo><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">=</mo><mn mathsize="0.800em">1</mn></mrow><mi mathsize="0.800em">G</mi></msubsup><mrow><mo lspace="0em" maxsize="0.800em" minsize="0.800em" stretchy="true">|</mo><msub><mi mathsize="0.800em">ğ’</mi><mi mathsize="0.800em">i</mi></msub><mo maxsize="0.800em" minsize="0.800em" stretchy="true">|</mo></mrow></mrow></mfrac></mstyle><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mstyle displaystyle="true"><munderover><mo maxsize="0.800em" minsize="0.800em" movablelimits="false" stretchy="true">âˆ‘</mo><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">=</mo><mn mathsize="0.800em">1</mn></mrow><mi mathsize="0.800em">G</mi></munderover></mstyle><mrow><mstyle displaystyle="true"><munderover><mo maxsize="0.800em" minsize="0.800em" movablelimits="false" stretchy="true">âˆ‘</mo><mrow><mi mathsize="0.800em">t</mi><mo mathsize="0.800em">=</mo><mn mathsize="0.800em">1</mn></mrow><mrow><mo maxsize="0.800em" minsize="0.800em" stretchy="true">|</mo><msub><mi mathsize="0.800em">ğ’</mi><mi mathsize="0.800em">i</mi></msub><mo maxsize="0.800em" minsize="0.800em" stretchy="true">|</mo></mrow></munderover></mstyle><mrow><mo>{</mo><mrow><munder><munder accentunder="true"><mrow><mi mathsize="0.800em">min</mi><mo>â¡</mo><mrow><mo>[</mo><mrow><msub><mi mathsize="0.800em">r</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mi mathsize="0.800em">Î¸</mi><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow><mo lspace="0em" rspace="0em">â€‹</mo><msub><mover accent="true"><mi mathsize="0.800em">A</mi><mo mathsize="0.800em">^</mo></mover><mi mathsize="0.800em">i</mi></msub></mrow><mo mathsize="0.800em">,</mo><mrow><mi mathsize="0.800em">clip</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mrow><msub><mi mathsize="0.800em">r</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mi mathsize="0.800em">Î¸</mi><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mo mathsize="0.800em">;</mo><mrow><mn mathsize="0.800em">1</mn><mo mathsize="0.800em">âˆ’</mo><msub><mi mathsize="0.800em">Ïµ</mi><mi mathsize="0.800em">l</mi></msub></mrow><mo mathsize="0.800em">,</mo><mrow><mn mathsize="0.800em">1</mn><mo mathsize="0.800em">+</mo><msub><mi mathsize="0.800em">Ïµ</mi><mi mathsize="0.800em">h</mi></msub></mrow><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow><mo lspace="0em" rspace="0em">â€‹</mo><msub><mover accent="true"><mi mathsize="0.800em">A</mi><mo mathsize="0.800em">^</mo></mover><mi mathsize="0.800em">i</mi></msub></mrow><mo>]</mo></mrow></mrow><mo stretchy="true">âŸ</mo></munder><mrow><msub><mi mathsize="0.800em">J</mi><mrow><mi mathsize="0.800em">p</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">i</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">c</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">y</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mi mathsize="0.800em">Î¸</mi><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow></munder><mo mathsize="0.800em">âˆ’</mo><munder><munder accentunder="true"><mrow><mi mathsize="0.800em">Î²</mi><mo lspace="0.170em" rspace="0em">â€‹</mo><msub><mi mathsize="0.800em">ğ”»</mi><mi mathsize="0.800em">KL</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo>[</mo><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo mathsize="0.800em">âˆ¥</mo><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">f</mi></mrow></msub></mrow><mo>]</mo></mrow></mrow><mo stretchy="true">âŸ</mo></munder><mrow><msub><mi mathsize="0.800em">J</mi><mrow><mi mathsize="0.800em">K</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">L</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mi mathsize="0.800em">Î¸</mi><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow></munder></mrow><mo>}</mo></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\frac{1}{\sum_{i=1}^{G}|\bm{o}_{i}|}\sum_{i=1}^{G}\sum_{t=1}^{|\bm{o}_{i}|}\left\{\underbrace{\min\left[r_{i,t}(\theta)\hat{A}_{i},\mathrm{clip}(r_{i,t}(\theta);1-\epsilon_{l},1+\epsilon_{h})\hat{A}_{i}\right]}_{J_{policy}(\theta)}-\underbrace{\beta\,\mathbb{D}_{\mathrm{KL}}\left[\pi_{\theta}\|\pi_{ref}\right]}_{J_{KL}(\theta)}\right\}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="A1.E5Xb" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A1.E5Xb.m2" class="ltx_Math" alttext="\displaystyle\mathrm{with}" display="inline"><semantics><mi mathsize="0.800em">with</mi><annotation encoding="application/x-tex">\displaystyle\mathrm{with}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E5Xb.m3" class="ltx_Math" alttext="\displaystyle r_{i,t}(\theta)=\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})},\mathrm{and}\,\,\mathbb{D}_{\mathrm{KL}}\left[\pi_{\theta}\|\pi_{ref}\right]=\frac{\pi_{ref}(o_{i,t})}{\pi_{\theta}(o_{i,t})}-\log\frac{\pi_{ref}(o_{i,t})}{\pi_{\theta}(o_{i,t})}-1." display="inline"><semantics><mrow><mrow><mrow><mrow><msub><mi mathsize="0.800em">r</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mi mathsize="0.800em">Î¸</mi><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mo mathsize="0.800em">=</mo><mstyle displaystyle="true"><mfrac><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mrow><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow></mfrac></mstyle></mrow><mo mathsize="0.800em">,</mo><mrow><mrow><mi mathsize="0.800em">and</mi><mo lspace="0.330em" rspace="0em">â€‹</mo><msub><mi mathsize="0.800em">ğ”»</mi><mi mathsize="0.800em">KL</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo>[</mo><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo mathsize="0.800em">âˆ¥</mo><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">f</mi></mrow></msub></mrow><mo>]</mo></mrow></mrow><mo mathsize="0.800em">=</mo><mrow><mstyle displaystyle="true"><mfrac><mrow><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">f</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow></mfrac></mstyle><mo mathsize="0.800em">âˆ’</mo><mrow><mi mathsize="0.800em">log</mi><mo lspace="0.167em">â¡</mo><mstyle displaystyle="true"><mfrac><mrow><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">f</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow></mfrac></mstyle></mrow><mo mathsize="0.800em">âˆ’</mo><mn mathsize="0.800em">1</mn></mrow></mrow></mrow><mo lspace="0em" mathsize="0.800em">.</mo></mrow><annotation encoding="application/x-tex">\displaystyle r_{i,t}(\theta)=\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})},\mathrm{and}\,\,\mathbb{D}_{\mathrm{KL}}\left[\pi_{\theta}\|\pi_{ref}\right]=\frac{\pi_{ref}(o_{i,t})}{\pi_{\theta}(o_{i,t})}-\log\frac{\pi_{ref}(o_{i,t})}{\pi_{\theta}(o_{i,t})}-1.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
</div>
<div id="A1.SS1.p3" class="ltx_para">
<p class="ltx_p">We begin by analyzing the policy loss term <math id="A1.SS1.p3.m1" class="ltx_Math" alttext="J_{policy}(\theta)" display="inline"><semantics><mrow><msub><mi>J</mi><mrow><mi>p</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>i</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>c</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>y</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>Î¸</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">J_{policy}(\theta)</annotation></semantics></math>, which originates from the PPO clipping mechanismÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.
Note that for samples with positive advantage estimates (i.e., <math id="A1.SS1.p3.m2" class="ltx_Math" alttext="\hat{A}_{i}&gt;0" display="inline"><semantics><mrow><msub><mover accent="true"><mi>A</mi><mo>^</mo></mover><mi>i</mi></msub><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\hat{A}_{i}&gt;0</annotation></semantics></math>), the clipping is activated only when <math id="A1.SS1.p3.m3" class="ltx_Math" alttext="r_{i,t}(\theta)&gt;1+\epsilon_{h}" display="inline"><semantics><mrow><mrow><msub><mi>r</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>Î¸</mi><mo stretchy="false">)</mo></mrow></mrow><mo>&gt;</mo><mrow><mn>1</mn><mo>+</mo><msub><mi>Ïµ</mi><mi>h</mi></msub></mrow></mrow><annotation encoding="application/x-tex">r_{i,t}(\theta)&gt;1+\epsilon_{h}</annotation></semantics></math>. Conversely, for samples with negative advantage estimates (i.e., <math id="A1.SS1.p3.m4" class="ltx_Math" alttext="\hat{A}_{i}&lt;0" display="inline"><semantics><mrow><msub><mover accent="true"><mi>A</mi><mo>^</mo></mover><mi>i</mi></msub><mo>&lt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\hat{A}_{i}&lt;0</annotation></semantics></math>), the clipping becomes active only when <math id="A1.SS1.p3.m5" class="ltx_Math" alttext="r_{i,t}(\theta)&lt;1+\epsilon_{l}" display="inline"><semantics><mrow><mrow><msub><mi>r</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>Î¸</mi><mo stretchy="false">)</mo></mrow></mrow><mo>&lt;</mo><mrow><mn>1</mn><mo>+</mo><msub><mi>Ïµ</mi><mi>l</mi></msub></mrow></mrow><annotation encoding="application/x-tex">r_{i,t}(\theta)&lt;1+\epsilon_{l}</annotation></semantics></math>.
Consequently, when clipping is active, the gradient <math id="A1.SS1.p3.m6" class="ltx_Math" alttext="\nabla_{\theta}J_{policy}(\theta)" display="inline"><semantics><mrow><mrow><msub><mo>âˆ‡</mo><mi>Î¸</mi></msub><msub><mi>J</mi><mrow><mi>p</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>i</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>c</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>y</mi></mrow></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>Î¸</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\nabla_{\theta}J_{policy}(\theta)</annotation></semantics></math> is zero; otherwise, it simplifies to <math id="A1.SS1.p3.m7" class="ltx_Math" alttext="\nabla_{\theta}r_{i,t}(\theta)\cdot\hat{A}_{i}" display="inline"><semantics><mrow><mrow><mrow><msub><mo>âˆ‡</mo><mi>Î¸</mi></msub><msub><mi>r</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>Î¸</mi><mo rspace="0.055em" stretchy="false">)</mo></mrow></mrow><mo rspace="0.222em">â‹…</mo><msub><mover accent="true"><mi>A</mi><mo>^</mo></mover><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\nabla_{\theta}r_{i,t}(\theta)\cdot\hat{A}_{i}</annotation></semantics></math>.
In summary, we can express the gradient of <math id="A1.SS1.p3.m8" class="ltx_Math" alttext="J_{policy}(\theta)" display="inline"><semantics><mrow><msub><mi>J</mi><mrow><mi>p</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>i</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>c</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>y</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>Î¸</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">J_{policy}(\theta)</annotation></semantics></math> as</p>
</div>
<div id="A1.SS1.p4" class="ltx_para">
<table id="A1.E6" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="A1.E6X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A1.E6X.m2" class="ltx_Math" alttext="\displaystyle\nabla_{\theta}J_{policy}(\theta)" display="inline"><semantics><mrow><mrow><msub><mo>âˆ‡</mo><mi>Î¸</mi></msub><msub><mi>J</mi><mrow><mi>p</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>i</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>c</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>y</mi></mrow></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>Î¸</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\nabla_{\theta}J_{policy}(\theta)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E6X.m3" class="ltx_Math" alttext="\displaystyle=\frac{\nabla_{\theta}\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})}\cdot\hat{A}_{i}\cdot\mathbb{I}_{\mathrm{trust}}(\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})},\hat{A}_{i})" display="inline"><semantics><mrow><mi></mi><mo>=</mo><mrow><mrow><mstyle displaystyle="true"><mfrac><mrow><mrow><msub><mo>âˆ‡</mo><mi>Î¸</mi></msub><msub><mi>Ï€</mi><mi>Î¸</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mrow><msub><mi>Ï€</mi><mrow><mi>o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mfrac></mstyle><mo lspace="0.222em" rspace="0.222em">â‹…</mo><msub><mover accent="true"><mi>A</mi><mo>^</mo></mover><mi>i</mi></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><msub><mi>ğ•€</mi><mi>trust</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mstyle displaystyle="true"><mfrac><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mrow><msub><mi>Ï€</mi><mrow><mi>o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mfrac></mstyle><mo>,</mo><msub><mover accent="true"><mi>A</mi><mo>^</mo></mover><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=\frac{\nabla_{\theta}\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})}\cdot\hat{A}_{i}\cdot\mathbb{I}_{\mathrm{trust}}(\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})},\hat{A}_{i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="3" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(6)</span></td>
</tr>
<tr id="A1.E6Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E6Xa.m2" class="ltx_Math" alttext="\displaystyle=\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})}\cdot\hat{A}_{i}\cdot\mathbb{I}_{\mathrm{trust}}(\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})},\hat{A}_{i})\nabla_{\theta}\log\pi_{\theta}(o_{i,t})" display="inline"><semantics><mrow><mi></mi><mo>=</mo><mrow><mrow><mstyle displaystyle="true"><mfrac><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mrow><msub><mi>Ï€</mi><mrow><mi>o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mfrac></mstyle><mo lspace="0.222em" rspace="0.222em">â‹…</mo><msub><mover accent="true"><mi>A</mi><mo>^</mo></mover><mi>i</mi></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><msub><mi>ğ•€</mi><mi>trust</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mstyle displaystyle="true"><mfrac><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mrow><msub><mi>Ï€</mi><mrow><mi>o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mfrac></mstyle><mo>,</mo><msub><mover accent="true"><mi>A</mi><mo>^</mo></mover><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mo lspace="0.167em" rspace="0em">â€‹</mo><mrow><mrow><msub><mo rspace="0.167em">âˆ‡</mo><mi>Î¸</mi></msub><mi>log</mi></mrow><mo lspace="0.167em">â¡</mo><msub><mi>Ï€</mi><mi>Î¸</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})}\cdot\hat{A}_{i}\cdot\mathbb{I}_{\mathrm{trust}}(\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})},\hat{A}_{i})\nabla_{\theta}\log\pi_{\theta}(o_{i,t})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="A1.E6Xb" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A1.E6Xb.m2" class="ltx_Math" alttext="\displaystyle\mathrm{where}" display="inline"><semantics><mi>where</mi><annotation encoding="application/x-tex">\displaystyle\mathrm{where}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E6Xb.m3" class="ltx_Math" alttext="\displaystyle\mathbb{I}_{\mathrm{trust}}(\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})},\hat{A}_{i})=\left\{\begin{array}[]{ll}0&amp;\left\{\begin{array}[]{l}\mathrm{if}\,\,\hat{A}_{i}&gt;0\,\,\mathrm{and}\,\,\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})}&gt;1+\epsilon_{h}\\
\mathrm{if}\,\,\hat{A}_{i}&lt;0\,\,\mathrm{and}\,\,\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})}&lt;1-\epsilon_{l}\end{array}\right.\\
1&amp;\mathrm{otherwise}\end{array}\right.." display="inline"><semantics><mrow><mrow><mrow><msub><mi>ğ•€</mi><mi>trust</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mstyle displaystyle="true"><mfrac><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mrow><msub><mi>Ï€</mi><mrow><mi>o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mfrac></mstyle><mo>,</mo><msub><mover accent="true"><mi>A</mi><mo>^</mo></mover><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing="5pt" rowspacing="0pt"><mtr><mtd class="ltx_align_left" columnalign="left"><mn>0</mn></mtd><mtd class="ltx_align_left" columnalign="left"><mrow><mo>{</mo><mtable rowspacing="0pt"><mtr><mtd class="ltx_align_left" columnalign="left"><mrow><mrow><mi>if</mi><mo lspace="0.330em" rspace="0em">â€‹</mo><msub><mover accent="true"><mi>A</mi><mo>^</mo></mover><mi>i</mi></msub></mrow><mo>&gt;</mo><mrow><mn>0</mn><mo lspace="0.330em" rspace="0em">â€‹</mo><mi>and</mi><mo lspace="0.330em" rspace="0em">â€‹</mo><mfrac><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mrow><msub><mi>Ï€</mi><mrow><mi>o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mfrac></mrow><mo>&gt;</mo><mrow><mn>1</mn><mo>+</mo><msub><mi>Ïµ</mi><mi>h</mi></msub></mrow></mrow></mtd></mtr><mtr><mtd class="ltx_align_left" columnalign="left"><mrow><mrow><mi>if</mi><mo lspace="0.330em" rspace="0em">â€‹</mo><msub><mover accent="true"><mi>A</mi><mo>^</mo></mover><mi>i</mi></msub></mrow><mo>&lt;</mo><mrow><mn>0</mn><mo lspace="0.330em" rspace="0em">â€‹</mo><mi>and</mi><mo lspace="0.330em" rspace="0em">â€‹</mo><mfrac><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mrow><msub><mi>Ï€</mi><mrow><mi>o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mfrac></mrow><mo>&lt;</mo><mrow><mn>1</mn><mo>âˆ’</mo><msub><mi>Ïµ</mi><mi>l</mi></msub></mrow></mrow></mtd></mtr></mtable><mi></mi></mrow></mtd></mtr><mtr><mtd class="ltx_align_left" columnalign="left"><mn>1</mn></mtd><mtd class="ltx_align_left" columnalign="left"><mi>otherwise</mi></mtd></mtr></mtable><mi></mi></mrow></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\displaystyle\mathbb{I}_{\mathrm{trust}}(\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})},\hat{A}_{i})=\left\{\begin{array}[]{ll}0&amp;\left\{\begin{array}[]{l}\mathrm{if}\,\,\hat{A}_{i}&gt;0\,\,\mathrm{and}\,\,\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})}&gt;1+\epsilon_{h}\\
\mathrm{if}\,\,\hat{A}_{i}&lt;0\,\,\mathrm{and}\,\,\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})}&lt;1-\epsilon_{l}\end{array}\right.\\
1&amp;\mathrm{otherwise}\end{array}\right..</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
</div>
<div id="A1.SS1.p5" class="ltx_para">
<p class="ltx_p">Next, we consider the KL constraint term <math id="A1.SS1.p5.m1" class="ltx_Math" alttext="J_{KL}(\theta)" display="inline"><semantics><mrow><msub><mi>J</mi><mrow><mi>K</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>L</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>Î¸</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">J_{KL}(\theta)</annotation></semantics></math>, commonly referred to as <math id="A1.SS1.p5.m2" class="ltx_Math" alttext="k_{3}" display="inline"><semantics><msub><mi>k</mi><mn>3</mn></msub><annotation encoding="application/x-tex">k_{3}</annotation></semantics></math> estimationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>. It provides an unbiased estimate of the KL divergence between the current policy and the reference policy. The gradient of <math id="A1.SS1.p5.m3" class="ltx_Math" alttext="J_{KL}(\theta)" display="inline"><semantics><mrow><msub><mi>J</mi><mrow><mi>K</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>L</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>Î¸</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">J_{KL}(\theta)</annotation></semantics></math> is given by:</p>
</div>
<div id="A1.SS1.p6" class="ltx_para">
<table id="A1.E7" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="A1.E7X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A1.E7X.m2" class="ltx_Math" alttext="\displaystyle\nabla_{\theta}J_{KL}(\theta)" display="inline"><semantics><mrow><mrow><msub><mo>âˆ‡</mo><mi>Î¸</mi></msub><msub><mi>J</mi><mrow><mi>K</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>L</mi></mrow></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>Î¸</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\nabla_{\theta}J_{KL}(\theta)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E7X.m3" class="ltx_Math" alttext="\displaystyle=\beta\nabla_{\theta}\frac{\pi_{ref}(o_{i,t})}{\pi_{\theta}(o_{i,t})}+\beta\nabla_{\theta}\log\pi_{\theta}(o_{i,t})" display="inline"><semantics><mrow><mi></mi><mo>=</mo><mrow><mrow><mi>Î²</mi><mo lspace="0.167em" rspace="0em">â€‹</mo><mrow><msub><mo rspace="0.167em">âˆ‡</mo><mi>Î¸</mi></msub><mstyle displaystyle="true"><mfrac><mrow><msub><mi>Ï€</mi><mrow><mi>r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>f</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mfrac></mstyle></mrow></mrow><mo>+</mo><mrow><mi>Î²</mi><mo lspace="0.167em" rspace="0em">â€‹</mo><mrow><mrow><msub><mo rspace="0.167em">âˆ‡</mo><mi>Î¸</mi></msub><mi>log</mi></mrow><mo lspace="0.167em">â¡</mo><msub><mi>Ï€</mi><mi>Î¸</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=\beta\nabla_{\theta}\frac{\pi_{ref}(o_{i,t})}{\pi_{\theta}(o_{i,t})}+\beta\nabla_{\theta}\log\pi_{\theta}(o_{i,t})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="3" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(7)</span></td>
</tr>
<tr id="A1.E7Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E7Xa.m2" class="ltx_Math" alttext="\displaystyle=-\beta\frac{\pi_{ref}(o_{i,t})}{\pi_{\theta}(o_{i,t})^{2}}\nabla_{\theta}\pi_{\theta}(o_{i,t})+\beta\nabla_{\theta}\log\pi_{\theta}(o_{i,t})" display="inline"><semantics><mrow><mi></mi><mo>=</mo><mrow><mrow><mo>âˆ’</mo><mrow><mi>Î²</mi><mo lspace="0em" rspace="0em">â€‹</mo><mstyle displaystyle="true"><mfrac><mrow><msub><mi>Ï€</mi><mrow><mi>r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>f</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><msup><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow><mn>2</mn></msup></mrow></mfrac></mstyle><mo lspace="0.167em" rspace="0em">â€‹</mo><mrow><msub><mo rspace="0.167em">âˆ‡</mo><mi>Î¸</mi></msub><msub><mi>Ï€</mi><mi>Î¸</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>+</mo><mrow><mi>Î²</mi><mo lspace="0.167em" rspace="0em">â€‹</mo><mrow><mrow><msub><mo rspace="0.167em">âˆ‡</mo><mi>Î¸</mi></msub><mi>log</mi></mrow><mo lspace="0.167em">â¡</mo><msub><mi>Ï€</mi><mi>Î¸</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=-\beta\frac{\pi_{ref}(o_{i,t})}{\pi_{\theta}(o_{i,t})^{2}}\nabla_{\theta}\pi_{\theta}(o_{i,t})+\beta\nabla_{\theta}\log\pi_{\theta}(o_{i,t})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="A1.E7Xb" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E7Xb.m2" class="ltx_Math" alttext="\displaystyle=-\left[\beta\frac{\pi_{ref}(o_{i,t})}{\pi_{\theta}(o_{i,t})}-\beta\right]\nabla_{\theta}\log\pi_{\theta}(o_{i,t})." display="inline"><semantics><mrow><mrow><mi></mi><mo>=</mo><mrow><mo>âˆ’</mo><mrow><mrow><mo>[</mo><mrow><mrow><mi>Î²</mi><mo lspace="0em" rspace="0em">â€‹</mo><mstyle displaystyle="true"><mfrac><mrow><msub><mi>Ï€</mi><mrow><mi>r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>f</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mfrac></mstyle></mrow><mo>âˆ’</mo><mi>Î²</mi></mrow><mo>]</mo></mrow><mo lspace="0.167em" rspace="0em">â€‹</mo><mrow><mrow><msub><mo rspace="0.167em">âˆ‡</mo><mi>Î¸</mi></msub><mi>log</mi></mrow><mo lspace="0.167em">â¡</mo><msub><mi>Ï€</mi><mi>Î¸</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\displaystyle=-\left[\beta\frac{\pi_{ref}(o_{i,t})}{\pi_{\theta}(o_{i,t})}-\beta\right]\nabla_{\theta}\log\pi_{\theta}(o_{i,t}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
</div>
<div id="A1.SS1.p7" class="ltx_para">
<p class="ltx_p">By combining Eqs.Â (<a href="#A1.E6" title="In A.1 Gradient Derivation for the GRPO Objective â€£ Appendix A Theoretical Interpretations â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>) and (<a href="#A1.E7" title="In A.1 Gradient Derivation for the GRPO Objective â€£ Appendix A Theoretical Interpretations â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>), we finally obtain the gradient of GRPO objective in the following form.</p>
</div>
<div id="A1.SS1.p8" class="ltx_para">
<table id="A1.E8" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="A1.E8X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A1.E8X.m2" class="ltx_Math" alttext="\displaystyle\nabla_{\theta}J_{GRPO}(\theta)" display="inline"><semantics><mrow><mrow><msub><mo mathsize="0.800em">âˆ‡</mo><mi mathsize="0.800em">Î¸</mi></msub><msub><mi mathsize="0.800em">J</mi><mrow><mi mathsize="0.800em">G</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">R</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">P</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">O</mi></mrow></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mi mathsize="0.800em">Î¸</mi><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\nabla_{\theta}J_{GRPO}(\theta)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E8X.m3" class="ltx_Math" alttext="\displaystyle=\mathbb{E}_{\bm{q}\sim\mathcal{D},\{\bm{o}_{i}\}_{i=1}^{G}\sim\pi_{old}}\frac{1}{\sum_{i=1}^{G}|\bm{o}_{i}|}\sum_{i=1}^{G}\sum_{t=1}^{|\bm{o}_{i}|}" display="inline"><semantics><mrow><mi></mi><mo mathsize="0.800em">=</mo><mrow><msub><mi mathsize="0.800em">ğ”¼</mi><mrow><mrow><mi mathsize="0.800em">ğ’’</mi><mo mathsize="0.800em">âˆ¼</mo><mi class="ltx_font_mathcaligraphic" mathsize="0.800em">ğ’Ÿ</mi></mrow><mo mathsize="0.800em">,</mo><mrow><msubsup><mrow><mo maxsize="0.800em" minsize="0.800em">{</mo><msub><mi mathsize="0.800em">ğ’</mi><mi mathsize="0.800em">i</mi></msub><mo maxsize="0.800em" minsize="0.800em">}</mo></mrow><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">=</mo><mn mathsize="0.800em">1</mn></mrow><mi mathsize="0.800em">G</mi></msubsup><mo mathsize="0.800em">âˆ¼</mo><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">d</mi></mrow></msub></mrow></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mstyle displaystyle="true"><mfrac><mn mathsize="0.800em">1</mn><mrow><msubsup><mo maxsize="0.800em" minsize="0.800em" stretchy="true">âˆ‘</mo><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">=</mo><mn mathsize="0.800em">1</mn></mrow><mi mathsize="0.800em">G</mi></msubsup><mrow><mo lspace="0em" maxsize="0.800em" minsize="0.800em" stretchy="true">|</mo><msub><mi mathsize="0.800em">ğ’</mi><mi mathsize="0.800em">i</mi></msub><mo maxsize="0.800em" minsize="0.800em" stretchy="true">|</mo></mrow></mrow></mfrac></mstyle><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mstyle displaystyle="true"><munderover><mo maxsize="0.800em" minsize="0.800em" movablelimits="false" stretchy="true">âˆ‘</mo><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">=</mo><mn mathsize="0.800em">1</mn></mrow><mi mathsize="0.800em">G</mi></munderover></mstyle><mstyle displaystyle="true"><munderover><mo maxsize="0.800em" minsize="0.800em" movablelimits="false" stretchy="true">âˆ‘</mo><mrow><mi mathsize="0.800em">t</mi><mo mathsize="0.800em">=</mo><mn mathsize="0.800em">1</mn></mrow><mrow><mo maxsize="0.800em" minsize="0.800em" stretchy="true">|</mo><msub><mi mathsize="0.800em">ğ’</mi><mi mathsize="0.800em">i</mi></msub><mo maxsize="0.800em" minsize="0.800em" stretchy="true">|</mo></mrow></munderover></mstyle></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=\mathbb{E}_{\bm{q}\sim\mathcal{D},\{\bm{o}_{i}\}_{i=1}^{G}\sim\pi_{old}}\frac{1}{\sum_{i=1}^{G}|\bm{o}_{i}|}\sum_{i=1}^{G}\sum_{t=1}^{|\bm{o}_{i}|}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="3" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(8)</span></td>
</tr>
<tr id="A1.E8Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E8Xa.m2" class="ltx_Math" alttext="\displaystyle\underbrace{\left[\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})}\hat{A}_{i}\cdot\mathbb{I}_{\mathrm{trust}}(\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})},\hat{A}_{i})+\beta\frac{\pi_{ref}(o_{i,t})}{\pi_{\theta}(o_{i,t})}-\beta\right]}_{w_{i,t}}\cdot\nabla_{\theta}\log\pi_{\theta}(o_{i,t})," display="inline"><semantics><mrow><mrow><mrow><munder><munder accentunder="true"><mrow><mo>[</mo><mrow><mrow><mrow><mrow><mrow><mstyle displaystyle="true"><mfrac><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mrow><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow></mfrac></mstyle><mo lspace="0em" rspace="0em">â€‹</mo><msub><mover accent="true"><mi mathsize="0.800em">A</mi><mo mathsize="0.800em">^</mo></mover><mi mathsize="0.800em">i</mi></msub></mrow><mo lspace="0.222em" mathsize="0.800em" rspace="0.222em">â‹…</mo><msub><mi mathsize="0.800em">ğ•€</mi><mi mathsize="0.800em">trust</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mstyle displaystyle="true"><mfrac><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mrow><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow></mfrac></mstyle><mo mathsize="0.800em">,</mo><msub><mover accent="true"><mi mathsize="0.800em">A</mi><mo mathsize="0.800em">^</mo></mover><mi mathsize="0.800em">i</mi></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mo mathsize="0.800em">+</mo><mrow><mi mathsize="0.800em">Î²</mi><mo lspace="0em" rspace="0em">â€‹</mo><mstyle displaystyle="true"><mfrac><mrow><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">f</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow></mfrac></mstyle></mrow></mrow><mo mathsize="0.800em">âˆ’</mo><mi mathsize="0.800em">Î²</mi></mrow><mo>]</mo></mrow><mo stretchy="true">âŸ</mo></munder><msub><mi mathsize="0.800em">w</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub></munder><mo lspace="0.222em" mathsize="0.800em" rspace="0.222em">â‹…</mo><mrow><mrow><msub><mo mathsize="0.800em" rspace="0.167em">âˆ‡</mo><mi mathsize="0.800em">Î¸</mi></msub><mi mathsize="0.800em">log</mi></mrow><mo lspace="0.167em">â¡</mo><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub></mrow></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mo mathsize="0.800em">,</mo></mrow><annotation encoding="application/x-tex">\displaystyle\underbrace{\left[\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})}\hat{A}_{i}\cdot\mathbb{I}_{\mathrm{trust}}(\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})},\hat{A}_{i})+\beta\frac{\pi_{ref}(o_{i,t})}{\pi_{\theta}(o_{i,t})}-\beta\right]}_{w_{i,t}}\cdot\nabla_{\theta}\log\pi_{\theta}(o_{i,t}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="A1.E8Xb" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A1.E8Xb.m2" class="ltx_Math" alttext="\displaystyle\mathrm{where}\,\,\mathbb{I}_{\mathrm{trust}}" display="inline"><semantics><mrow><mi mathsize="0.800em">where</mi><mo lspace="0.330em" rspace="0em">â€‹</mo><msub><mi mathsize="0.800em">ğ•€</mi><mi mathsize="0.800em">trust</mi></msub></mrow><annotation encoding="application/x-tex">\displaystyle\mathrm{where}\,\,\mathbb{I}_{\mathrm{trust}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E8Xb.m3" class="ltx_Math" alttext="\displaystyle(\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})},\hat{A}_{i})=\left\{\begin{array}[]{ll}0&amp;\left\{\begin{array}[]{l}\mathrm{if}\,\,\hat{A}_{i}&gt;0\,\,\mathrm{and}\,\,\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})}&gt;1+\epsilon_{h}\\
\mathrm{if}\,\,\hat{A}_{i}&lt;0\,\,\mathrm{and}\,\,\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})}&lt;1-\epsilon_{l}\end{array}\right.\\
1&amp;\mathrm{otherwise}\end{array}\right.." display="inline"><semantics><mrow><mrow><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><mstyle displaystyle="true"><mfrac><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mrow><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow></mfrac></mstyle><mo mathsize="0.800em">,</mo><msub><mover accent="true"><mi mathsize="0.800em">A</mi><mo mathsize="0.800em">^</mo></mover><mi mathsize="0.800em">i</mi></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow><mo mathsize="0.800em">=</mo><mrow><mo>{</mo><mtable columnspacing="5pt" rowspacing="0pt"><mtr><mtd class="ltx_align_left" columnalign="left"><mn mathsize="0.800em">0</mn></mtd><mtd class="ltx_align_left" columnalign="left"><mrow><mo>{</mo><mtable rowspacing="0pt"><mtr><mtd class="ltx_align_left" columnalign="left"><mrow><mrow><mi mathsize="0.800em">if</mi><mo lspace="0.330em" rspace="0em">â€‹</mo><msub><mover accent="true"><mi mathsize="0.800em">A</mi><mo mathsize="0.800em">^</mo></mover><mi mathsize="0.800em">i</mi></msub></mrow><mo mathsize="0.800em">&gt;</mo><mrow><mn mathsize="0.800em">0</mn><mo lspace="0.330em" rspace="0em">â€‹</mo><mi mathsize="0.800em">and</mi><mo lspace="0.330em" rspace="0em">â€‹</mo><mfrac><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mrow><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow></mfrac></mrow><mo mathsize="0.800em">&gt;</mo><mrow><mn mathsize="0.800em">1</mn><mo mathsize="0.800em">+</mo><msub><mi mathsize="0.800em">Ïµ</mi><mi mathsize="0.800em">h</mi></msub></mrow></mrow></mtd></mtr><mtr><mtd class="ltx_align_left" columnalign="left"><mrow><mrow><mi mathsize="0.800em">if</mi><mo lspace="0.330em" rspace="0em">â€‹</mo><msub><mover accent="true"><mi mathsize="0.800em">A</mi><mo mathsize="0.800em">^</mo></mover><mi mathsize="0.800em">i</mi></msub></mrow><mo mathsize="0.800em">&lt;</mo><mrow><mn mathsize="0.800em">0</mn><mo lspace="0.330em" rspace="0em">â€‹</mo><mi mathsize="0.800em">and</mi><mo lspace="0.330em" rspace="0em">â€‹</mo><mfrac><mrow><msub><mi mathsize="0.800em">Ï€</mi><mi mathsize="0.800em">Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow><mrow><msub><mi mathsize="0.800em">Ï€</mi><mrow><mi mathsize="0.800em">o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi mathsize="0.800em">d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo maxsize="0.800em" minsize="0.800em">(</mo><msub><mi mathsize="0.800em">o</mi><mrow><mi mathsize="0.800em">i</mi><mo mathsize="0.800em">,</mo><mi mathsize="0.800em">t</mi></mrow></msub><mo maxsize="0.800em" minsize="0.800em">)</mo></mrow></mrow></mfrac></mrow><mo mathsize="0.800em">&lt;</mo><mrow><mn mathsize="0.800em">1</mn><mo mathsize="0.800em">âˆ’</mo><msub><mi mathsize="0.800em">Ïµ</mi><mi mathsize="0.800em">l</mi></msub></mrow></mrow></mtd></mtr></mtable><mi></mi></mrow></mtd></mtr><mtr><mtd class="ltx_align_left" columnalign="left"><mn mathsize="0.800em">1</mn></mtd><mtd class="ltx_align_left" columnalign="left"><mi mathsize="0.800em">otherwise</mi></mtd></mtr></mtable><mi></mi></mrow></mrow><mo lspace="0em" mathsize="0.800em">.</mo></mrow><annotation encoding="application/x-tex">\displaystyle(\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})},\hat{A}_{i})=\left\{\begin{array}[]{ll}0&amp;\left\{\begin{array}[]{l}\mathrm{if}\,\,\hat{A}_{i}&gt;0\,\,\mathrm{and}\,\,\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})}&gt;1+\epsilon_{h}\\
\mathrm{if}\,\,\hat{A}_{i}&lt;0\,\,\mathrm{and}\,\,\frac{\pi_{\theta}(o_{i,t})}{\pi_{old}(o_{i,t})}&lt;1-\epsilon_{l}\end{array}\right.\\
1&amp;\mathrm{otherwise}\end{array}\right..</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Proof for PropositionÂ <a href="#S4.Thmtheorem2" title="Proposition 4.2. â€£ 4.1 Explanation on Low-Probability Tokensâ€™ Dominance â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>
</h3>

<div id="A1.SS2.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Proof. </span>
As introduced in SectionÂ <a href="#S4.SS1" title="4.1 Explanation on Low-Probability Tokensâ€™ Dominance â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>, we denote LLM as a composite function <math id="A1.SS2.p1.m1" class="ltx_Math" alttext="f=f_{L}\circ f_{L-1}\circ\cdots\circ f_{1}" display="inline"><semantics><mrow><mi>f</mi><mo>=</mo><mrow><msub><mi>f</mi><mi>L</mi></msub><mo lspace="0.222em" rspace="0.222em">âˆ˜</mo><msub><mi>f</mi><mrow><mi>L</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo lspace="0.222em" rspace="0.222em">âˆ˜</mo><mi mathvariant="normal">â‹¯</mi><mo lspace="0.222em" rspace="0.222em">âˆ˜</mo><msub><mi>f</mi><mn>1</mn></msub></mrow></mrow><annotation encoding="application/x-tex">f=f_{L}\circ f_{L-1}\circ\cdots\circ f_{1}</annotation></semantics></math>, where each <math id="A1.SS2.p1.m2" class="ltx_Math" alttext="f_{\ell}" display="inline"><semantics><msub><mi>f</mi><mi mathvariant="normal">â„“</mi></msub><annotation encoding="application/x-tex">f_{\ell}</annotation></semantics></math> (with <math id="A1.SS2.p1.m3" class="ltx_Math" alttext="\ell\in\{1,\dots,L\}" display="inline"><semantics><mrow><mi mathvariant="normal">â„“</mi><mo>âˆˆ</mo><mrow><mo stretchy="false">{</mo><mn>1</mn><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><mi>L</mi><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">\ell\in\{1,\dots,L\}</annotation></semantics></math>) corresponds to a distinct layer of the network.
<math id="A1.SS2.p1.m4" class="ltx_Math" alttext="\bm{a}_{\ell-1}" display="inline"><semantics><msub><mi>ğ’‚</mi><mrow><mi mathvariant="normal">â„“</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">\bm{a}_{\ell-1}</annotation></semantics></math> denotes the input and <math id="A1.SS2.p1.m5" class="ltx_Math" alttext="\bm{a}_{\ell}" display="inline"><semantics><msub><mi>ğ’‚</mi><mi mathvariant="normal">â„“</mi></msub><annotation encoding="application/x-tex">\bm{a}_{\ell}</annotation></semantics></math> denotes the output of <math id="A1.SS2.p1.m6" class="ltx_Math" alttext="\ell" display="inline"><semantics><mi mathvariant="normal">â„“</mi><annotation encoding="application/x-tex">\ell</annotation></semantics></math>th layer, and the Jacobian matrix of the <math id="A1.SS2.p1.m7" class="ltx_Math" alttext="\ell" display="inline"><semantics><mi mathvariant="normal">â„“</mi><annotation encoding="application/x-tex">\ell</annotation></semantics></math>th layer with respect to its input is expressed as <math id="A1.SS2.p1.m8" class="ltx_Math" alttext="J_{\ell}:=\frac{\partial f_{l}(\bm{a}_{\ell-1})}{\partial\bm{a}_{\ell-1}}" display="inline"><semantics><mrow><msub><mi>J</mi><mi mathvariant="normal">â„“</mi></msub><mo>:=</mo><mfrac><mrow><mo rspace="0em">âˆ‚</mo><mrow><msub><mi>f</mi><mi>l</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>ğ’‚</mi><mrow><mi mathvariant="normal">â„“</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mrow><mo rspace="0em">âˆ‚</mo><msub><mi>ğ’‚</mi><mrow><mi mathvariant="normal">â„“</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">J_{\ell}:=\frac{\partial f_{l}(\bm{a}_{\ell-1})}{\partial\bm{a}_{\ell-1}}</annotation></semantics></math>.
For any token <math id="A1.SS2.p1.m9" class="ltx_Math" alttext="o_{i,t}" display="inline"><semantics><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><annotation encoding="application/x-tex">o_{i,t}</annotation></semantics></math>, we denote the gradient of GRPO objective with respect to the activations <math id="A1.SS2.p1.m10" class="ltx_Math" alttext="\bm{a}_{\ell}" display="inline"><semantics><msub><mi>ğ’‚</mi><mi mathvariant="normal">â„“</mi></msub><annotation encoding="application/x-tex">\bm{a}_{\ell}</annotation></semantics></math> at <math id="A1.SS2.p1.m11" class="ltx_Math" alttext="\ell" display="inline"><semantics><mi mathvariant="normal">â„“</mi><annotation encoding="application/x-tex">\ell</annotation></semantics></math>th layer as <math id="A1.SS2.p1.m12" class="ltx_Math" alttext="\bm{\delta}_{\ell}(o_{i,t}):=\nabla_{\bm{a}_{\ell}}J_{GRPO}(o_{i,t})" display="inline"><semantics><mrow><mrow><msub><mi>ğœ¹</mi><mi mathvariant="normal">â„“</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo>:=</mo><mrow><mrow><msub><mo rspace="0.167em">âˆ‡</mo><msub><mi>ğ’‚</mi><mi mathvariant="normal">â„“</mi></msub></msub><msub><mi>J</mi><mrow><mi>G</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>R</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>P</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>O</mi></mrow></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\bm{\delta}_{\ell}(o_{i,t}):=\nabla_{\bm{a}_{\ell}}J_{GRPO}(o_{i,t})</annotation></semantics></math>. According to the rule of backpropagation, we have:</p>
<table id="A1.E9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A1.E9.m1" class="ltx_Math" alttext="\bm{\delta}_{\ell}(o_{i,t})=J_{\ell+1}^{\mathsf{T}}\bm{\delta}_{\ell+1}(o_{i,t})=\prod_{j=\ell+1}^{L}J_{j}^{\mathsf{T}}\cdot\bm{\delta}_{L}(o_{i,t})." display="block"><semantics><mrow><mrow><mrow><msub><mi>ğœ¹</mi><mi mathvariant="normal">â„“</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><msubsup><mi>J</mi><mrow><mi mathvariant="normal">â„“</mi><mo>+</mo><mn>1</mn></mrow><mi>ğ–³</mi></msubsup><mo lspace="0em" rspace="0em">â€‹</mo><msub><mi>ğœ¹</mi><mrow><mi mathvariant="normal">â„“</mi><mo>+</mo><mn>1</mn></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo rspace="0.111em">=</mo><mrow><munderover><mo movablelimits="false">âˆ</mo><mrow><mi>j</mi><mo>=</mo><mrow><mi mathvariant="normal">â„“</mi><mo>+</mo><mn>1</mn></mrow></mrow><mi>L</mi></munderover><mrow><mrow><msubsup><mi>J</mi><mi>j</mi><mi>ğ–³</mi></msubsup><mo lspace="0.222em" rspace="0.222em">â‹…</mo><msub><mi>ğœ¹</mi><mi>L</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\bm{\delta}_{\ell}(o_{i,t})=J_{\ell+1}^{\mathsf{T}}\bm{\delta}_{\ell+1}(o_{i,t})=\prod_{j=\ell+1}^{L}J_{j}^{\mathsf{T}}\cdot\bm{\delta}_{L}(o_{i,t}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
</div>
<div id="A1.SS2.p2" class="ltx_para">
<p class="ltx_p">Note that the gradients of all intermediate layers are back-propagated from the last layer of LLM, thereby we discuss the gradients of the last layer (<math id="A1.SS2.p2.m1" class="ltx_Math" alttext="\bm{\delta}_{L}(o_{i,t})" display="inline"><semantics><mrow><msub><mi>ğœ¹</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\bm{\delta}_{L}(o_{i,t})</annotation></semantics></math>) first.
The last-layer output of an LLM is the logits <math id="A1.SS2.p2.m2" class="ltx_Math" alttext="\bm{a}_{L}=(a^{1}_{L},a^{2}_{L},\dots,a^{N}_{L})" display="inline"><semantics><mrow><msub><mi>ğ’‚</mi><mi>L</mi></msub><mo>=</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>a</mi><mi>L</mi><mn>1</mn></msubsup><mo>,</mo><msubsup><mi>a</mi><mi>L</mi><mn>2</mn></msubsup><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><msubsup><mi>a</mi><mi>L</mi><mi>N</mi></msubsup><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\bm{a}_{L}=(a^{1}_{L},a^{2}_{L},\dots,a^{N}_{L})</annotation></semantics></math>, which corresponds to a finite vocabulary <math id="A1.SS2.p2.m3" class="ltx_Math" alttext="\mathcal{V}=\{v^{1},v^{2},\dots,v^{N}\}" display="inline"><semantics><mrow><mi class="ltx_font_mathcaligraphic">ğ’±</mi><mo>=</mo><mrow><mo stretchy="false">{</mo><msup><mi>v</mi><mn>1</mn></msup><mo>,</mo><msup><mi>v</mi><mn>2</mn></msup><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><msup><mi>v</mi><mi>N</mi></msup><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{V}=\{v^{1},v^{2},\dots,v^{N}\}</annotation></semantics></math>.
The output probability of the corresponding token is calculated through softmax operation:</p>
<table id="A1.E10" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A1.E10.m1" class="ltx_Math" alttext="\pi_{\theta}(v^{n})=\frac{e^{a^{n}_{L}}}{\sum_{m=1}^{N}e^{a^{m}_{L}}},\quad\mathrm{for}\,\,\forall n\in\{1,2,\dots,N\}." display="block"><semantics><mrow><mrow><mrow><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>n</mi></msup><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mfrac><msup><mi>e</mi><msubsup><mi>a</mi><mi>L</mi><mi>n</mi></msubsup></msup><mrow><msubsup><mo>âˆ‘</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msup><mi>e</mi><msubsup><mi>a</mi><mi>L</mi><mi>m</mi></msubsup></msup></mrow></mfrac></mrow><mo rspace="1.167em">,</mo><mrow><mrow><mi>for</mi><mo lspace="0.497em" rspace="0em">â€‹</mo><mrow><mo rspace="0.167em">âˆ€</mo><mi>n</mi></mrow></mrow><mo>âˆˆ</mo><mrow><mo stretchy="false">{</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><mi>N</mi><mo stretchy="false">}</mo></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\pi_{\theta}(v^{n})=\frac{e^{a^{n}_{L}}}{\sum_{m=1}^{N}e^{a^{m}_{L}}},\quad\mathrm{for}\,\,\forall n\in\{1,2,\dots,N\}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(10)</span></td>
</tr></tbody>
</table>
</div>
<div id="A1.SS2.p3" class="ltx_para">
<p class="ltx_p">Given a token <math id="A1.SS2.p3.m1" class="ltx_Math" alttext="o_{i,t}" display="inline"><semantics><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><annotation encoding="application/x-tex">o_{i,t}</annotation></semantics></math>, let <math id="A1.SS2.p3.m2" class="ltx_Math" alttext="k" display="inline"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> denote the index of the logits head corresponding to this token (i.e., <math id="A1.SS2.p3.m3" class="ltx_Math" alttext="v^{k}=o_{i,t}" display="inline"><semantics><mrow><msup><mi>v</mi><mi>k</mi></msup><mo>=</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">v^{k}=o_{i,t}</annotation></semantics></math>). To obtain the gradient of last layer of LLM, we have:</p>
</div>
<div id="A1.SS2.p4" class="ltx_para">
<table id="A1.E11" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="A1.E11X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A1.E11X.m2" class="ltx_Math" alttext="\displaystyle\frac{\partial J_{GRPO}(o_{i,t})}{\partial a_{L}^{n}}" display="inline"><semantics><mstyle displaystyle="true"><mfrac><mrow><mo rspace="0em">âˆ‚</mo><mrow><msub><mi>J</mi><mrow><mi>G</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>R</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>P</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>O</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mrow><mo rspace="0em">âˆ‚</mo><msubsup><mi>a</mi><mi>L</mi><mi>n</mi></msubsup></mrow></mfrac></mstyle><annotation encoding="application/x-tex">\displaystyle\frac{\partial J_{GRPO}(o_{i,t})}{\partial a_{L}^{n}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E11X.m3" class="ltx_Math" alttext="\displaystyle\stackrel{{\scriptstyle i}}{{=}}w_{i,t}\cdot\frac{\partial\log\pi_{\theta}(o_{i,t})}{\partial a_{L}^{n}}" display="inline"><semantics><mrow><mi></mi><mover><mo>=</mo><mi>i</mi></mover><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mstyle displaystyle="true"><mfrac><mrow><mo rspace="0.167em">âˆ‚</mo><mrow><mrow><mi>log</mi><mo lspace="0.167em">â¡</mo><msub><mi>Ï€</mi><mi>Î¸</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mrow><mo rspace="0em">âˆ‚</mo><msubsup><mi>a</mi><mi>L</mi><mi>n</mi></msubsup></mrow></mfrac></mstyle></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\stackrel{{\scriptstyle i}}{{=}}w_{i,t}\cdot\frac{\partial\log\pi_{\theta}(o_{i,t})}{\partial a_{L}^{n}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="3" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(11)</span></td>
</tr>
<tr id="A1.E11Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E11Xa.m2" class="ltx_Math" alttext="\displaystyle\stackrel{{\scriptstyle ii}}{{=}}w_{i,t}\cdot\sum_{m=1}^{N}\frac{\partial\log\pi_{\theta}(o_{i,t})}{\partial\pi_{\theta}(v^{m})}\cdot\frac{\partial\pi_{\theta}(v^{m})}{\partial a_{L}^{n}}" display="inline"><semantics><mrow><mi></mi><mover><mo>=</mo><mrow><mi>i</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>i</mi></mrow></mover><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mrow><mstyle displaystyle="true"><munderover><mo movablelimits="false">âˆ‘</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover></mstyle><mrow><mstyle displaystyle="true"><mfrac><mrow><mo rspace="0.167em">âˆ‚</mo><mrow><mrow><mi>log</mi><mo lspace="0.167em">â¡</mo><msub><mi>Ï€</mi><mi>Î¸</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mrow><mo rspace="0em">âˆ‚</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>m</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow></mfrac></mstyle><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mstyle displaystyle="true"><mfrac><mrow><mo rspace="0em">âˆ‚</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>m</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mrow><mo rspace="0em">âˆ‚</mo><msubsup><mi>a</mi><mi>L</mi><mi>n</mi></msubsup></mrow></mfrac></mstyle></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\stackrel{{\scriptstyle ii}}{{=}}w_{i,t}\cdot\sum_{m=1}^{N}\frac{\partial\log\pi_{\theta}(o_{i,t})}{\partial\pi_{\theta}(v^{m})}\cdot\frac{\partial\pi_{\theta}(v^{m})}{\partial a_{L}^{n}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="A1.E11Xb" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E11Xb.m2" class="ltx_Math" alttext="\displaystyle\stackrel{{\scriptstyle iii}}{{=}}w_{i,t}\cdot\frac{\partial\log\pi_{\theta}(o_{i,t})}{\partial\pi_{\theta}(v^{k})}\cdot\frac{\partial\pi_{\theta}(v^{k})}{\partial a_{L}^{n}}=w_{i,t}\cdot\frac{1}{\pi_{\theta}(v^{k})}\cdot\frac{\partial\pi_{\theta}(v^{k})}{\partial a_{L}^{n}}." display="inline"><semantics><mrow><mrow><mi></mi><mover><mo>=</mo><mrow><mi>i</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>i</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>i</mi></mrow></mover><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mstyle displaystyle="true"><mfrac><mrow><mo rspace="0.167em">âˆ‚</mo><mrow><mrow><mi>log</mi><mo lspace="0.167em">â¡</mo><msub><mi>Ï€</mi><mi>Î¸</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mrow><mo rspace="0em">âˆ‚</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow></mfrac></mstyle><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mstyle displaystyle="true"><mfrac><mrow><mo rspace="0em">âˆ‚</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mrow><mo rspace="0em">âˆ‚</mo><msubsup><mi>a</mi><mi>L</mi><mi>n</mi></msubsup></mrow></mfrac></mstyle></mrow><mo>=</mo><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mstyle displaystyle="true"><mfrac><mn>1</mn><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mfrac></mstyle><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mstyle displaystyle="true"><mfrac><mrow><mo rspace="0em">âˆ‚</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mrow><mo rspace="0em">âˆ‚</mo><msubsup><mi>a</mi><mi>L</mi><mi>n</mi></msubsup></mrow></mfrac></mstyle></mrow></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\displaystyle\stackrel{{\scriptstyle iii}}{{=}}w_{i,t}\cdot\frac{\partial\log\pi_{\theta}(o_{i,t})}{\partial\pi_{\theta}(v^{k})}\cdot\frac{\partial\pi_{\theta}(v^{k})}{\partial a_{L}^{n}}=w_{i,t}\cdot\frac{1}{\pi_{\theta}(v^{k})}\cdot\frac{\partial\pi_{\theta}(v^{k})}{\partial a_{L}^{n}}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
<p class="ltx_p">Here, equality (i) follows from Eq.Â (<a href="#A1.E8" title="In A.1 Gradient Derivation for the GRPO Objective â€£ Appendix A Theoretical Interpretations â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>); equality (ii) is obtained by applying the chain rule during backpropagation; and equality (iii) holds because <math id="A1.SS2.p4.m1" class="ltx_Math" alttext="{\partial\log\pi_{\theta}(o_{i,t})}/{\pi_{\theta}(v^{m})}=0" display="inline"><semantics><mrow><mrow><mo rspace="0.167em">âˆ‚</mo><mrow><mrow><mrow><mrow><mi>log</mi><mo lspace="0.167em">â¡</mo><msub><mi>Ï€</mi><mi>Î¸</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo>/</mo><msub><mi>Ï€</mi><mi>Î¸</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>m</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">{\partial\log\pi_{\theta}(o_{i,t})}/{\pi_{\theta}(v^{m})}=0</annotation></semantics></math> for all <math id="A1.SS2.p4.m2" class="ltx_Math" alttext="m\neq k" display="inline"><semantics><mrow><mi>m</mi><mo>â‰ </mo><mi>k</mi></mrow><annotation encoding="application/x-tex">m\neq k</annotation></semantics></math>.
Next, we consider the following two cases for the gradient on the logits head <math id="A1.SS2.p4.m3" class="ltx_Math" alttext="a_{L}^{n}" display="inline"><semantics><msubsup><mi>a</mi><mi>L</mi><mi>n</mi></msubsup><annotation encoding="application/x-tex">a_{L}^{n}</annotation></semantics></math> (<math id="A1.SS2.p4.m4" class="ltx_Math" alttext="n\in\{1,2,\dots,N\}" display="inline"><semantics><mrow><mi>n</mi><mo>âˆˆ</mo><mrow><mo stretchy="false">{</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><mi>N</mi><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">n\in\{1,2,\dots,N\}</annotation></semantics></math>).</p>
</div>
<div id="A1.SS2.p5" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Case 1: the logits head corresponds to the sampled token (<math id="A1.SS2.p5.m1" class="ltx_Math" alttext="n=k" display="inline"><semantics><mrow><mi>n</mi><mo>=</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n=k</annotation></semantics></math>)</span></p>
</div>
<div id="A1.SS2.p6" class="ltx_para">
<table id="A1.E12" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="A1.E12X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A1.E12X.m2" class="ltx_Math" alttext="\displaystyle\frac{\partial J_{GRPO}(o_{i,t})}{\partial a_{L}^{k}}" display="inline"><semantics><mstyle displaystyle="true"><mfrac><mrow><mo rspace="0em">âˆ‚</mo><mrow><msub><mi>J</mi><mrow><mi>G</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>R</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>P</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>O</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mrow><mo rspace="0em">âˆ‚</mo><msubsup><mi>a</mi><mi>L</mi><mi>k</mi></msubsup></mrow></mfrac></mstyle><annotation encoding="application/x-tex">\displaystyle\frac{\partial J_{GRPO}(o_{i,t})}{\partial a_{L}^{k}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E12X.m3" class="ltx_Math" alttext="\displaystyle=w_{i,t}\cdot\frac{1}{\pi_{\theta}(v^{k})}\cdot\frac{\partial\pi_{\theta}(v^{k})}{\partial a_{L}^{k}}" display="inline"><semantics><mrow><mi></mi><mo>=</mo><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mstyle displaystyle="true"><mfrac><mn>1</mn><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mfrac></mstyle><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mstyle displaystyle="true"><mfrac><mrow><mo rspace="0em">âˆ‚</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mrow><mo rspace="0em">âˆ‚</mo><msubsup><mi>a</mi><mi>L</mi><mi>k</mi></msubsup></mrow></mfrac></mstyle></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=w_{i,t}\cdot\frac{1}{\pi_{\theta}(v^{k})}\cdot\frac{\partial\pi_{\theta}(v^{k})}{\partial a_{L}^{k}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="4" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(12)</span></td>
</tr>
<tr id="A1.E12Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E12Xa.m2" class="ltx_Math" alttext="\displaystyle=w_{i,t}\cdot\frac{1}{\pi_{\theta}(v^{k})}\cdot\frac{e^{a^{n}_{L}}\cdot{\sum_{m=1}^{N}e^{a^{m}_{L}}}-e^{2a^{n}_{L}}}{({\sum_{m=1}^{N}e^{a^{m}_{L}}})^{2}}" display="inline"><semantics><mrow><mi></mi><mo>=</mo><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mstyle displaystyle="true"><mfrac><mn>1</mn><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mfrac></mstyle><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mstyle displaystyle="true"><mfrac><mrow><mrow><msup><mi>e</mi><msubsup><mi>a</mi><mi>L</mi><mi>n</mi></msubsup></msup><mo lspace="0.222em" rspace="0.055em">â‹…</mo><mrow><msubsup><mo>âˆ‘</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msup><mi>e</mi><msubsup><mi>a</mi><mi>L</mi><mi>m</mi></msubsup></msup></mrow></mrow><mo>âˆ’</mo><msup><mi>e</mi><mrow><mn>2</mn><mo lspace="0em" rspace="0em">â€‹</mo><msubsup><mi>a</mi><mi>L</mi><mi>n</mi></msubsup></mrow></msup></mrow><msup><mrow><mo stretchy="false">(</mo><mrow><msubsup><mo lspace="0em">âˆ‘</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msup><mi>e</mi><msubsup><mi>a</mi><mi>L</mi><mi>m</mi></msubsup></msup></mrow><mo stretchy="false">)</mo></mrow><mn>2</mn></msup></mfrac></mstyle></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=w_{i,t}\cdot\frac{1}{\pi_{\theta}(v^{k})}\cdot\frac{e^{a^{n}_{L}}\cdot{\sum_{m=1}^{N}e^{a^{m}_{L}}}-e^{2a^{n}_{L}}}{({\sum_{m=1}^{N}e^{a^{m}_{L}}})^{2}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="A1.E12Xb" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E12Xb.m2" class="ltx_Math" alttext="\displaystyle=w_{i,t}\cdot\frac{1}{\pi_{\theta}(v^{k})}\cdot\pi_{\theta}(v^{k})\cdot\left(1-\pi_{\theta}(v^{k})\right)" display="inline"><semantics><mrow><mi></mi><mo>=</mo><mrow><mrow><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mstyle displaystyle="true"><mfrac><mn>1</mn><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mfrac></mstyle><mo lspace="0.222em" rspace="0.222em">â‹…</mo><msub><mi>Ï€</mi><mi>Î¸</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo rspace="0.055em" stretchy="false">)</mo></mrow></mrow><mo rspace="0.222em">â‹…</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>âˆ’</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=w_{i,t}\cdot\frac{1}{\pi_{\theta}(v^{k})}\cdot\pi_{\theta}(v^{k})\cdot\left(1-\pi_{\theta}(v^{k})\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="A1.E12Xc" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E12Xc.m2" class="ltx_Math" alttext="\displaystyle=w_{i,t}\cdot\left(1-\pi_{\theta}(v^{k})\right)." display="inline"><semantics><mrow><mrow><mi></mi><mo>=</mo><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>âˆ’</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\displaystyle=w_{i,t}\cdot\left(1-\pi_{\theta}(v^{k})\right).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
</div>
<div id="A1.SS2.p7" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Case 2: the logits head corresponds to the un-sampled token (<math id="A1.SS2.p7.m1" class="ltx_Math" alttext="n\neq k" display="inline"><semantics><mrow><mi>n</mi><mo>â‰ </mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n\neq k</annotation></semantics></math>)</span></p>
</div>
<div id="A1.SS2.p8" class="ltx_para">
<table id="A1.E13" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="A1.E13X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A1.E13X.m2" class="ltx_Math" alttext="\displaystyle\frac{\partial J_{GRPO}(o_{i,t})}{\partial a_{L}^{n}}" display="inline"><semantics><mstyle displaystyle="true"><mfrac><mrow><mo rspace="0em">âˆ‚</mo><mrow><msub><mi>J</mi><mrow><mi>G</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>R</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>P</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>O</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mrow><mo rspace="0em">âˆ‚</mo><msubsup><mi>a</mi><mi>L</mi><mi>n</mi></msubsup></mrow></mfrac></mstyle><annotation encoding="application/x-tex">\displaystyle\frac{\partial J_{GRPO}(o_{i,t})}{\partial a_{L}^{n}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E13X.m3" class="ltx_Math" alttext="\displaystyle=w_{i,t}\cdot\frac{1}{\pi_{\theta}(v^{k})}\cdot\frac{\partial\pi_{\theta}(v^{k})}{\partial a_{L}^{n}}" display="inline"><semantics><mrow><mi></mi><mo>=</mo><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mstyle displaystyle="true"><mfrac><mn>1</mn><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mfrac></mstyle><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mstyle displaystyle="true"><mfrac><mrow><mo rspace="0em">âˆ‚</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mrow><mo rspace="0em">âˆ‚</mo><msubsup><mi>a</mi><mi>L</mi><mi>n</mi></msubsup></mrow></mfrac></mstyle></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=w_{i,t}\cdot\frac{1}{\pi_{\theta}(v^{k})}\cdot\frac{\partial\pi_{\theta}(v^{k})}{\partial a_{L}^{n}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="4" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(13)</span></td>
</tr>
<tr id="A1.E13Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E13Xa.m2" class="ltx_Math" alttext="\displaystyle=w_{i,t}\cdot\frac{1}{\pi_{\theta}(v^{k})}\cdot\frac{-e^{a^{k}_{L}}\cdot e^{a^{n}_{L}}}{({\sum_{m=1}^{N}e^{a^{m}_{L}}})^{2}}" display="inline"><semantics><mrow><mi></mi><mo>=</mo><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mstyle displaystyle="true"><mfrac><mn>1</mn><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mfrac></mstyle><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mstyle displaystyle="true"><mfrac><mrow><mo>âˆ’</mo><mrow><msup><mi>e</mi><msubsup><mi>a</mi><mi>L</mi><mi>k</mi></msubsup></msup><mo lspace="0.222em" rspace="0.222em">â‹…</mo><msup><mi>e</mi><msubsup><mi>a</mi><mi>L</mi><mi>n</mi></msubsup></msup></mrow></mrow><msup><mrow><mo stretchy="false">(</mo><mrow><msubsup><mo lspace="0em">âˆ‘</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msup><mi>e</mi><msubsup><mi>a</mi><mi>L</mi><mi>m</mi></msubsup></msup></mrow><mo stretchy="false">)</mo></mrow><mn>2</mn></msup></mfrac></mstyle></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=w_{i,t}\cdot\frac{1}{\pi_{\theta}(v^{k})}\cdot\frac{-e^{a^{k}_{L}}\cdot e^{a^{n}_{L}}}{({\sum_{m=1}^{N}e^{a^{m}_{L}}})^{2}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="A1.E13Xb" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E13Xb.m2" class="ltx_Math" alttext="\displaystyle=w_{i,t}\cdot\frac{1}{\pi_{\theta}(v^{k})}\cdot\pi_{\theta}(v^{k})\cdot\left(-\pi_{\theta}(v^{n})\right)" display="inline"><semantics><mrow><mi></mi><mo>=</mo><mrow><mrow><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mstyle displaystyle="true"><mfrac><mn>1</mn><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mfrac></mstyle><mo lspace="0.222em" rspace="0.222em">â‹…</mo><msub><mi>Ï€</mi><mi>Î¸</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo rspace="0.055em" stretchy="false">)</mo></mrow></mrow><mo rspace="0.222em">â‹…</mo><mrow><mo>(</mo><mrow><mo>âˆ’</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>n</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=w_{i,t}\cdot\frac{1}{\pi_{\theta}(v^{k})}\cdot\pi_{\theta}(v^{k})\cdot\left(-\pi_{\theta}(v^{n})\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="A1.E13Xc" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E13Xc.m2" class="ltx_Math" alttext="\displaystyle=w_{i,t}\cdot\left(-\pi_{\theta}(v^{n})\right)." display="inline"><semantics><mrow><mrow><mi></mi><mo>=</mo><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mrow><mo>(</mo><mrow><mo>âˆ’</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>n</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\displaystyle=w_{i,t}\cdot\left(-\pi_{\theta}(v^{n})\right).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
</div>
<div id="A1.SS2.p9" class="ltx_para">
<p class="ltx_p">For simplicity, we denote the vector distribution output across the vocabulary as <math id="A1.SS2.p9.m1" class="ltx_Math" alttext="\bm{p}" display="inline"><semantics><mi>ğ’‘</mi><annotation encoding="application/x-tex">\bm{p}</annotation></semantics></math>, and denote <math id="A1.SS2.p9.m2" class="ltx_Math" alttext="\bm{I}(o_{i,t})" display="inline"><semantics><mrow><mi>ğ‘°</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\bm{I}(o_{i,t})</annotation></semantics></math> as the one-hot vector with its only non-zero component at <math id="A1.SS2.p9.m3" class="ltx_Math" alttext="k" display="inline"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>th position (i.e., the position correspondence to token <math id="A1.SS2.p9.m4" class="ltx_Math" alttext="o_{i,t}" display="inline"><semantics><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><annotation encoding="application/x-tex">o_{i,t}</annotation></semantics></math>). We have the following expressions</p>
<table id="A1.E14" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="A1.E14X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A1.E14X.m2" class="ltx_Math" alttext="\displaystyle\bm{p}(o_{i,t})" display="inline"><semantics><mrow><mi>ğ’‘</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\bm{p}(o_{i,t})</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E14X.m3" class="ltx_Math" alttext="\displaystyle=(\pi_{\theta}(v^{1}),\pi_{\theta}(v^{2}),\dots,\pi_{\theta}(v^{N}))\in\mathcal{R}^{N}" display="inline"><semantics><mrow><mi></mi><mo>=</mo><mrow><mo stretchy="false">(</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mn>1</mn></msup><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>N</mi></msup><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow><mo>âˆˆ</mo><msup><mi class="ltx_font_mathcaligraphic">â„›</mi><mi>N</mi></msup></mrow><annotation encoding="application/x-tex">\displaystyle=(\pi_{\theta}(v^{1}),\pi_{\theta}(v^{2}),\dots,\pi_{\theta}(v^{N}))\in\mathcal{R}^{N}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="2" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(14)</span></td>
</tr>
<tr id="A1.E14Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A1.E14Xa.m2" class="ltx_Math" alttext="\displaystyle\bm{I}(o_{i,t})" display="inline"><semantics><mrow><mi>ğ‘°</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\bm{I}(o_{i,t})</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E14Xa.m3" class="ltx_Math" alttext="\displaystyle=(0,0,\dots,\underbrace{1}_{k\mathrm{th}},\dots,0)\in\mathcal{R}^{N}." display="inline"><semantics><mrow><mrow><mi></mi><mo>=</mo><mrow><mo stretchy="false">(</mo><mn>0</mn><mo>,</mo><mn>0</mn><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><munder><munder accentunder="true"><mn>1</mn><mo stretchy="true">âŸ</mo></munder><mrow><mi>k</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>th</mi></mrow></munder><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><mo>âˆˆ</mo><msup><mi class="ltx_font_mathcaligraphic">â„›</mi><mi>N</mi></msup></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\displaystyle=(0,0,\dots,\underbrace{1}_{k\mathrm{th}},\dots,0)\in\mathcal{R}^{N}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
<p class="ltx_p">Combining Eq.Â (<a href="#A1.E12" title="In A.2 Proof for Proposition 4.2 â€£ Appendix A Theoretical Interpretations â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>) and Eq.Â (<a href="#A1.E13" title="In A.2 Proof for Proposition 4.2 â€£ Appendix A Theoretical Interpretations â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a>), and utilizing the notation defined in Eq.Â (<a href="#A1.E14" title="In A.2 Proof for Proposition 4.2 â€£ Appendix A Theoretical Interpretations â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a>), we obtain:</p>
<table id="A1.E15" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A1.E15.m1" class="ltx_Math" alttext="\bm{\delta}_{L}(o_{i,t})=\nabla_{\bm{a}_{L}}J_{GRPO}(o_{i,t})=w_{i,t}\cdot\left(\bm{I}(o_{i,t})-\bm{p}(o_{i,t})\right)." display="block"><semantics><mrow><mrow><mrow><msub><mi>ğœ¹</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msub><mo rspace="0.167em">âˆ‡</mo><msub><mi>ğ’‚</mi><mi>L</mi></msub></msub><msub><mi>J</mi><mrow><mi>G</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>R</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>P</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>O</mi></mrow></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mrow><mo>(</mo><mrow><mrow><mi>ğ‘°</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo>âˆ’</mo><mrow><mi>ğ’‘</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\bm{\delta}_{L}(o_{i,t})=\nabla_{\bm{a}_{L}}J_{GRPO}(o_{i,t})=w_{i,t}\cdot\left(\bm{I}(o_{i,t})-\bm{p}(o_{i,t})\right).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(15)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">Considering the lower bound for the gradient norm, we have:</p>
<table id="A1.E16" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="A1.E16X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A1.E16X.m2" class="ltx_Math" alttext="\displaystyle\|\bm{\delta}_{L}(o_{i,t})\|" display="inline"><semantics><mrow><mo stretchy="false">â€–</mo><mrow><msub><mi>ğœ¹</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">â€–</mo></mrow><annotation encoding="application/x-tex">\displaystyle\|\bm{\delta}_{L}(o_{i,t})\|</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E16X.m3" class="ltx_Math" alttext="\displaystyle=|w_{i,t}|\cdot\|\bm{p}(o_{i,t})-\bm{I}(o_{i,t})\|" display="inline"><semantics><mrow><mi></mi><mo>=</mo><mrow><mrow><mo stretchy="false">|</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo rspace="0.055em" stretchy="false">|</mo></mrow><mo rspace="0.222em">â‹…</mo><mrow><mo stretchy="false">â€–</mo><mrow><mrow><mi>ğ’‘</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo>âˆ’</mo><mrow><mi>ğ‘°</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mo stretchy="false">â€–</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=|w_{i,t}|\cdot\|\bm{p}(o_{i,t})-\bm{I}(o_{i,t})\|</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="5" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(16)</span></td>
</tr>
<tr id="A1.E16Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E16Xa.m2" class="ltx_Math" alttext="\displaystyle=|w_{i,t}|\cdot\sqrt{\left(1-\pi_{\theta}(v^{k})\right)^{2}+\sum\nolimits_{n\neq k}^{N}\pi_{\theta}(v^{n})^{2}}" display="inline"><semantics><mrow><mi></mi><mo>=</mo><mrow><mrow><mo stretchy="false">|</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo rspace="0.055em" stretchy="false">|</mo></mrow><mo rspace="0.222em">â‹…</mo><msqrt><mrow><msup><mrow><mo>(</mo><mrow><mn>1</mn><mo>âˆ’</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>)</mo></mrow><mn>2</mn></msup><mo>+</mo><mrow><mstyle displaystyle="true"><msubsup><mo>âˆ‘</mo><mrow><mi>n</mi><mo>â‰ </mo><mi>k</mi></mrow><mi>N</mi></msubsup></mstyle><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><msup><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>n</mi></msup><mo stretchy="false">)</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></msqrt></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=|w_{i,t}|\cdot\sqrt{\left(1-\pi_{\theta}(v^{k})\right)^{2}+\sum\nolimits_{n\neq k}^{N}\pi_{\theta}(v^{n})^{2}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="A1.E16Xb" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E16Xb.m2" class="ltx_Math" alttext="\displaystyle\geq|w_{i,t}|\cdot\sqrt{\left(1-\pi_{\theta}(v^{k})\right)^{2}+\frac{1}{N-1}\big{(}\sum\nolimits_{n\neq k}^{N}\pi_{\theta}(v^{n})\big{)}^{2}}" display="inline"><semantics><mrow><mi></mi><mo>â‰¥</mo><mrow><mrow><mo stretchy="false">|</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo rspace="0.055em" stretchy="false">|</mo></mrow><mo rspace="0.222em">â‹…</mo><msqrt><mrow><msup><mrow><mo>(</mo><mrow><mn>1</mn><mo>âˆ’</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>)</mo></mrow><mn>2</mn></msup><mo>+</mo><mrow><mstyle displaystyle="true"><mfrac><mn>1</mn><mrow><mi>N</mi><mo>âˆ’</mo><mn>1</mn></mrow></mfrac></mstyle><mo lspace="0em" rspace="0em">â€‹</mo><msup><mrow><mo maxsize="1.200em" minsize="1.200em">(</mo><mrow><mstyle displaystyle="true"><msubsup><mo>âˆ‘</mo><mrow><mi>n</mi><mo>â‰ </mo><mi>k</mi></mrow><mi>N</mi></msubsup></mstyle><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>n</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo maxsize="1.200em" minsize="1.200em">)</mo></mrow><mn>2</mn></msup></mrow></mrow></msqrt></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\geq|w_{i,t}|\cdot\sqrt{\left(1-\pi_{\theta}(v^{k})\right)^{2}+\frac{1}{N-1}\big{(}\sum\nolimits_{n\neq k}^{N}\pi_{\theta}(v^{n})\big{)}^{2}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="A1.E16Xc" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E16Xc.m2" class="ltx_Math" alttext="\displaystyle=|w_{i,t}|\cdot\sqrt{\left(1-\pi_{\theta}(v^{k})\right)^{2}+\frac{1}{N-1}\left(1-\pi_{\theta}(v^{k})\right)^{2}}" display="inline"><semantics><mrow><mi></mi><mo>=</mo><mrow><mrow><mo stretchy="false">|</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo rspace="0.055em" stretchy="false">|</mo></mrow><mo rspace="0.222em">â‹…</mo><msqrt><mrow><msup><mrow><mo>(</mo><mrow><mn>1</mn><mo>âˆ’</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>)</mo></mrow><mn>2</mn></msup><mo>+</mo><mrow><mstyle displaystyle="true"><mfrac><mn>1</mn><mrow><mi>N</mi><mo>âˆ’</mo><mn>1</mn></mrow></mfrac></mstyle><mo lspace="0em" rspace="0em">â€‹</mo><msup><mrow><mo>(</mo><mrow><mn>1</mn><mo>âˆ’</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow></msqrt></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=|w_{i,t}|\cdot\sqrt{\left(1-\pi_{\theta}(v^{k})\right)^{2}+\frac{1}{N-1}\left(1-\pi_{\theta}(v^{k})\right)^{2}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="A1.E16Xd" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E16Xd.m2" class="ltx_Math" alttext="\displaystyle=|w_{i,t}|\cdot\sqrt{\frac{N}{N-1}}\left(1-\pi_{\theta}(o_{i,t})\right)," display="inline"><semantics><mrow><mrow><mi></mi><mo>=</mo><mrow><mrow><mrow><mo stretchy="false">|</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo rspace="0.055em" stretchy="false">|</mo></mrow><mo rspace="0.222em">â‹…</mo><msqrt><mstyle displaystyle="true"><mfrac><mi>N</mi><mrow><mi>N</mi><mo>âˆ’</mo><mn>1</mn></mrow></mfrac></mstyle></msqrt></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>âˆ’</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\displaystyle=|w_{i,t}|\cdot\sqrt{\frac{N}{N-1}}\left(1-\pi_{\theta}(o_{i,t})\right),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
<p class="ltx_p">where the inequality follows from the Cauchy-Schwarz inequality. The equality holds holding if and only if <math id="A1.SS2.p9.m5" class="ltx_Math" alttext="\pi_{\theta}(v^{n})" display="inline"><semantics><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>n</mi></msup><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\pi_{\theta}(v^{n})</annotation></semantics></math> is uniformly distributed for all <math id="A1.SS2.p9.m6" class="ltx_Math" alttext="n\neq k" display="inline"><semantics><mrow><mi>n</mi><mo>â‰ </mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n\neq k</annotation></semantics></math>.</p>
</div>
<div id="A1.SS2.p10" class="ltx_para">
<p class="ltx_p">By substituting Eq.(<a href="#A1.E16" title="In A.2 Proof for Proposition 4.2 â€£ Appendix A Theoretical Interpretations â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">16</span></a>) into Eq.(<a href="#A1.E9" title="In A.2 Proof for Proposition 4.2 â€£ Appendix A Theoretical Interpretations â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>), we obtain:</p>
</div>
<div id="A1.SS2.p11" class="ltx_para">
<table id="A1.E17" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="A1.E17X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A1.E17X.m2" class="ltx_Math" alttext="\displaystyle\|\bm{\delta}_{\ell}(o_{i,t})\|" display="inline"><semantics><mrow><mo stretchy="false">â€–</mo><mrow><msub><mi>ğœ¹</mi><mi mathvariant="normal">â„“</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">â€–</mo></mrow><annotation encoding="application/x-tex">\displaystyle\|\bm{\delta}_{\ell}(o_{i,t})\|</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E17X.m3" class="ltx_Math" alttext="\displaystyle=\|\prod\nolimits_{j=\ell+1}^{L}J_{j}^{\mathsf{T}}\cdot\bm{\delta}_{L}(o_{i,t})\|" display="inline"><semantics><mrow><mi></mi><mo>=</mo><mrow><mo stretchy="false">â€–</mo><mrow><mstyle displaystyle="true"><msubsup><mo>âˆ</mo><mrow><mi>j</mi><mo>=</mo><mrow><mi mathvariant="normal">â„“</mi><mo>+</mo><mn>1</mn></mrow></mrow><mi>L</mi></msubsup></mstyle><mrow><mrow><msubsup><mi>J</mi><mi>j</mi><mi>ğ–³</mi></msubsup><mo lspace="0.222em" rspace="0.222em">â‹…</mo><msub><mi>ğœ¹</mi><mi>L</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mo stretchy="false">â€–</mo></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=\|\prod\nolimits_{j=\ell+1}^{L}J_{j}^{\mathsf{T}}\cdot\bm{\delta}_{L}(o_{i,t})\|</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="4" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(17)</span></td>
</tr>
<tr id="A1.E17Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E17Xa.m2" class="ltx_Math" alttext="\displaystyle\stackrel{{\scriptstyle i}}{{\geq}}\prod\nolimits_{j=\ell+1}^{L}\sigma_{\min}(J_{j}^{\mathsf{T}})\cdot\|\bm{\delta}_{L}(o_{i,t})\|" display="inline"><semantics><mrow><mi></mi><mover><mo>â‰¥</mo><mi>i</mi></mover><mrow><mstyle displaystyle="true"><msubsup><mo>âˆ</mo><mrow><mi>j</mi><mo>=</mo><mrow><mi mathvariant="normal">â„“</mi><mo>+</mo><mn>1</mn></mrow></mrow><mi>L</mi></msubsup></mstyle><mrow><mrow><msub><mi>Ïƒ</mi><mi>min</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>J</mi><mi>j</mi><mi>ğ–³</mi></msubsup><mo rspace="0.055em" stretchy="false">)</mo></mrow></mrow><mo rspace="0.222em">â‹…</mo><mrow><mo stretchy="false">â€–</mo><mrow><msub><mi>ğœ¹</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">â€–</mo></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\stackrel{{\scriptstyle i}}{{\geq}}\prod\nolimits_{j=\ell+1}^{L}\sigma_{\min}(J_{j}^{\mathsf{T}})\cdot\|\bm{\delta}_{L}(o_{i,t})\|</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="A1.E17Xb" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E17Xb.m2" class="ltx_Math" alttext="\displaystyle\stackrel{{\scriptstyle ii}}{{\geq}}\prod\nolimits_{j=\ell+1}^{L}c_{j}\cdot\|\bm{\delta}_{L}(o_{i,t})\|" display="inline"><semantics><mrow><mi></mi><mover><mo>â‰¥</mo><mrow><mi>i</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>i</mi></mrow></mover><mrow><mstyle displaystyle="true"><msubsup><mo>âˆ</mo><mrow><mi>j</mi><mo>=</mo><mrow><mi mathvariant="normal">â„“</mi><mo>+</mo><mn>1</mn></mrow></mrow><mi>L</mi></msubsup></mstyle><mrow><msub><mi>c</mi><mi>j</mi></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mrow><mo stretchy="false">â€–</mo><mrow><msub><mi>ğœ¹</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">â€–</mo></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\stackrel{{\scriptstyle ii}}{{\geq}}\prod\nolimits_{j=\ell+1}^{L}c_{j}\cdot\|\bm{\delta}_{L}(o_{i,t})\|</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="A1.E17Xc" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E17Xc.m2" class="ltx_Math" alttext="\displaystyle\stackrel{{\scriptstyle iii}}{{\geq}}\prod\nolimits_{j=\ell+1}^{L}c_{j}\cdot|w_{i,t}|\cdot\sqrt{\frac{N}{N-1}}\left(1-\pi_{\theta}(v^{k})\right)," display="inline"><semantics><mrow><mrow><mi></mi><mover><mo>â‰¥</mo><mrow><mi>i</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>i</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>i</mi></mrow></mover><mrow><mstyle displaystyle="true"><msubsup><mo>âˆ</mo><mrow><mi>j</mi><mo>=</mo><mrow><mi mathvariant="normal">â„“</mi><mo>+</mo><mn>1</mn></mrow></mrow><mi>L</mi></msubsup></mstyle><mrow><mrow><msub><mi>c</mi><mi>j</mi></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mrow><mo stretchy="false">|</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo rspace="0.055em" stretchy="false">|</mo></mrow><mo rspace="0.222em">â‹…</mo><msqrt><mstyle displaystyle="true"><mfrac><mi>N</mi><mrow><mi>N</mi><mo>âˆ’</mo><mn>1</mn></mrow></mfrac></mstyle></msqrt></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>âˆ’</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\displaystyle\stackrel{{\scriptstyle iii}}{{\geq}}\prod\nolimits_{j=\ell+1}^{L}c_{j}\cdot|w_{i,t}|\cdot\sqrt{\frac{N}{N-1}}\left(1-\pi_{\theta}(v^{k})\right),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
</div>
<div id="A1.SS2.p12" class="ltx_para">
<p class="ltx_p">where inequality (i) follows from the variational characterization of singular values, inequality (ii) is a consequence of AssumptionÂ <a href="#S4.Thmtheorem1" title="Assumption 4.1. â€£ 4.1 Explanation on Low-Probability Tokensâ€™ Dominance â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>, and inequality (iii) results from Eq.Â (<a href="#A1.E16" title="In A.2 Proof for Proposition 4.2 â€£ Appendix A Theoretical Interpretations â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">16</span></a>).</p>
</div>
<div id="A1.SS2.p13" class="ltx_para">
<p class="ltx_p">Next, considering an alternative direction, we derive an upper bound for the gradient norm:</p>
<table id="A1.E18" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="A1.E18X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A1.E18X.m2" class="ltx_Math" alttext="\displaystyle\|\bm{\delta}_{L}(o_{i,t})\|" display="inline"><semantics><mrow><mo stretchy="false">â€–</mo><mrow><msub><mi>ğœ¹</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">â€–</mo></mrow><annotation encoding="application/x-tex">\displaystyle\|\bm{\delta}_{L}(o_{i,t})\|</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E18X.m3" class="ltx_Math" alttext="\displaystyle=|w_{i,t}|\cdot\sqrt{\left(1-\pi_{\theta}(v^{k})\right)^{2}+\sum\nolimits_{n\neq k}^{N}\pi_{\theta}(v^{n})^{2}}" display="inline"><semantics><mrow><mi></mi><mo>=</mo><mrow><mrow><mo stretchy="false">|</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo rspace="0.055em" stretchy="false">|</mo></mrow><mo rspace="0.222em">â‹…</mo><msqrt><mrow><msup><mrow><mo>(</mo><mrow><mn>1</mn><mo>âˆ’</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>)</mo></mrow><mn>2</mn></msup><mo>+</mo><mrow><mstyle displaystyle="true"><msubsup><mo>âˆ‘</mo><mrow><mi>n</mi><mo>â‰ </mo><mi>k</mi></mrow><mi>N</mi></msubsup></mstyle><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><msup><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>n</mi></msup><mo stretchy="false">)</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></msqrt></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=|w_{i,t}|\cdot\sqrt{\left(1-\pi_{\theta}(v^{k})\right)^{2}+\sum\nolimits_{n\neq k}^{N}\pi_{\theta}(v^{n})^{2}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="5" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(18)</span></td>
</tr>
<tr id="A1.E18Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E18Xa.m2" class="ltx_Math" alttext="\displaystyle\leq|w_{i,t}|\cdot\sqrt{\left(1-\pi_{\theta}(v^{k})\right)^{2}+\sum\nolimits_{n\neq k}^{N}\pi_{\theta}(v^{n})^{2}+2\sum\nolimits_{n,m\neq k,n&lt;m}^{N}\pi_{\theta}(v^{n})\pi_{\theta}(v^{m})}" display="inline"><semantics><mrow><mi></mi><mo>â‰¤</mo><mrow><mrow><mo stretchy="false">|</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo rspace="0.055em" stretchy="false">|</mo></mrow><mo rspace="0.222em">â‹…</mo><msqrt><mrow><msup><mrow><mo>(</mo><mrow><mn>1</mn><mo>âˆ’</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>)</mo></mrow><mn>2</mn></msup><mo>+</mo><mrow><mstyle displaystyle="true"><msubsup><mo>âˆ‘</mo><mrow><mi>n</mi><mo>â‰ </mo><mi>k</mi></mrow><mi>N</mi></msubsup></mstyle><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><msup><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>n</mi></msup><mo stretchy="false">)</mo></mrow><mn>2</mn></msup></mrow></mrow><mo>+</mo><mrow><mn>2</mn><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mstyle displaystyle="true"><msubsup><mo>âˆ‘</mo><mrow><mrow><mrow><mi>n</mi><mo>,</mo><mi>m</mi></mrow><mo>â‰ </mo><mi>k</mi></mrow><mo>,</mo><mrow><mi>n</mi><mo>&lt;</mo><mi>m</mi></mrow></mrow><mi>N</mi></msubsup></mstyle><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>n</mi></msup><mo stretchy="false">)</mo></mrow><mo lspace="0em" rspace="0em">â€‹</mo><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>m</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow></mrow></msqrt></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\leq|w_{i,t}|\cdot\sqrt{\left(1-\pi_{\theta}(v^{k})\right)^{2}+\sum\nolimits_{n\neq k}^{N}\pi_{\theta}(v^{n})^{2}+2\sum\nolimits_{n,m\neq k,n&lt;m}^{N}\pi_{\theta}(v^{n})\pi_{\theta}(v^{m})}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="A1.E18Xb" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E18Xb.m2" class="ltx_Math" alttext="\displaystyle=|w_{i,t}|\cdot\sqrt{\left(1-\pi_{\theta}(v^{k})\right)^{2}+\big{(}\sum\nolimits_{n\neq k}^{N}\pi_{\theta}(v^{n})\big{)}^{2}}" display="inline"><semantics><mrow><mi></mi><mo>=</mo><mrow><mrow><mo stretchy="false">|</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo rspace="0.055em" stretchy="false">|</mo></mrow><mo rspace="0.222em">â‹…</mo><msqrt><mrow><msup><mrow><mo>(</mo><mrow><mn>1</mn><mo>âˆ’</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>)</mo></mrow><mn>2</mn></msup><mo>+</mo><msup><mrow><mo maxsize="1.200em" minsize="1.200em">(</mo><mrow><mstyle displaystyle="true"><msubsup><mo>âˆ‘</mo><mrow><mi>n</mi><mo>â‰ </mo><mi>k</mi></mrow><mi>N</mi></msubsup></mstyle><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>n</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo maxsize="1.200em" minsize="1.200em">)</mo></mrow><mn>2</mn></msup></mrow></msqrt></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=|w_{i,t}|\cdot\sqrt{\left(1-\pi_{\theta}(v^{k})\right)^{2}+\big{(}\sum\nolimits_{n\neq k}^{N}\pi_{\theta}(v^{n})\big{)}^{2}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="A1.E18Xc" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E18Xc.m2" class="ltx_Math" alttext="\displaystyle=|w_{i,t}|\cdot\sqrt{\left(1-\pi_{\theta}(v^{k})\right)^{2}+\left(1-\pi_{\theta}(v^{k})\right)^{2}}" display="inline"><semantics><mrow><mi></mi><mo>=</mo><mrow><mrow><mo stretchy="false">|</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo rspace="0.055em" stretchy="false">|</mo></mrow><mo rspace="0.222em">â‹…</mo><msqrt><mrow><msup><mrow><mo>(</mo><mrow><mn>1</mn><mo>âˆ’</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>)</mo></mrow><mn>2</mn></msup><mo>+</mo><msup><mrow><mo>(</mo><mrow><mn>1</mn><mo>âˆ’</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>)</mo></mrow><mn>2</mn></msup></mrow></msqrt></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=|w_{i,t}|\cdot\sqrt{\left(1-\pi_{\theta}(v^{k})\right)^{2}+\left(1-\pi_{\theta}(v^{k})\right)^{2}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="A1.E18Xd" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E18Xd.m2" class="ltx_Math" alttext="\displaystyle=|w_{i,t}|\cdot\sqrt{2}\,\left(1-\pi_{\theta}(o_{i,t})\right)," display="inline"><semantics><mrow><mrow><mi></mi><mo>=</mo><mrow><mrow><mrow><mo stretchy="false">|</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo rspace="0.055em" stretchy="false">|</mo></mrow><mo rspace="0.222em">â‹…</mo><msqrt><mn>2</mn></msqrt></mrow><mo lspace="0.170em" rspace="0em">â€‹</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>âˆ’</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\displaystyle=|w_{i,t}|\cdot\sqrt{2}\,\left(1-\pi_{\theta}(o_{i,t})\right),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
<p class="ltx_p">where the inequality holds because <math id="A1.SS2.p13.m1" class="ltx_Math" alttext="\pi_{\theta}(v^{n})\geq 0" display="inline"><semantics><mrow><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>n</mi></msup><mo stretchy="false">)</mo></mrow></mrow><mo>â‰¥</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\pi_{\theta}(v^{n})\geq 0</annotation></semantics></math> for all <math id="A1.SS2.p13.m2" class="ltx_Math" alttext="n\in{1,2,\dots,N}" display="inline"><semantics><mrow><mi>n</mi><mo>âˆˆ</mo><mrow><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><mi>N</mi></mrow></mrow><annotation encoding="application/x-tex">n\in{1,2,\dots,N}</annotation></semantics></math>. The equality is achieved if and only if there exists an index <math id="A1.SS2.p13.m3" class="ltx_Math" alttext="m" display="inline"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math> such that <math id="A1.SS2.p13.m4" class="ltx_Math" alttext="\pi_{\theta}(v^{m})=1-\pi_{\theta}(v^{k})" display="inline"><semantics><mrow><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>m</mi></msup><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mn>1</mn><mo>âˆ’</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">\pi_{\theta}(v^{m})=1-\pi_{\theta}(v^{k})</annotation></semantics></math> and <math id="A1.SS2.p13.m5" class="ltx_Math" alttext="\pi_{\theta}(v^{m})=0" display="inline"><semantics><mrow><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>m</mi></msup><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\pi_{\theta}(v^{m})=0</annotation></semantics></math> for all <math id="A1.SS2.p13.m6" class="ltx_Math" alttext="n\neq m" display="inline"><semantics><mrow><mi>n</mi><mo>â‰ </mo><mi>m</mi></mrow><annotation encoding="application/x-tex">n\neq m</annotation></semantics></math> and <math id="A1.SS2.p13.m7" class="ltx_Math" alttext="n\neq k" display="inline"><semantics><mrow><mi>n</mi><mo>â‰ </mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n\neq k</annotation></semantics></math>.</p>
</div>
<div id="A1.SS2.p14" class="ltx_para">
<p class="ltx_p">Similarly, substituting Eq.(<a href="#A1.E18" title="In A.2 Proof for Proposition 4.2 â€£ Appendix A Theoretical Interpretations â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">18</span></a>) into Eq.(<a href="#A1.E9" title="In A.2 Proof for Proposition 4.2 â€£ Appendix A Theoretical Interpretations â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>), we have</p>
<table id="A1.E19" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="A1.E19X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A1.E19X.m2" class="ltx_Math" alttext="\displaystyle\|\bm{\delta}_{\ell}(o_{i,t})\|" display="inline"><semantics><mrow><mo stretchy="false">â€–</mo><mrow><msub><mi>ğœ¹</mi><mi mathvariant="normal">â„“</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">â€–</mo></mrow><annotation encoding="application/x-tex">\displaystyle\|\bm{\delta}_{\ell}(o_{i,t})\|</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E19X.m3" class="ltx_Math" alttext="\displaystyle=\|\prod\nolimits_{j=\ell+1}^{L}J_{j}^{\mathsf{T}}\cdot\bm{\delta}_{L}(o_{i,t})\|" display="inline"><semantics><mrow><mi></mi><mo>=</mo><mrow><mo stretchy="false">â€–</mo><mrow><mstyle displaystyle="true"><msubsup><mo>âˆ</mo><mrow><mi>j</mi><mo>=</mo><mrow><mi mathvariant="normal">â„“</mi><mo>+</mo><mn>1</mn></mrow></mrow><mi>L</mi></msubsup></mstyle><mrow><mrow><msubsup><mi>J</mi><mi>j</mi><mi>ğ–³</mi></msubsup><mo lspace="0.222em" rspace="0.222em">â‹…</mo><msub><mi>ğœ¹</mi><mi>L</mi></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mo stretchy="false">â€–</mo></mrow></mrow><annotation encoding="application/x-tex">\displaystyle=\|\prod\nolimits_{j=\ell+1}^{L}J_{j}^{\mathsf{T}}\cdot\bm{\delta}_{L}(o_{i,t})\|</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="4" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(19)</span></td>
</tr>
<tr id="A1.E19Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E19Xa.m2" class="ltx_Math" alttext="\displaystyle\leq\prod\nolimits_{j=\ell+1}^{L}\sigma_{\max}(J_{j}^{\mathsf{T}})\cdot\|\bm{\delta}_{L}(o_{i,t})\|" display="inline"><semantics><mrow><mi></mi><mo>â‰¤</mo><mrow><mstyle displaystyle="true"><msubsup><mo>âˆ</mo><mrow><mi>j</mi><mo>=</mo><mrow><mi mathvariant="normal">â„“</mi><mo>+</mo><mn>1</mn></mrow></mrow><mi>L</mi></msubsup></mstyle><mrow><mrow><msub><mi>Ïƒ</mi><mi>max</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>J</mi><mi>j</mi><mi>ğ–³</mi></msubsup><mo rspace="0.055em" stretchy="false">)</mo></mrow></mrow><mo rspace="0.222em">â‹…</mo><mrow><mo stretchy="false">â€–</mo><mrow><msub><mi>ğœ¹</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">â€–</mo></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\leq\prod\nolimits_{j=\ell+1}^{L}\sigma_{\max}(J_{j}^{\mathsf{T}})\cdot\|\bm{\delta}_{L}(o_{i,t})\|</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="A1.E19Xb" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E19Xb.m2" class="ltx_Math" alttext="\displaystyle\leq\prod\nolimits_{j=\ell+1}^{L}d_{j}\cdot\|\bm{\delta}_{L}(o_{i,t})\|" display="inline"><semantics><mrow><mi></mi><mo>â‰¤</mo><mrow><mstyle displaystyle="true"><msubsup><mo>âˆ</mo><mrow><mi>j</mi><mo>=</mo><mrow><mi mathvariant="normal">â„“</mi><mo>+</mo><mn>1</mn></mrow></mrow><mi>L</mi></msubsup></mstyle><mrow><msub><mi>d</mi><mi>j</mi></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mrow><mo stretchy="false">â€–</mo><mrow><msub><mi>ğœ¹</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">â€–</mo></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\leq\prod\nolimits_{j=\ell+1}^{L}d_{j}\cdot\|\bm{\delta}_{L}(o_{i,t})\|</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="A1.E19Xc" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E19Xc.m2" class="ltx_Math" alttext="\displaystyle\leq\prod\nolimits_{j=\ell+1}^{L}d_{j}\cdot|w_{i,t}|\cdot\sqrt{2}\left(1-\pi_{\theta}(v^{k})\right)," display="inline"><semantics><mrow><mrow><mi></mi><mo>â‰¤</mo><mrow><mstyle displaystyle="true"><msubsup><mo>âˆ</mo><mrow><mi>j</mi><mo>=</mo><mrow><mi mathvariant="normal">â„“</mi><mo>+</mo><mn>1</mn></mrow></mrow><mi>L</mi></msubsup></mstyle><mrow><mrow><msub><mi>d</mi><mi>j</mi></msub><mo lspace="0.222em" rspace="0.222em">â‹…</mo><mrow><mo stretchy="false">|</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo rspace="0.055em" stretchy="false">|</mo></mrow><mo rspace="0.222em">â‹…</mo><msqrt><mn>2</mn></msqrt></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>âˆ’</mo><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msup><mi>v</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\displaystyle\leq\prod\nolimits_{j=\ell+1}^{L}d_{j}\cdot|w_{i,t}|\cdot\sqrt{2}\left(1-\pi_{\theta}(v^{k})\right),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
</div>
<div id="A1.SS2.p15" class="ltx_para">
<p class="ltx_p">where the inequalities hold for the same reasons as in Eq.Â (<a href="#A1.E17" title="In A.2 Proof for Proposition 4.2 â€£ Appendix A Theoretical Interpretations â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">17</span></a>). Together, Eqs.Â (<a href="#A1.E17" title="In A.2 Proof for Proposition 4.2 â€£ Appendix A Theoretical Interpretations â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">17</span></a>) and (<a href="#A1.E19" title="In A.2 Proof for Proposition 4.2 â€£ Appendix A Theoretical Interpretations â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">19</span></a>) establish the result of PropositionÂ <a href="#S4.Thmtheorem2" title="Proposition 4.2. â€£ 4.1 Explanation on Low-Probability Tokensâ€™ Dominance â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>.</p>
</div>
</section>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Hyperparameter Settings</h2>

<div id="A2.p1" class="ltx_para">
<p class="ltx_p">As described in SectionÂ <a href="#S4.SS2" title="4.2 Mitigating the Over-Dominance of Low-Probability Tokens â€£ 4 Methodology â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>, our proposed <span class="ltx_text ltx_font_italic">Advantage Reweighting</span> and <span class="ltx_text ltx_font_italic">Lopti</span> require only minor modifications to the existing GRPO training framework.
Our implementation is built upon the <span class="ltx_text ltx_font_typewriter">verl</span> library<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://github.com/volcengine/verl" title="" class="ltx_ref ltx_href">https://github.com/volcengine/verl</a></span></span></span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>.
The key hyperparameter configurations for GRPO training are detailed in TableÂ <a href="#A2.T2" title="Table 2 â€£ Appendix B Hyperparameter Settings â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
Note that we adopt the â€˜clip higherâ€™ technique from DAPOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> to stabilize entropy and mitigate entropy collapse. All other hyperparameters adhere to the default settings provided by <span class="ltx_text ltx_font_typewriter">verl</span>.</p>
</div>
<div id="A2.p2" class="ltx_para">
<p class="ltx_p">The hyperparameter configurations specific to <span class="ltx_text ltx_font_italic">Advantage Reweighting</span> and <span class="ltx_text ltx_font_italic">Lopti</span> are summarized in TableÂ <a href="#A2.T3" title="Table 3 â€£ Appendix B Hyperparameter Settings â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
As reported in SectionÂ <a href="#S5" title="5 Experimental Results â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, while the joint application of the two techniques generally yields improved results for the K&amp;K Logic Puzzle dataset, this is not the case for the Math dataset. Consequently, using either technique individually is recommended for the math-related dataset.
For consistency, the same seed is used across all experiments.
We save a checkpoint every 20 RL steps, and all evaluation accuracies reported on the test set in this paper are averaged over the last three checkpoints.
The detailed implementation can be found in our code.</p>
</div>
<figure id="A2.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Key hyperparameters for GRPO training, with the corresponding variable names in the <span class="ltx_text ltx_font_typewriter">verl</span> configuration indicated in brackets.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="background-color:#EFEFEF;" colspan="2"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Value</span></td>
</tr>
<tr class="ltx_tr" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Hyperparameter</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">K&amp;K</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Math</span></td>
</tr>
<tr class="ltx_tr" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#ECF4FF;">Rollout-related</span></td>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Sampling temperature (<span class="ltx_text ltx_font_typewriter">temperature</span>)</td>
<td class="ltx_td ltx_align_center">0.7</td>
<td class="ltx_td ltx_align_center">1.0</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Question num per batch (<span class="ltx_text ltx_font_typewriter">ppo_mini_batch_size</span>)</td>
<td class="ltx_td ltx_align_center">64</td>
<td class="ltx_td ltx_align_center">128</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Answer num per question (<span class="ltx_text ltx_font_typewriter">rollout.n</span>)</td>
<td class="ltx_td ltx_align_center" colspan="2">8</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Max tokens num per response (<span class="ltx_text ltx_font_typewriter">max_response_length</span>)</td>
<td class="ltx_td ltx_align_center" colspan="2">4096</td>
</tr>
<tr class="ltx_tr" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#ECF4FF;">Training-related</span></td>
<td class="ltx_td ltx_border_t"></td>
<td class="ltx_td ltx_border_t"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Update batch size (<span class="ltx_text ltx_font_typewriter">ppo_micro_batch_size</span>)</td>
<td class="ltx_td ltx_align_center">256</td>
<td class="ltx_td ltx_align_center">512</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Optimizer (<span class="ltx_text ltx_font_typewriter">optim.type</span>)</td>
<td class="ltx_td ltx_align_center" colspan="2">adamw</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Learning rate (<span class="ltx_text ltx_font_typewriter">optim.lr</span>)</td>
<td class="ltx_td ltx_align_center" colspan="2">1e-6</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">KL divergence coefficient (<span class="ltx_text ltx_font_typewriter">kl_loss_coef</span>)</td>
<td class="ltx_td ltx_align_center" colspan="2">0.001</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Lower clipping threshold (<span class="ltx_text ltx_font_typewriter">clip_ratio_low</span>)</td>
<td class="ltx_td ltx_align_center" colspan="2">0.2</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b">Upper clipping threshold (<span class="ltx_text ltx_font_typewriter">clip_ratio_high</span>)</td>
<td class="ltx_td ltx_align_center ltx_border_b" colspan="2">0.24</td>
</tr>
</tbody>
</table>
</figure>
<figure id="A2.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Hyperparameter settings for <span class="ltx_text ltx_font_italic">Advantage Reweighting</span> and <span class="ltx_text ltx_font_italic">Lopti</span>.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_border_t"></td>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="background-color:#EFEFEF;" colspan="2"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Value</span></th>
</tr>
<tr class="ltx_tr" style="background-color:#EFEFEF;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Hyperparameter</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">K&amp;K</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Math</span></th>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t">Advantage Reweighting (<math id="A2.T3.m1" class="ltx_Math" alttext="\alpha" display="inline"><semantics><mi>Î±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.3</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.1</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Lopti (<math id="A2.T3.m2" class="ltx_Math" alttext="\eta" display="inline"><semantics><mi>Î·</mi><annotation encoding="application/x-tex">\eta</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center">0.5</td>
<td class="ltx_td ltx_align_center">0.5</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b">Joint operation for better results</td>
<td class="ltx_td ltx_align_center ltx_border_b"><span class="ltx_text ltx_font_typewriter">True</span></td>
<td class="ltx_td ltx_align_center ltx_border_b"><span class="ltx_text ltx_font_typewriter">False</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Experimental Details</h2>

<section id="A3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Task Description</h3>

<section id="A3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">C.1.1 </span>K&amp;K Logic Puzzle</h4>

<div id="A3.SS1.SSS1.p1" class="ltx_para">
<p class="ltx_p">As introduced in SectionÂ <a href="#S5.SS1" title="5.1 Experiments on K&amp;K Logic Puzzles â€£ 5 Experimental Results â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>, the K&amp;K logic puzzles involve a fictional scenario where inhabitants of an island are either Knights, who always tell the truth, or Knaves, who always lie.
The objective of the LLMs is to determine the identity of each inhabitant (Knight or Knave) based on a set of statements they make about themselves and others. Following Logic-RLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, we utilize the LLMs after instruction fine-tuning (<span class="ltx_text ltx_font_typewriter">Qwen2.5-3B-Instruct</span> and <span class="ltx_text ltx_font_typewriter">Qwen2.5-7B-Instruct-1M</span>) as starting point. The prompt specifically designed for the LLMs is as follows.</p>
</div>
<div id="A3.SS1.SSS1.p2" class="ltx_para ltx_noindent ltx_align_center">
<span class="ltx_inline-block"><svg id="A3.SS1.SSS1.p2.pic1" class="ltx_picture" height="166.19" overflow="visible" version="1.1" viewBox="0 0 570 166.19" width="570"><g transform="translate(0,166.19) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#008080" fill-opacity="1.0"><path d="M 0 0 L 0 166.19 L 570 166.19 L 570 0 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 3.94 3.94 L 3.94 138.25 L 566.06 138.25 L 566.06 3.94 Z" style="stroke:none"></path></g><g fill="#008080" fill-opacity="1.0"><path d="M 3.94 142.19 L 3.94 162.25 L 566.06 162.25 L 566.06 142.19 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 15.75 148.82)"><foreignObject width="538.5" height="12.18" transform="matrix(1 0 0 -1 0 9.49)" overflow="visible" style="--fo_width :38.92em;--fo_height:0.69em;--fo_depth :0.19em;" color="#FFFFFF"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:33.84em;">
<span class="ltx_p"><span class="ltx_text ltx_font_bold">Prompt</span></span>
</span></span></span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 15.75 18.52)"><foreignObject width="538.5" height="110.7" transform="matrix(1 0 0 -1 0 107.93)" overflow="visible" style="--fo_width :38.92em;--fo_height:7.8em;--fo_depth :0.2em;" color="#000000"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:45.78em;">
<span class="ltx_p"><span class="ltx_text" style="font-size:80%;color:#404040;">system\n You are a helpful assistant. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within &lt;think&gt; &lt;/think&gt; and&lt;answer&gt; &lt;/answer&gt; tags, respectively, i.e., &lt;think&gt; reasoning process here &lt;/think&gt;&lt;answer&gt; answer here &lt;/answer&gt;. Now the user asks you to solve a logical reasoning problem. After thinking, when you finally reach a conclusion, clearly state the identity of each character within &lt;answer&gt; &lt;/answer&gt; tags. i.e., &lt;answer&gt; (1) Zoey is a knight\n (2) â€¦ &lt;/answer&gt;.\n \n user\n <span class="ltx_text" style="color:#FF0000;">{problem}</span>\n \n assistant\n &lt;think&gt;
<span class="ltx_text" style="color:#000000;"></span></span></span>
</span></span></span></foreignObject></g></g></svg></span>
</div>
<div id="A3.SS1.SSS1.p3" class="ltx_para">
<p class="ltx_p">To encourage LLMs to exhibit chain-of-thought (CoT) reasoning, Logic-RLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> designs a reward function consisting of two components, as outlined in TableÂ <a href="#A3.T4" title="Table 4 â€£ C.1.1 K&amp;K Logic Puzzle â€£ C.1 Task Description â€£ Appendix C Experimental Details â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. The output format is deemed completely correct if LLMs include CoT reasoning enclosed within <span class="ltx_text ltx_font_typewriter">&lt;think&gt;&lt;/think&gt;</span> tags and the final answer enclosed within <span class="ltx_text ltx_font_typewriter">&lt;answer&gt;&lt;/answer&gt;</span> tags.</p>
</div>
<figure id="A3.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Reward design for K&amp;K Logic Puzzle proposed in Logic-RLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite></figcaption>
<p class="ltx_p ltx_align_center">.


<span class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<span class="ltx_thead">
<span class="ltx_tr">
<span class="ltx_td ltx_th ltx_th_row ltx_border_t"></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Format Reward</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Answer Reward</span></span></span>
<span class="ltx_tr">
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t">Completely Correct</span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">1</span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">2</span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row">Patially Correct</span>
<span class="ltx_td ltx_align_center">-1</span>
<span class="ltx_td ltx_align_center">-1.5</span></span>
<span class="ltx_tr">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b">Completely Wrong</span>
<span class="ltx_td ltx_align_center ltx_border_b">-1</span>
<span class="ltx_td ltx_align_center ltx_border_b">-2</span></span>
</span>
</span></p>
</figure>
<div id="A3.SS1.SSS1.p4" class="ltx_para">
<p class="ltx_p">For the K&amp;K Logic Puzzle dataset, the number of players (ranging from 3 to 7) can be adjusted to control the difficulty level, with a greater number of players resulting in higher difficulty. To provide an intuitive illustration, we present an easy example with 3 players and a challenging example with 7 players below. Without utilizing curriculum learning, we directly train the LLMs on the mixed training set for a total of 5 epochs.</p>
</div>
<div id="A3.SS1.SSS1.p5" class="ltx_para ltx_noindent">
<div class="ltx_logical-block">
<div id="A3.SS1.SSS1.p5.p1" class="ltx_para ltx_noindent ltx_align_center">
<span class="ltx_inline-block"><svg id="A3.SS1.SSS1.p5.p1.pic1" class="ltx_picture" height="223.26" overflow="visible" version="1.1" viewBox="0 0 570 223.26" width="570"><g transform="translate(0,223.26) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#0F75FF" fill-opacity="1.0"><path d="M 0 0 L 0 223.26 L 570 223.26 L 570 0 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 3.94 3.94 L 3.94 197.68 L 566.06 197.68 L 566.06 3.94 Z" style="stroke:none"></path></g><g fill="#0F75FF" fill-opacity="1.0"><path d="M 3.94 201.61 L 3.94 219.33 L 566.06 219.33 L 566.06 201.61 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 15.75 207.7)"><foreignObject width="538.5" height="9.84" transform="matrix(1 0 0 -1 0 7.69)" overflow="visible" style="--fo_width :45.78em;--fo_height:0.65em;--fo_depth :0.18em;" color="#FFFFFF"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:39.71em;">
<span class="ltx_p"><span class="ltx_text ltx_font_bold" style="font-size:80%;">An Example of K&amp;K Puzzle with 3 people</span></span>
</span></span></span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 15.75 18.52)"><foreignObject width="538.5" height="170.12" transform="matrix(1 0 0 -1 0 167.35)" overflow="visible" style="--fo_width :45.78em;--fo_height:14.23em;--fo_depth :0.24em;" color="#000000"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:45.78em;">
<span class="ltx_p"><span class="ltx_text ltx_font_bold">Problem:</span><span class="ltx_text" style="font-size:80%;"></span></span>
<span class="ltx_p"><span class="ltx_text" style="font-size:80%;color:#404040;">A very special island is inhabited only by knights and knaves. Knights always tell the truth, and knaves always lie. You meet 3 inhabitants: Alexander, Lily, and Samuel. Alexander remarked, "Lily is a knave or Lily is a knight". In a statement by Lily: "Samuel is a knight if and only if Lily is a knight". Samuel was heard saying, "Lily is a knight". So who is a knight and who is a knave?</span><span class="ltx_text" style="font-size:80%;"></span></span>
<span class="ltx_p"><span class="ltx_text ltx_font_bold">Example Reasoning Process:
<br class="ltx_break"></span><span class="ltx_text" style="font-size:80%;color:#404040;">
â€¢â€‰ Assume Alexander is a knight. No contradiction is found in their claim that Lily is a knave or Lily is a knight.
<br class="ltx_break">â€¢â€‰ Assume Lily is a knight. No contradiction is found in their claim that Samuel is a knight if and only if Lily is a knight.
<br class="ltx_break">â€¢â€‰ Assume Samuel is a knight. No contradiction is found in their claim that Lily is a knight.</span><span class="ltx_text" style="font-size:80%;"></span></span>
<span class="ltx_p"><span class="ltx_text ltx_font_bold">Standard Solution:
<br class="ltx_break"></span><span class="ltx_text" style="font-size:80%;color:#404040;">(1) Alexander is a knight, (2) Lily is a knight, (3) Samuel is a knight</span><span class="ltx_text" style="font-size:80%;"></span></span>
</span></span></span></foreignObject></g></g></svg></span>
</div>
</div>
</div>
<div id="A3.SS1.SSS1.p6" class="ltx_para ltx_noindent">
<div class="ltx_logical-block">
<div id="A3.SS1.SSS1.p6.p1" class="ltx_para ltx_noindent ltx_align_center">
<span class="ltx_inline-block"><svg id="A3.SS1.SSS1.p6.p1.pic1" class="ltx_picture" height="394.15" overflow="visible" version="1.1" viewBox="0 0 570 394.15" width="570"><g transform="translate(0,394.15) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#0F75FF" fill-opacity="1.0"><path d="M 0 0 L 0 394.15 L 570 394.15 L 570 0 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 3.94 3.94 L 3.94 368.56 L 566.06 368.56 L 566.06 3.94 Z" style="stroke:none"></path></g><g fill="#0F75FF" fill-opacity="1.0"><path d="M 3.94 372.5 L 3.94 390.21 L 566.06 390.21 L 566.06 372.5 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 15.75 378.59)"><foreignObject width="538.5" height="9.84" transform="matrix(1 0 0 -1 0 7.69)" overflow="visible" style="--fo_width :45.78em;--fo_height:0.65em;--fo_depth :0.18em;" color="#FFFFFF"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:39.71em;">
<span class="ltx_p"><span class="ltx_text ltx_font_bold" style="font-size:80%;">An Example of K&amp;K Puzzle with 7 people</span></span>
</span></span></span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 15.75 18.52)"><foreignObject width="538.5" height="341.01" transform="matrix(1 0 0 -1 0 338.24)" overflow="visible" style="--fo_width :45.78em;--fo_height:28.76em;--fo_depth :0.24em;" color="#000000"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:45.78em;">
<span class="ltx_p"><span class="ltx_text ltx_font_bold">Problem:</span><span class="ltx_text" style="font-size:80%;"></span></span>
<span class="ltx_p"><span class="ltx_text" style="font-size:80%;color:#404040;">A very special island is inhabited only by knights and knaves. Knights always tell the truth, and knaves always lie. You meet 7 inhabitants: Harper, Emma, Mia, Luke, Alexander, David, and Ethan. As Harper put it, "David is not a knight". In Emmaâ€™s words: "David is a knight". Mia said that If Emma is a knight then Emma is a knave. Luke said, "If Alexander is a knave then Emma is a knight." Alexander was heard saying, "If David is a knight then Harper is a knave". "Alexander is not a knight" - David. "Harper is a knight," Ethan mentioned. So who is a knight and who is a knave?</span><span class="ltx_text" style="font-size:80%;"></span></span>
<span class="ltx_p"><span class="ltx_text ltx_font_bold">Example Reasoning Process:
<br class="ltx_break"></span><span class="ltx_text" style="font-size:80%;color:#404040;">
â€¢â€‰ Assume Harper is a knight. No contradiction is found in their claim that David is not a knight.
<br class="ltx_break">â€¢â€‰ David cannot be a knight, because this would contradict the claim of Harper that David is not a knight.
<br class="ltx_break">â€¢â€‰ Assume David is a knave. No contradiction is found in their false claim that Alexander is not a knight.
<br class="ltx_break">â€¢â€‰ Assume Alexander is a knight. No contradiction is found in their claim that If David is a knight then Harper is a knave.
<br class="ltx_break">â€¢â€‰ Emma cannot be a knight, because this would contradict the claim of their own that David is a knight.
<br class="ltx_break">â€¢â€‰ Assume Emma is a knave. No contradiction is found in their false claim that David is a knight.
<br class="ltx_break">â€¢â€‰ Assume Mia is a knight. No contradiction is found in their claim that If Emma is a knight then Emma is a knave.
<br class="ltx_break">â€¢â€‰ Assume Luke is a knight. No contradiction is found in their claim that If Alexander is a knave then Emma is a knight.
<br class="ltx_break">â€¢â€‰ Assume Ethan is a knight. No contradiction is found in their claim that Harper is a knight.</span><span class="ltx_text" style="font-size:80%;"></span></span>
<span class="ltx_p"><span class="ltx_text ltx_font_bold">Standard Solution:
<br class="ltx_break"></span><span class="ltx_text" style="font-size:80%;color:#404040;">(1) Harper is a knight (2) Emma is a knave (3) Mia is a knight (4) Luke is a knight (5) Alexander is a knight (6) David is a knave (7) Ethan is a knight</span><span class="ltx_text" style="font-size:80%;"></span></span>
</span></span></span></foreignObject></g></g></svg></span>
</div>
</div>
</div>
<div id="A3.SS1.SSS1.p7" class="ltx_para">
<p class="ltx_p">The detailed training records for <span class="ltx_text ltx_font_typewriter">Qwen2.5-3B-Instruct</span> and <span class="ltx_text ltx_font_typewriter">Qwen2.5-7B-Instruct-1M</span> are presented in FigureÂ <a href="#A3.F7" title="Figure 7 â€£ C.1.1 K&amp;K Logic Puzzle â€£ C.1 Task Description â€£ Appendix C Experimental Details â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> and FigureÂ <a href="#A3.F8" title="Figure 8 â€£ C.1.1 K&amp;K Logic Puzzle â€£ C.1 Task Description â€£ Appendix C Experimental Details â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, respectively. In addition to the points discussed in SectionÂ <a href="#S5.SS1" title="5.1 Experiments on K&amp;K Logic Puzzles â€£ 5 Experimental Results â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>, it is worth noting that our <span class="ltx_text ltx_font_italic">Advantage Reweighting</span> and <span class="ltx_text ltx_font_italic">Lopti</span> approaches slightly increase the response length while significantly reducing the gradient norm compared to the naive GRPO. Both observations empirically suggest that the RL training process is further stabilized.</p>
</div>
<figure id="A3.F7" class="ltx_figure"><img src="/html/2505.12929/assets/fig/kk_logics_training_record_3B.png" id="A3.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="299" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>
Experimental records of <span class="ltx_text ltx_font_typewriter">Qwen2.5-3B-Instruct</span> trained with GRPO on the K&amp;K Logic Puzzle dataset. The training curve is smoothed through exponential moving average with coefficient of 0.95.
</figcaption>
</figure>
<figure id="A3.F8" class="ltx_figure"><img src="/html/2505.12929/assets/fig/kk_logics_training_record_7B.png" id="A3.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="299" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>
Experimental records of <span class="ltx_text ltx_font_typewriter">Qwen2.5-7B-Instruct-1M</span> trained with GRPO on the K&amp;K Logic Puzzle dataset.
</figcaption>
</figure>
<div id="A3.SS1.SSS1.p8" class="ltx_para">
<p class="ltx_p">For the six categories of inference-related words used in the linguistic analysis, the detailed word lists are provided in TableÂ <a href="#A3.T5" title="Table 5 â€£ C.1.1 K&amp;K Logic Puzzle â€£ C.1 Task Description â€£ Appendix C Experimental Details â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. It is important to note that for the nouns and verbs listed in the table, their conjugated forms are also included in the analysis. Specifically, we account for the plural forms of nouns as well as the past tense and past participle forms of verbs. Additionally, uppercase and lowercase letters are treated equivalently.</p>
</div>
<figure id="A3.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Six categories of inference-related words associated with LLMsâ€™ performance on the K&amp;K Logic Puzzles dataset.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr" style="background-color:#EFEFEF;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Category</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Words<span class="ltx_text ltx_font_medium"> <span class="ltx_text" style="color:#404040;background-color:#EFEFEF;">(Nouns and verbs include their conjugated forms)</span></span></span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t">Analysis</td>
<td class="ltx_td ltx_align_left ltx_border_t">â€˜analyzeâ€™, â€˜considerâ€™, â€˜look atâ€™, â€˜checkâ€™, â€˜examineâ€™</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Statement</td>
<td class="ltx_td ltx_align_left">XXXâ€™s â€˜statementâ€™</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Causal Indicator</td>
<td class="ltx_td ltx_align_left">â€˜sinceâ€™, â€˜becauseâ€™, â€˜due toâ€™, â€˜given thatâ€™</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Conclusion Indicator</td>
<td class="ltx_td ltx_align_left">â€˜soâ€™, â€˜thusâ€™, â€˜henceâ€™, â€˜as a resultâ€™, â€˜consequentlyâ€™, â€˜thereforeâ€™</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Assumption</td>
<td class="ltx_td ltx_align_left">â€˜assumeâ€™, â€˜ifâ€¦thenâ€¦â€™</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b">Assertion</td>
<td class="ltx_td ltx_align_left ltx_border_b">â€˜must beâ€™, â€˜definiteâ€™</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="A3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">C.1.2 </span>Math Dataset</h4>

<div id="A3.SS1.SSS2.p1" class="ltx_para">
<p class="ltx_p">As discussed in SectionÂ <a href="#S5.SS2" title="5.2 Experiments on Math-related Datasets â€£ 5 Experimental Results â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>, we perform additional experiments on two math-related datasets, DSR-Uniform and ORZ. Consistent with the majority of prior studies, we use <span class="ltx_text ltx_font_typewriter">Qwen2.5-7B</span> as the starting point. It is important to note that <span class="ltx_text ltx_font_typewriter">Qwen2.5-7B</span> undergoes no post-training. This setup is therefore referred to as a "cold-start" and denoted as RL-ZeroÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. No instruction-following templates are employed; instead, we use the following straightforward prompt.</p>
</div>
<div id="A3.SS1.SSS2.p2" class="ltx_para ltx_noindent ltx_align_center">
<span class="ltx_inline-block"><svg id="A3.SS1.SSS2.p2.pic1" class="ltx_picture" height="66.56" overflow="visible" version="1.1" viewBox="0 0 570 66.56" width="570"><g transform="translate(0,66.56) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#008080" fill-opacity="1.0"><path d="M 0 0 L 0 66.56 L 570 66.56 L 570 0 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 3.94 3.94 L 3.94 38.63 L 566.06 38.63 L 566.06 3.94 Z" style="stroke:none"></path></g><g fill="#008080" fill-opacity="1.0"><path d="M 3.94 42.57 L 3.94 62.62 L 566.06 62.62 L 566.06 42.57 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 15.75 49.19)"><foreignObject width="538.5" height="12.18" transform="matrix(1 0 0 -1 0 9.49)" overflow="visible" style="--fo_width :38.92em;--fo_height:0.69em;--fo_depth :0.19em;" color="#FFFFFF"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:33.84em;">
<span class="ltx_p"><span class="ltx_text ltx_font_bold">Prompt</span></span>
</span></span></span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 15.75 18.52)"><foreignObject width="538.5" height="11.07" transform="matrix(1 0 0 -1 0 8.3)" overflow="visible" style="--fo_width :38.92em;--fo_height:0.6em;--fo_depth :0.2em;" color="#000000"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:45.78em;">
<span class="ltx_p"><span class="ltx_text" style="font-size:80%;color:#FF0000;">{problem}<span class="ltx_text" style="color:#000000;"> <span class="ltx_text" style="color:#404040;">Letâ€™s think step by step and output the final answer within \\boxed{}.</span></span></span></span>
</span></span></span></foreignObject></g></g></svg></span>
</div>
<div id="A3.SS1.SSS2.p3" class="ltx_para">
<p class="ltx_p">LLMs that have not undergone post-training typically exhibit poor performance in adhering to specific output formats. As a result, format-related points were not included during training. Additionally, math problems are generally not partially correct, making a binary reward sufficient for evaluating the LLMsâ€™ output. Specifically, a reward of 1 is assigned when LLMs produce the correct answer, and 0 otherwise.</p>
</div>
<div id="A3.SS1.SSS2.p4" class="ltx_para">
<p class="ltx_p">The detailed experimental results for the DSR-Uniform and ORZ datasets are presented in FigureÂ <a href="#A3.F9" title="Figure 9 â€£ C.1.2 Math Dataset â€£ C.1 Task Description â€£ Appendix C Experimental Details â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> and FigureÂ <a href="#A3.F10" title="Figure 10 â€£ C.1.2 Math Dataset â€£ C.1 Task Description â€£ Appendix C Experimental Details â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>, respectively. Notably, the training curve for DSR-Uniform demonstrates a continual learning trend, with the reward progressively increasing over time. In contrast, this is not observed for ORZ, where the reward converges rapidly within 100 steps. However, the test accuracy curves for both datasets converge to a stable value within 100 steps, after which they exhibit only minor fluctuations. Despite these patterns, the improvements achieved by our proposed methods, <span class="ltx_text ltx_font_italic">Advantage Reweighting</span> and <span class="ltx_text ltx_font_italic">Lopti</span>, remain clearly observable.</p>
</div>
<figure id="A3.F9" class="ltx_figure"><img src="/html/2505.12929/assets/fig/deepscaler_record.png" id="A3.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="568" height="341" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>
Experimental records of <span class="ltx_text ltx_font_typewriter">Qwen2.5-7B</span> trained with GRPO on DSR-uniform dataset. The training curve is smoothed through exponential moving average with coefficient of 0.95, and the testing curve is smoothed with a window size of 3.
</figcaption>
</figure>
<figure id="A3.F10" class="ltx_figure"><img src="/html/2505.12929/assets/fig/orz_record.png" id="A3.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="568" height="341" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>
Experimental records of <span class="ltx_text ltx_font_typewriter">Qwen2.5-7B</span> trained with GRPO on ORZ dataset.
</figcaption>
</figure>
</section>
</section>
<section id="A3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Computational Costs</h3>

<div id="A3.SS2.p1" class="ltx_para">
<p class="ltx_p">Our experiments are conducted on a single machine equipped with an AMD EPYC 7V13 64-Core CPU and four NVIDIA A100 80GB PCIe GPUs. The experiments on the K&amp;K Logic Puzzle dataset require approximately 16â€“22 hours to complete (excluding testing during the training process), while those on the math-related dataset take around 37â€“48 hours.</p>
</div>
<div id="A3.SS2.p2" class="ltx_para">
<p class="ltx_p">The <span class="ltx_text ltx_font_italic">Advantage Reweighting</span> involves only recalculating the advantage of tokens, with a time overhead in the range of milliseconds. However, this efficiency does not apply to <span class="ltx_text ltx_font_italic">Lopti</span>, as it splits the tokens in a batch into two groups and performs updates twice. Consequently, the updating process requires twice the amount of time, as detailed in TableÂ <a href="#A3.T6" title="Table 6 â€£ C.2 Computational Costs â€£ Appendix C Experimental Details â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<figure id="A3.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Computational cost comparison of <span class="ltx_text ltx_font_italic">Lopti</span> operation over the first 50 training steps on K&amp;K Logic Puzzle Dataset.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_border_r ltx_border_t"></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="background-color:#EFEFEF;" colspan="4"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Time (s)/step</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_r"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#EFEFEF;" colspan="2"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Qwen2.5-3B-Instruct</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="background-color:#EFEFEF;" colspan="2"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Qwen2.5-7B-Instruct-1M</span></td>
</tr>
<tr class="ltx_tr" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_center ltx_border_r" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Procedure</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">w/o Lopti</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">w/ Lopti</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">w/o Lopti</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">w/ Lopti</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">Sampling</span></td>
<td class="ltx_td ltx_align_center ltx_border_t">25.4</td>
<td class="ltx_td ltx_align_center ltx_border_t">27.8</td>
<td class="ltx_td ltx_align_center ltx_border_t">61.4</td>
<td class="ltx_td ltx_align_center ltx_border_t">116.8</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Training</span></td>
<td class="ltx_td ltx_align_center">17.6</td>
<td class="ltx_td ltx_align_center">35.3</td>
<td class="ltx_td ltx_align_center">68.5</td>
<td class="ltx_td ltx_align_center">69.3</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Others</span></td>
<td class="ltx_td ltx_align_center">2.4</td>
<td class="ltx_td ltx_align_center">2.8</td>
<td class="ltx_td ltx_align_center">10.3</td>
<td class="ltx_td ltx_align_center">10.2</td>
</tr>
<tr class="ltx_tr" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_center ltx_border_b"><span class="ltx_text ltx_font_bold" style="background-color:#ECF4FF;">Total</span></td>
<td class="ltx_td ltx_align_center ltx_border_b"><span class="ltx_text" style="background-color:#ECF4FF;">45.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_b"><span class="ltx_text" style="background-color:#ECF4FF;">65.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_b"><span class="ltx_text" style="background-color:#ECF4FF;">140.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_b"><span class="ltx_text" style="background-color:#ECF4FF;">196.3</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Additional Experimental Results on REINFORCE++</h2>

<div id="A4.p1" class="ltx_para">
<p class="ltx_p">In addition to GRPO, our proposed methods, <span class="ltx_text ltx_font_italic">Advantage Reweighting</span> and <span class="ltx_text ltx_font_italic">Lopti</span>, are also well-adapted to other Policy Gradient-based RL algorithms.
In this section, we extend our methods to REINFORCE++Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>, a widely recognized algorithm that builds upon the conventional REINFORCEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> while incorporating various stabilization techniques introduced by PPOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.
We first provide an introduction to the REINFORCE++ in AppendixÂ <a href="#A4.SS1" title="D.1 REINFORCE++ â€£ Appendix D Additional Experimental Results on REINFORCE++ â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D.1</span></a> and subsequently present the experimental results in AppendixÂ <a href="#A4.SS2" title="D.2 Experiments on K&amp;K Logic Puzzle â€£ Appendix D Additional Experimental Results on REINFORCE++ â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D.2</span></a>.</p>
</div>
<section id="A4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.1 </span>REINFORCE++</h3>

<div id="A4.SS1.p1" class="ltx_para">
<p class="ltx_p">Similar to GRPO, REINFORCE++ also eliminates the need for a value model, thereby reducing computational costs compared to PPO.
The key differences between GRPO and REINFORCE++ lie in how they <span class="ltx_text ltx_font_italic">estimate the advantage</span> and <span class="ltx_text ltx_font_italic">constrain the distance between the RL-trained model and the initial (or reference) model</span>. GRPO estimates the advantage based on the difference between the reward and the group-relative expected return, incorporating the KL constraint directly into the objective function (cf. SectionÂ <a href="#S3" title="3 Preliminary â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> for details). In contrast, REINFORCE++ does not emphasize the concept of â€˜groupâ€™ under the same prompt. Instead, it estimates the advantage directly from the reward and treats the KL constraint as a penalty term added to the reward.
Specifically, REINFORCE++ estimates the advantage as follows:</p>
</div>
<div id="A4.SS1.p2" class="ltx_para">
<table id="A4.E20" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A4.E20.m1" class="ltx_Math" alttext="\hat{A}_{i,t}=\frac{\hat{A}_{i,t}^{R++}-\mu_{A}}{\sigma_{A}}\,\,\,\mathrm{with}\,\,\,\hat{A}_{i,t}^{R++}=r(\bm{q},\bm{o}_{i})-\beta\cdot\sum_{j=t}^{T}\mathbb{D}_{\mathrm{KL}}\left[\pi_{\theta}(o_{i,j})\|\pi_{ref}(o_{i,j})\right]," display="block"><semantics><mrow><mrow><msub><mover accent="true"><mi>A</mi><mo>^</mo></mover><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo>=</mo><mrow><mfrac><mrow><msubsup><mover accent="true"><mi>A</mi><mo>^</mo></mover><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow><mrow><mrow><mi>R</mi><mo>+</mo></mrow><mo lspace="0em">â£</mo><mo>+</mo></mrow></msubsup><mo>âˆ’</mo><msub><mi>Î¼</mi><mi>A</mi></msub></mrow><msub><mi>Ïƒ</mi><mi>A</mi></msub></mfrac><mo lspace="0.500em" rspace="0em">â€‹</mo><mi>with</mi><mo lspace="0.500em" rspace="0em">â€‹</mo><msubsup><mover accent="true"><mi>A</mi><mo>^</mo></mover><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow><mrow><mrow><mi>R</mi><mo>+</mo></mrow><mo lspace="0em">â£</mo><mo>+</mo></mrow></msubsup></mrow><mo>=</mo><mrow><mrow><mi>r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>ğ’’</mi><mo>,</mo><msub><mi>ğ’</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mrow><mo>âˆ’</mo><mrow><mi>Î²</mi><mo lspace="0.222em" rspace="0.055em">â‹…</mo><mrow><munderover><mo movablelimits="false">âˆ‘</mo><mrow><mi>j</mi><mo>=</mo><mi>t</mi></mrow><mi>T</mi></munderover><mrow><msub><mi>ğ”»</mi><mi>KL</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo>[</mo><mrow><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo>âˆ¥</mo><mrow><msub><mi>Ï€</mi><mrow><mi>r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>f</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>]</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\hat{A}_{i,t}=\frac{\hat{A}_{i,t}^{R++}-\mu_{A}}{\sigma_{A}}\,\,\,\mathrm{with}\,\,\,\hat{A}_{i,t}^{R++}=r(\bm{q},\bm{o}_{i})-\beta\cdot\sum_{j=t}^{T}\mathbb{D}_{\mathrm{KL}}\left[\pi_{\theta}(o_{i,j})\|\pi_{ref}(o_{i,j})\right],</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(20)</span></td>
</tr></tbody>
</table>
</div>
<div id="A4.SS1.p3" class="ltx_para">
<p class="ltx_p">where <math id="A4.SS1.p3.m1" class="ltx_Math" alttext="\mu_{A}" display="inline"><semantics><msub><mi>Î¼</mi><mi>A</mi></msub><annotation encoding="application/x-tex">\mu_{A}</annotation></semantics></math> and <math id="A4.SS1.p3.m2" class="ltx_Math" alttext="\sigma_{A}" display="inline"><semantics><msub><mi>Ïƒ</mi><mi>A</mi></msub><annotation encoding="application/x-tex">\sigma_{A}</annotation></semantics></math> represent the mean and standard deviation of the advantages of all tokens within the RL-sampled batch, respectively. The KL divergence term is computed using the k1 estimationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>: <math id="A4.SS1.p3.m3" class="ltx_Math" alttext="\mathbb{D}_{\mathrm{KL}}\left[\pi_{\theta}(o_{i,j})\|\pi_{ref}(o_{i,j})\right]=\pi_{\theta}(o_{i,j})/\pi_{ref}(o_{i,j})" display="inline"><semantics><mrow><mrow><msub><mi>ğ”»</mi><mi>KL</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo>[</mo><mrow><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo>âˆ¥</mo><mrow><msub><mi>Ï€</mi><mrow><mi>r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>f</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>]</mo></mrow></mrow><mo>=</mo><mrow><mrow><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo>/</mo><msub><mi>Ï€</mi><mrow><mi>r</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>f</mi></mrow></msub></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathbb{D}_{\mathrm{KL}}\left[\pi_{\theta}(o_{i,j})\|\pi_{ref}(o_{i,j})\right]=\pi_{\theta}(o_{i,j})/\pi_{ref}(o_{i,j})</annotation></semantics></math>.
The optimization objective of REINFORCE++ is:</p>
</div>
<div id="A4.SS1.p4" class="ltx_para">
<table id="A4.E21" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="A4.E21X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A4.E21X.m2" class="ltx_Math" alttext="\displaystyle J_{R++}(\theta)" display="inline"><semantics><mrow><msub><mi>J</mi><mrow><mrow><mi>R</mi><mo>+</mo></mrow><mo lspace="0em">â£</mo><mo>+</mo></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>Î¸</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\displaystyle J_{R++}(\theta)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A4.E21X.m3" class="ltx_Math" alttext="\displaystyle=\mathbb{E}_{\bm{q}\sim\mathcal{D},\{\bm{o}_{i}\}_{i=1}^{G}\sim\pi_{old}}" display="inline"><semantics><mrow><mi></mi><mo>=</mo><msub><mi>ğ”¼</mi><mrow><mrow><mi>ğ’’</mi><mo>âˆ¼</mo><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi></mrow><mo>,</mo><mrow><msubsup><mrow><mo stretchy="false">{</mo><msub><mi>ğ’</mi><mi>i</mi></msub><mo stretchy="false">}</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>G</mi></msubsup><mo>âˆ¼</mo><msub><mi>Ï€</mi><mrow><mi>o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>d</mi></mrow></msub></mrow></mrow></msub></mrow><annotation encoding="application/x-tex">\displaystyle=\mathbb{E}_{\bm{q}\sim\mathcal{D},\{\bm{o}_{i}\}_{i=1}^{G}\sim\pi_{old}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="3" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(21)</span></td>
</tr>
<tr id="A4.E21Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A4.E21Xa.m2" class="ltx_Math" alttext="\displaystyle\frac{1}{\sum_{i=1}^{G}|\bm{o}_{i}|}\sum_{i=1}^{G}\sum_{t=1}^{|\bm{o}_{i}|}\left\{\min\left[r_{i,t}(\theta)\hat{A}_{i,t},\mathrm{clip}(r_{i,t}(\theta);1-\epsilon_{l},1+\epsilon_{h})\hat{A}_{i,t}\right]\right\}" display="inline"><semantics><mrow><mstyle displaystyle="true"><mfrac><mn>1</mn><mrow><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>G</mi></msubsup><mrow><mo lspace="0em" stretchy="false">|</mo><msub><mi>ğ’</mi><mi>i</mi></msub><mo stretchy="false">|</mo></mrow></mrow></mfrac></mstyle><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mstyle displaystyle="true"><munderover><mo movablelimits="false">âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>G</mi></munderover></mstyle><mrow><mstyle displaystyle="true"><munderover><mo movablelimits="false">âˆ‘</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><mo stretchy="false">|</mo><msub><mi>ğ’</mi><mi>i</mi></msub><mo stretchy="false">|</mo></mrow></munderover></mstyle><mrow><mo>{</mo><mrow><mi>min</mi><mo>â¡</mo><mrow><mo>[</mo><mrow><msub><mi>r</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>Î¸</mi><mo stretchy="false">)</mo></mrow><mo lspace="0em" rspace="0em">â€‹</mo><msub><mover accent="true"><mi>A</mi><mo>^</mo></mover><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub></mrow><mo>,</mo><mrow><mi>clip</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mrow><msub><mi>r</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>Î¸</mi><mo stretchy="false">)</mo></mrow></mrow><mo>;</mo><mrow><mn>1</mn><mo>âˆ’</mo><msub><mi>Ïµ</mi><mi>l</mi></msub></mrow><mo>,</mo><mrow><mn>1</mn><mo>+</mo><msub><mi>Ïµ</mi><mi>h</mi></msub></mrow><mo stretchy="false">)</mo></mrow><mo lspace="0em" rspace="0em">â€‹</mo><msub><mover accent="true"><mi>A</mi><mo>^</mo></mover><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub></mrow><mo>]</mo></mrow></mrow><mo>}</mo></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\frac{1}{\sum_{i=1}^{G}|\bm{o}_{i}|}\sum_{i=1}^{G}\sum_{t=1}^{|\bm{o}_{i}|}\left\{\min\left[r_{i,t}(\theta)\hat{A}_{i,t},\mathrm{clip}(r_{i,t}(\theta);1-\epsilon_{l},1+\epsilon_{h})\hat{A}_{i,t}\right]\right\}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="A4.E21Xb" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A4.E21Xb.m2" class="ltx_Math" alttext="\displaystyle\mathrm{with}" display="inline"><semantics><mi>with</mi><annotation encoding="application/x-tex">\displaystyle\mathrm{with}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A4.E21Xb.m3" class="ltx_Math" alttext="\displaystyle\,\,r_{i,t}(\theta)=\frac{\pi_{\theta}(o_{i,t}|\bm{q},\bm{o}_{i,&lt;t})}{\pi_{old}(o_{i,t}|\bm{q},\bm{o}_{i,&lt;t})}." display="inline"><semantics><mrow><mrow><mrow><msub><mi>r</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi>Î¸</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mstyle displaystyle="true"><mfrac><mrow><msub><mi>Ï€</mi><mi>Î¸</mi></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mrow><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo fence="false">|</mo><mrow><mi>ğ’’</mi><mo>,</mo><msub><mi>ğ’</mi><mrow><mi>i</mi><mo>,</mo><mrow><mi></mi><mo>&lt;</mo><mi>t</mi></mrow></mrow></msub></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow><mrow><msub><mi>Ï€</mi><mrow><mi>o</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>l</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>d</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mrow><msub><mi>o</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo fence="false">|</mo><mrow><mi>ğ’’</mi><mo>,</mo><msub><mi>ğ’</mi><mrow><mi>i</mi><mo>,</mo><mrow><mi></mi><mo>&lt;</mo><mi>t</mi></mrow></mrow></msub></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mfrac></mstyle></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\displaystyle\,\,r_{i,t}(\theta)=\frac{\pi_{\theta}(o_{i,t}|\bm{q},\bm{o}_{i,&lt;t})}{\pi_{old}(o_{i,t}|\bm{q},\bm{o}_{i,&lt;t})}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="A4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.2 </span>Experiments on K&amp;K Logic Puzzle</h3>

<div id="A4.SS2.p1" class="ltx_para">
<p class="ltx_p">Similar to the experiments conducted with GRPO, we validate two base models as starting points: <span class="ltx_text ltx_font_typewriter">Qwen2.5-3B-Instruct</span> and <span class="ltx_text ltx_font_typewriter">Qwen2.5-7B-Instruct-1M</span>. All hyperparameters of REINFORCE++ are kept consistent with those used for GRPO, as described in AppendixÂ <a href="#A2" title="Appendix B Hyperparameter Settings â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>.
The only difference is that, on the K&amp;K Logic Puzzle dataset, the optimal hyperparameter setting for <span class="ltx_text ltx_font_italic">Advantage Reweighting</span> is <math id="A4.SS2.p1.m1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics><mrow><mi>Î±</mi><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">\alpha=0.1</annotation></semantics></math> for REINFORCE++, and <math id="A4.SS2.p1.m2" class="ltx_Math" alttext="\alpha=0.3" display="inline"><semantics><mrow><mi>Î±</mi><mo>=</mo><mn>0.3</mn></mrow><annotation encoding="application/x-tex">\alpha=0.3</annotation></semantics></math> for GRPO.</p>
</div>
<div id="A4.SS2.p2" class="ltx_para">
<p class="ltx_p">The evaluation results on the test set are reported in TableÂ <a href="#A4.T7" title="Table 7 â€£ D.2 Experiments on K&amp;K Logic Puzzle â€£ Appendix D Additional Experimental Results on REINFORCE++ â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. Notably, the performance of naive REINFORCE++ is slightly worse than that of naive GRPO (cf. FigureÂ <a href="#S5.F4" title="Figure 4 â€£ 5.1 Experiments on K&amp;K Logic Puzzles â€£ 5 Experimental Results â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). This observation aligns with the findings of Xiong et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, as the advantage normalization method in REINFORCE++ may introduce unnecessary bias toward entirely incorrect responses on overly difficult prompts.
Nevertheless, the improvements achieved by our proposed methods, <span class="ltx_text ltx_font_italic">Advantage Reweighting</span> and <span class="ltx_text ltx_font_italic">Lopti</span>, remain significant. For more details on the training process, please refer to the records presented in FigureÂ <a href="#A4.F11" title="Figure 11 â€£ D.2 Experiments on K&amp;K Logic Puzzle â€£ Appendix D Additional Experimental Results on REINFORCE++ â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> and FigureÂ <a href="#A4.F12" title="Figure 12 â€£ D.2 Experiments on K&amp;K Logic Puzzle â€£ Appendix D Additional Experimental Results on REINFORCE++ â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>.</p>
</div>
<figure id="A4.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Experimental results of REINFORCE++ on the K&amp;K Logic Puzzles dataset.
For <span class="ltx_text ltx_font_italic">Advantage Reweight</span>, <math id="A4.T7.m3" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics><mrow><mi>Î±</mi><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">\alpha=0.1</annotation></semantics></math>, and for <span class="ltx_text ltx_font_italic">Lopti</span>, <math id="A4.T7.m4" class="ltx_Math" alttext="\eta=0.5" display="inline"><semantics><mrow><mi>Î·</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\eta=0.5</annotation></semantics></math>.
The evaluation accuracy on the test set are averaged over the last three checkpoints to mitigate randomness.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_border_t"></td>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="background-color:#EFEFEF;" colspan="5"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Difficulty by Number of People</span></th>
<td class="ltx_td ltx_border_t"></td>
</tr>
<tr class="ltx_tr" style="background-color:#EFEFEF;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">3</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">4</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">5</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">6</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">7</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column"><span class="ltx_text ltx_font_bold" style="background-color:#EFEFEF;">Avg.</span></th>
</tr>
<tr class="ltx_tr" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#ECF4FF;">Qwen2.5-3B-Instruct</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="background-color:#ECF4FF;">0.09</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="background-color:#ECF4FF;">0.10</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="background-color:#ECF4FF;">0.03</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="background-color:#ECF4FF;">0.05</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="background-color:#ECF4FF;">0.02</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" style="background-color:#ECF4FF;"><span class="ltx_text" style="background-color:#ECF4FF;">0.06</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#9B9B9B;"><span class="ltx_text ltx_font_bold" style="color:#9B9B9B;">REINFORCE++</span></span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#9B9B9B;">0.37</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#9B9B9B;">0.31</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#9B9B9B;">0.20</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#9B9B9B;">0.21</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#9B9B9B;">0.06</span></td>
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#9B9B9B;">0.23</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#F56B00;"><span class="ltx_text ltx_font_bold" style="color:#F56B00;">REINFORCE++ with Reweight</span></span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#F56B00;">0.53</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#F56B00;">0.44</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#F56B00;">0.31</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#F56B00;">0.26</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#F56B00;">0.14</span></td>
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#F56B00;">0.34 <sup class="ltx_sup"><span class="ltx_text ltx_font_italic">(â†‘46.1%)</span></sup></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#32BEE6;"><span class="ltx_text ltx_font_bold" style="color:#32BEE6;">REINFORCE++ with Lopti</span></span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#32BEE6;">0.47</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#32BEE6;">0.36</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#32BEE6;">0.26</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#32BEE6;">0.26</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#32BEE6;">0.12</span></td>
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#32BEE6;">0.29 <sup class="ltx_sup"><span class="ltx_text ltx_font_italic">(â†‘27.8%)</span></sup></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#009901;"><span class="ltx_text ltx_font_bold" style="color:#009901;">REINFORCE++ with Reweight &amp; Lopti</span></span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#009901;">0.61</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#009901;">0.49</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#009901;">0.38</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#009901;">0.34</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#009901;">0.21</span></td>
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#009901;">0.41 <sup class="ltx_sup"><span class="ltx_text ltx_font_italic">(â†‘76.5%)</span></sup></span></td>
</tr>
<tr class="ltx_tr" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_t"><span class="ltx_text ltx_font_bold" style="background-color:#ECF4FF;">Qwen2.5-7B-Instruct-1M</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="background-color:#ECF4FF;">0.22</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="background-color:#ECF4FF;">0.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="background-color:#ECF4FF;">0.08</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="background-color:#ECF4FF;">0.10</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text" style="background-color:#ECF4FF;">0.02</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" style="background-color:#ECF4FF;"><span class="ltx_text" style="background-color:#ECF4FF;">0.11</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#9B9B9B;"><span class="ltx_text ltx_font_bold" style="color:#9B9B9B;">REINFORCE++</span></span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#9B9B9B;">0.68</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#9B9B9B;">0.72</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#9B9B9B;">0.54</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#9B9B9B;">0.42</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#9B9B9B;">0.43</span></td>
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#9B9B9B;">0.56</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#F56B00;"><span class="ltx_text ltx_font_bold" style="color:#F56B00;">REINFORCE++ with Reweight</span></span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#F56B00;">0.81</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#F56B00;">0.77</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#F56B00;">0.66</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#F56B00;">0.62</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#F56B00;">0.48</span></td>
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#F56B00;">0.67 <sup class="ltx_sup"><span class="ltx_text ltx_font_italic">(â†‘19.7%)</span></sup></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#32BEE6;"><span class="ltx_text ltx_font_bold" style="color:#32BEE6;">REINFORCE++ with Lopti</span></span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#32BEE6;">0.89</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#32BEE6;">0.85</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#32BEE6;">0.71</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#32BEE6;">0.66</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text" style="color:#32BEE6;">0.51</span></td>
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="color:#32BEE6;">0.72 <sup class="ltx_sup"><span class="ltx_text ltx_font_italic">(â†‘29.7%)</span></sup></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b"><span class="ltx_text" style="color:#009901;"><span class="ltx_text ltx_font_bold" style="color:#009901;">REINFORCE++ with Reweight &amp; Lopti</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_b"><span class="ltx_text" style="color:#009901;">0.87</span></td>
<td class="ltx_td ltx_align_center ltx_border_b"><span class="ltx_text" style="color:#009901;">0.88</span></td>
<td class="ltx_td ltx_align_center ltx_border_b"><span class="ltx_text" style="color:#009901;">0.81</span></td>
<td class="ltx_td ltx_align_center ltx_border_b"><span class="ltx_text" style="color:#009901;">0.71</span></td>
<td class="ltx_td ltx_align_center ltx_border_b"><span class="ltx_text" style="color:#009901;">0.69</span></td>
<td class="ltx_td ltx_align_left ltx_border_b"><span class="ltx_text" style="color:#009901;">0.79 <sup class="ltx_sup"><span class="ltx_text ltx_font_italic">(â†‘41.9%)</span></sup></span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="A4.F11" class="ltx_figure"><img src="/html/2505.12929/assets/fig/kk_logics_training_record_RPP_3B.png" id="A4.F11.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="299" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>
Experimental records of <span class="ltx_text ltx_font_typewriter">Qwen2.5-3B-Instruct</span> trained with REINFORCE++ on the K&amp;K Logic Puzzle dataset. The training curve is smoothed through exponential moving average with coefficient of 0.95.
</figcaption>
</figure>
<figure id="A4.F12" class="ltx_figure"><img src="/html/2505.12929/assets/fig/kk_logics_training_record_RPP_7B.png" id="A4.F12.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="299" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>
Experimental records of <span class="ltx_text ltx_font_typewriter">Qwen2.5-7B-Instruct-1M</span> trained with REINFORCE++ on the K&amp;K Logic Puzzle dataset.
</figcaption>
</figure>
</section>
</section>
<section id="A5" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Limitations</h2>

<div id="A5.p1" class="ltx_para">
<p class="ltx_p">One limitation of our study lies in the additional computational overhead introduced by <span class="ltx_text ltx_font_italic">Lopti</span>.
As detailed in AppendixÂ <a href="#A3.SS2" title="C.2 Computational Costs â€£ Appendix C Experimental Details â€£ Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.2</span></a>, the updating process requires twice the amount of time as it splits the tokens in a batch into two groups and performs updates twice.
However, we also propose an alternative method, <span class="ltx_text ltx_font_italic">Advantage Reweighting</span>, which incurs negligible computational cost while achieving even greater improvements on the math-related dataset compared to <span class="ltx_text ltx_font_italic">Lopti</span>.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="javascript: void(0)" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/land_of_honey_and_milk" rel="nofollow" aria-hidden="true" tabindex="-1"></a>
    <a href="/log/2505.12929" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2505.12929">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2505.12929" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="javascript: void(0)" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Jun  5 14:48:30 2025 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
